{"instruction": "For a non-negative discrete random variable X, prove that E[X] = ∞ X i=0 P(X > i) [Kushal]", "response": "The students that assumed X to only take integer values (along with the previous constraints) will get the following answer We know that by definition the formula for a discrete random variable expectation of a random variable X is E[X] = X x∈Ω xP(X = x) where Ωis the set of values the discrete variable X can take. We also know that P(X > i) = X x∈Ω′ P(X = x) where Ω′ = {ω ∈Ω: ω > i} Now, we know that we can represent x as x = Px 0(1), since X was a non-negative discrete random variable with integer values. E[X] = X x∈Ω ( x X 0 1)P(X = x) Since, P(X = x) is always non-negative we can exchange the limits of the summations. And since the range of X was 0 to ∞, so we can replace Ωwith that E[X] = ∞ X i=0 X x>i P(X = x) E[X] = ∞ X i=0 P(X > i) 1 For students who didn’t assume that X only took integer values they will get this answer We know that by definition the formula for a discrete random variable expectation of a random variable X is E[X] = X x∈Ω xP(X = x) where Ωis a countable set. We also know that P(X > i) = X x∈Ω′ P(X = x) where Ω′ = {ω ∈Ω: ω > i} Now, we know that we can represent x as x = R x 0 du, since X was a non-negative discrete random variable. E[X] = X x∈Ω ( Z x 0 du)P(X = x) Since, P(X = x) is always non-negative we can exchange the limits of the summation and the integral. E[X] = Z ∞ 0 X x>u P(X = x)du E[X] = Z ∞ 0 P(X > u)du Marking Scheme (5 Marks Total): • Correctly stating E[X] and P(X > i) (1 mark) – 0.5 marks each • Correctly manipulating the summation of E[X] (3 marks) : – Writing x as a sum or integral with limits 0 to x (1 mark). – Swapping the summations or integral and using correct limits (2 marks) • Final answer (1 mark) : – Simplifying the double summation or integral to get the final answer Both answers will be given 5 marks. Other solutions that don’t assume X to be integers will be con- sidered and marked appropriately."}
{"instruction": "Consider a Geometric random variable X with parameter p. Derive the expression for its mean, second moment and variance. [Ronak] 2", "response": "1. Mean (Expected Value) of X For a Geometric random variable X with parameter p, the probability mass function is given by: P(X = k) = (1 −p)k−1p for k = 1, 2, 3, . . . The expected value E[X] is calculated as: E[X] = ∞ X k=1 k · P(X = k) = ∞ X k=1 k · (1 −p)k−1p This can be simplified using the identity for the sum of an infinite series. Consider the series: S = ∞ X k=1 kxk−1 = 1 (1 −x)2 for |x| < 1 Let x = 1 −p: E[X] = p ∞ X k=1 k(1 −p)k−1 = p · 1 p2 = 1 p Thus, the mean of X is: E[X] = 1 p 2. Second Moment of X The second moment E[X2] is calculated as: E[X2] = ∞ X k=1 k2 · P(X = k) = ∞ X k=1 k2 · (1 −p)k−1p Using the identity for the sum of the series: ∞ X k=1 k2xk−1 = 1 + x (1 −x)3 Let x = 1 −p: E[X2] = p ∞ X k=1 k2(1 −p)k−1 = p · 1 + (1 −p) p3 = p · 2 −p p3 = 2 −p p2 Thus, the second moment of X is: E[X2] = 2 −p p2 3 3. Variance of X The variance Var(X) is calculated as: Var(X) = E[X2] −(E[X])2 Substitute the values from the previous calculations: Var(X) = 2 −p p2 − \u00121 p \u00132 = 2 −p p2 −1 p2 = 2 −p −1 p2 = 1 −p p2 Thus, the variance of X is: Var(X) = 1 −p p2 Alternative Derivation We will apply the total expectation theorem, with A1 = {X = 1} (the event that the first try is a success) and A2 = {X > 1} (the event that the first try is a failure). This approach leads to a simpler calculation. If the first try is successful, then X = 1, and we have: E[X | X = 1] = 1. If the first try fails (X > 1), we have wasted one try, and we are back where we started. Therefore, the expected number of remaining tries is E[X], so: E[X | X > 1] = 1 + E[X]. By the total expectation theorem: E[X] = P(X = 1)E[X | X = 1] + P(X > 1)E[X | X > 1] = p · 1 + (1 −p) · (1 + E[X]) . Expanding and solving for E[X]: E[X] = p + (1 −p)(1 + E[X]), E[X] = p + (1 −p) + (1 −p)E[X], E[X] −(1 −p)E[X] = 1, E[X](p) = 1, 4 E[X] = 1 p. With similar reasoning, we can derive E[X2]: E[X2 | X = 1] = 1, E[X2 | X > 1] = E[(1 + X)2], E[(1 + X)2] = 1 + 2E[X] + E[X2]. Using the total expectation theorem again: E[X2] = p · 1 + (1 −p) · \u00001 + 2E[X] + E[X2] \u0001 , E[X2] = p + (1 −p) + 2(1 −p)E[X] + (1 −p)E[X2], E[X2] −(1 −p)E[X2] = p + 2(1 −p)E[X], E[X2](p) = 1 + 2(1 −p)E[X], E[X2] = 1 + 2(1 −p)E[X] p . Substituting E[X] = 1 p: E[X2] = 1 + 2(1 −p) 1 p p = 1 + 2(1 −p) · 1 p p , E[X2] = 1 + 2(1−p) p p = p + 2(1 −p) p2 , E[X2] = 2 −p p2 . So, E[X2] = 2 p2 −1 p. Alternate Variance Derivation Var[X] = E[X(X −1)] + E[X] −(E[X])2 E[X(X −1)] = 2(1 −p)p2 5 Marking Scheme (5 Marks Total): • Derivation of the Mean (2 marks): – Correct setup of the expectation formula (1 mark). – Correct derivation and final expression for E[X] = 1 p (1 mark). • Derivation of the Second Moment (2 marks): – Correct setup of the second moment formula (1 mark). – Correct derivation and final expression for E[X2] = 2−p p2 (1 mark). • Derivation of the Variance (1 mark): – Correct derivation and final expression for Var(X) = 1−p p2 (1 mark)."}
{"instruction": "Suppose that we roll a die twice. Consider the following three events • A = Second roll is 4 • B = Difference between the two rolls is 4 • C = Difference between the two rolls is 3 Are the three events pairwise independent? Are they also mutually independent? [Abhinav]", "response": "P(A) = 1/6 For event B, favourable outcomes are (1, 5), (5, 1), (2, 6), (6, 2) and hence P(B) = 4/36 = 1/9 For event C, favourable outcomes are (1, 4), (4, 1), (2, 5), (5, 2), (3, 6), (6, 3) and hence P(C) = 6/36 = 1/6 P(A T B) = 0 as the difference between 2 dice can’t be 4 with the second roll being 4, whereas P(A)P(B) = 1/54 P(B T C) = 0 as the difference between 2 dice can’t be 4 and 3 simulta- neously, whereas P(B)P(C) = 1/54 P(A T C) = 1/36 as there is only one possibility (1, 4) Since only P(A T C) = 1/36 = P(A) · P(C), A & C are independent. A & B and B & C are not. Since all the pairs are not independent, the 3 events are not pairwise independent. Since all subsets of the set of events (A, B and C) are not independent, the events are not mutually independent. Marking Scheme (5 Marks Total): • Correctly finding the probabilities of events and their intersection (3 marks) • Pairwise independence with reason (1 mark) 6 • Mutual independence with reason (1 mark) • If the difference is considered as 1stdie −2nddie, changes will be as follows: – P(B) = 1/18, P(C) = 1/12 – P(A T C) = 0 and still the events will not be both pairwise and mutually independent. – This notion of difference will also be considered if it is clearly mentioned in the answer. Also holds for 2nddie −1stdie • Partial marks will be given depending on the correctness of the an- swer"}
{"instruction": "Let X denote a Gaussian random variable with parameters c and d. Let Y denote", "response": "Binomial random variable with parameters n and p. Derive the expression for their respective variance Solution Derivation for Gaussian Note: Replaced d by d2 here for simplicity The pdf of a Gaussian random variable X ∼N(c, d2) is given by fX(x) = 1 √ 2πd2 exp \u0012 −(x −c)2 2d2 \u0013 Let I(n) denote the following family of integrals I(n) = Z ∞ −∞ (x −c)n √ 2πd2 exp \u0012 −(x −c)2 2d2 \u0013 dx Applying integration by parts, taking u = exp \u0010 −(x−c)2 2d2 \u0011 , dv = (x−c)ndx √ 2πd2 , the indefinite integral is given by Z udv = uv − Z vdu = exp \u0012 −(x −c)2 2d2 \u0013 (x −c)n+1 (n + 1) √ 2πd2 − Z (x −c)n+1 (n + 1) √ 2πd2 −(x −c) d2 exp \u0012 −(x −c)2 2d2 \u0013 dx = exp \u0012 −(x −c)2 2d2 \u0013 (x −c)n+1 (n + 1) √ 2πd2 + 1 (n + 1)d2 Z (x −c)n+2 √ 2πd2 exp \u0012 −(x −c)2 2d2 \u0013 dx Applying the limits from −∞to ∞, the first term simplifies to 0 and we get I(n) = I(n + 2) (n + 1)d2 or I(n) = (n −1)d2I(n −2) 7 I(0) = Z ∞ −∞ 1 √ 2πd2 exp \u0012 −(x −c)2 2d2 \u0013 dx = Z ∞ −∞ fX(x) dx = 1 To calculate the mean, we observe that I(1) = Z ∞ −∞ (x −c) √ 2πd2 exp \u0012 −(x −c)2 2d2 \u0013 dx = Z ∞ −∞ x √ 2πd2 exp \u0012 −(x −c)2 2d2 \u0013 dx −c Z ∞ −∞ 1 √ 2πd2 exp \u0012 −(x −c)2 2d2 \u0013 dx = E[X] −c I(1) = Z ∞ −∞ (x −c) √ 2πd2 exp \u0012 −(x −c)2 2d2 \u0013 dx Substituting t = x −c, we get I(1) = Z ∞ −∞ t √ 2πd2 exp \u0012 −t2 2d2 \u0013 dt Since this is an odd function, the integral is 0 =⇒I(1) = 0 =⇒E[X] −c = 0 =⇒E[X] = c The variance is given by V ar(X) = E[(X −E[X])2] = Z ∞ −∞ (x −c)2 fX(x) dx = Z ∞ −∞ (x −c)2 √ 2πd2 exp \u0012 −(x −c)2 2d2 \u0013 dx = I(2) From the recursive relation, we get I(2) = d2I(0) = d2(1) = d2 =⇒V ar(X) = d2 Derivation for Binomial The pmf of a binomial random variable Y ∼B(n, p) is given by pY (k) = \u0012n k \u0013 pk(1 −p)n−k 8 The mean is given by E[Y ] = n X k=0 kpY (k) = n X k=0 k \u0012n k \u0013 pk(1 −p)n−k To calculate the mean, we take the derivative of the binomial sum n X k=0 \u0012n k \u0013 pk(1 −p)n−k = 1 Differentiating w.r.t p n X k=0 \u0012n k \u0013 \u0000kpk−1(1 −p)n−k −(n −k)pk(1 −p)n−k−1\u0001 = 0 =⇒ n X k=0 \u0012n k \u0013 kpk−1(1 −p)n−k−1(p + 1 −p) = n n X k=0 \u0012n k \u0013 pk(1 −p)n−k−1 =⇒ 1 p(1 −p) n X k=0 k \u0012n k \u0013 pk(1−p)n−k(p+1−p) = n 1 −p n X k=0 \u0012n k \u0013 pk(1−p)n−k =⇒ E[Y ] p(1 −p) = n 1 −p =⇒E[Y ] = np To calculate E[Y 2], we take the derivative of E[Y] E[Y ] = n X k=0 k \u0012n k \u0013 pk(1 −p)n−k = np Differentiating w.r.t p n X k=0 k \u0012n k \u0013 \u0000kpk−1(1 −p)n−k −(n −k)pk(1 −p)n−k−1\u0001 = n =⇒ n X k=0 k2 \u0012n k \u0013 pk−1(1−p)n−k−1 (1 −p + p)−n n X k=0 k \u0012n k \u0013 pk(1−p)n−k−1 = n =⇒ E[Y 2] p(1 −p) −n E[Y ] (1 −p) = n =⇒E[Y 2] = np(1 −p) + npE[Y ] =⇒E[Y 2] = np(1 −p) + n2p2 The variance is given by V ar(Y ) = E[Y 2] −E[Y ]2 = np(1 −p) + n2p2 −n2p2 V ar(Y ) = np(1 −p) 9 Alternative derivation for binomial We consider Y ∼B(n, p) as sum of n independent bernoulli random variables Zi with parameter p V ar(Y ) = V ar( n X i=1 Zi) = n X i=1 V ar(Zi) = nV ar(Z) Z takes value 1 with probability p and 0 with probability 1 −p The expected value of Z is given by E[Z] = X z z · P(Z = z) = 0 · P(Z = 0) + 1 · P(Z = 1) = 0 · (1 −p) + 1 · p = p E[Z2] = X z z2 · P(Z = z) = 02 · P(Z = 0) + 12 · P(Z = 1) = 0 · (1 −p) + 1 · p = p V ar(Z) = E[Z2] −E[Z]2 = p −p2 = p(1 −p) V ar(Y ) = nV ar(Z) = np(1 −p) Marking Scheme (5 Marks Total): • Derivation for Gaussian (2.5 marks) – Correct derivation of mean (0.5 marks). – Correct derivation of variance (2 marks). • Derivation for Binomial (2.5 marks): – Correct derivation of mean (1 mark) – Correct derivation of variance (1.5 marks). • Alternative Derivation for binomial (2.5 marks) – Formula for variance of sum of i.i.d random variables (0.5 marks) – Correct derivation of mean (1 mark) 10 – Correct derivation of variance (1 mark) Note: • No marks will be given for directly writing the result without proof. • All integrals need proper proofs, except gaussian integral for which equating integral of pdf with 1 will suffice. 11"}
{"instruction": "Let X be an exponential random variable with parameter λ and let Y be a random variable with the Gamma distribution Y ∼Gamma(k, θ).", "response": ") Show how to generate X using a uniform random variable U drawn from the interval [0, 1]. b) Show how to generate Y using k uniform random variables drawn from [0, 1]. Note: The Gamma distribution Y ∼Gamma(k, θ) can be expressed as the sum of k independent exponential random variables X1, X2, . . . , Xk, where each Xi ∼ Exp \u0000 1 θ \u0001 . That is: Y = k X i=1 Xi where Xi are independent and identically distributed. Answer: a) To generate X: The cumulative distribution function (CDF) of X is given by: FX(x) = 1 −e−λx for x ≥0 - Let U ∼Uniform(0, 1). By the inverse transform method: FX(X) = U 1 −e−λX = U X = −1 λ ln(1 −U) - Since U ∼Uniform(0, 1), the distribution of 1 −U is also uniform, so −ln(1 −U) has the same distribution as −ln(U). Therefore, we can simplify this to: X = −1 λ ln(U) b) To generate Y ∼Gamma(k, θ): - Generate k independent uniform random variables: U1, U2, . . . , Uk ∼Uniform(0, 1) - Using the inverse transform method for each Xi ∼Exp \u0000 1 θ \u0001 : Xi = −θ ln(Ui), i = 1, 2, . . . , k - Sum the Xi’s to obtain Y : Y = k X i=1 Xi = −θ k X i=1 ln(Ui) 1"}
{"instruction": "Prove that x ∼f(x) = xe−x; x ≥0 has a moment generating function of 1 (1−t)2. Hint: Use the change of variable technique to integrate with respect to w = x(1−t) instead of x.", "response": "The moment generating function is M(x, t) = E(ext) = Z ∞ 0 extxe−xdx = Z ∞ 0 xe−x(1−t)dx. Define w = x(1 −t). Then x = w 1 −t and dx dw = 1 1 −t. The change of variable technique indicates that Z g(x)dx = Z g(x(w)) dx dwdw, where g(x) = xe−x(1−t). Thus we find that M(x, t) = Z ∞ 0 w 1 −te−w 1 1 −tdw = 1 (1 −t)2 Z ∞ 0 we−wdw = 1 (1 −t)2. Here the value of the final integral is unity, since the expression we−w, which is to be found under the integral sign, has the same form as the p.d.f. of x. To demonstrate directly that the value is unity, we can use the technique of inte- grating by parts. The formula is Z udv dxdx = uv − Z vdu dxdx. Within the expression we−w, we take u = w and e−w = dv/dw. Then we get Z ∞ 0 we−wdw = \u0002 −we−w\u0003∞ 0 + Z ∞ 0 e−wdw = \u0002 −e−w\u0003∞ 0 = 1."}
{"instruction": "Use the rejection method to generate a random variable having the Gamma(5 2, 1) density function. Note: The pdf of Gamma(k, θ) is given by f(x) = 1 Γ(k)θk xk−1e−x/θ and Γ(5 2) = 3 4π. Hint: You need to figure out an appropriate distribution you can already sample from to use in the rejection method.", "response": "We pick exp(λ) as the distribution we’ll be sampling from. f(x) = 4 3√πx 3 2e−x, x > 0 g(x) = λe−λx, x > 0 =⇒f(x) g(x) = 4 3λ√πx 3 2e(λ−1)x 2 We wish to find a c such that f(x) g(x) ≤c for all x d dx \u0012f(x) g(x) \u0013 = 0 Hence, x = 3 2(1 −λ) We need to pick an appropriate λ such that x > 0. We pick λ = 2 5. c = 10 3√π \u00125 2 \u0013 3 2 e−3 2 f(x) cg(x) = x 3 2e−3x 5 \u0000 5 2 \u0001 3 2 e−3 2 Now for to finally generate the required random number (i.e using the rejection method algorithm) (a) Generate a random number U1 and use that to generate a random number from exp(2 5) (Y = −5 2 log U1) (b) Generate a random number U2 (c) If U2 < Y 3 2 e−3Y 5 ( 5 2) 3 2 e−3 2 , set X = Y. Otherwise, execute the step (a)."}
{"instruction": "What is the expected number of iterations to generate k random numbers from a distribution using the rejection method?", "response": "Let f be the pdf of the distribution we wish to sample from and g be the pdf of the distribution we sample from such that support(f) ⊆support(g). Then for rejection sampling we have a c such that f(y) g(y) ≤c for all y. We claim that P \u0010 U ≤ f(Y ) Mg(Y ) \u0011 = 1 c P \u0012 U ≤f(Y ) cg(Y ) \u0013 = Eg(Y )[P(U ≤f(y) cg(y)|Y = y)] = Eg(Y ) \u0014 f(y) cg(y) \u0015 = Eg(Y ) \u0014 f(y) cg(y) \u0015 = Z y:g(y)>0 f(y) cg(y)g(y)dy = 1 c The last step comes from the fact that support(f) ⊆support(g). Now notice that the number of iteration required to successfully generate one num- ber is a geometric random variable with parameter 1 c. So the expected number of iterations for generating one sample is c and for k samples is kc 3"}
{"instruction": "(a) Let MX(s) be finite for s ∈[−c, c], where c > 0. Show that the MGF of Y= aX + b is given by MY (s) = esbMX(as) and it is finite in h −c |a|, c |a| i . (b) If X1, X2, . . . , Xn are n independent random variables with respective moment- generating functions MXi(t) = E[etXi] for i = 1, 2, . . . , n, then prove the moment-generating function of the linear combination: Y = Pn i=1 aiXi is: MY (t) = n Y i=1 MXi(ait)", "response": "(a) MY (s) = E[esY ] = E[es(aX+b)] = esbE[e(sa)X] = esbMX(as). Where, as ∈[−c, c]. So, MX(as) is finite for s ∈ h −c |a|, c |a| i . (b) MY (t) = E[etY ] = E[et(a1X1+a2X2+···+anXn)] = E[ea1tX1]E[ea2tX2] . . . E[eantXn] = MX1(a1t)MX2(a2t) . . . MXn(ant) = n Y i=1 MXi(ait)"}
{"instruction": "Let X ∼Normal(Y, 1) where Y ∼Exponential(λ). Find the MGF of X.", "response": "E[etX] = Z ∞ 0 E[esX|Y = y]fY (y)dy using the MGF of Gaussian = Z ∞ 0 eyte 1 2 t2λe−λydy = λe 1 2 t2 Z ∞ 0 ey(t−λ)dy = λ t −λe 1 2 t2 \u0002 ey(t−λ)\u0003∞ 0 when t < λ = λ t −λe 1 2 t2[−1] = λ λ −te 1 2 t2 4"}
{"instruction": "Let X be a continuous random variable with PDF fX(x) = ( x2 \u00002x + 3 2 \u0001 for 0 < x ≤1 0 otherwise If Y = 2 X + 3, find Var(Y ).", "response": "First, note that Var(Y ) = Var( 2 X + 3) = 4 · Var( 1 X ), Thus, it suffices to find Var( 1 X ), which is given by Var( 1 X ) = E[ 1 X2] −(E[ 1 X ])2. Using LOTUS (Law of the Unconscious Statistician), we have E[ 1 X ] = Z 1 0 x \u0012 2x + 3 2 \u0013 dx = 17 12, E[ 1 X2] = Z 1 0 \u0012 2x + 3 2 \u0013 dx = 5 2. Thus, Var( 1 X ) = E[ 1 X2] −(E[ 1 X ])2 = 71 144. So, we obtain Var(Y ) = 4 · Var( 1 X ) = 71 36."}
{"instruction": "An absent-minded professor schedules two student appointments for the same time. The appointment durations are independent and exponentially distributed with mean thirty minutes. The first student arrives on time, but the second student arrives five minutes late. What is the expected value of the time between the arrival of the first student and the departure of the second student?", "response": "The expected value of the time between the arrival of the first student and the departure of the second student is given by: E[Time] = (5+E[stay of 2nd student])·P(1st stays no more than 5 minutes)+ (E[stay of 1st | stay of 1st ≥5]+E[stay of 2nd student])·P(1st stays more than 5 minutes). We have: E[stay of 2nd student] = 30, 1 and using the memorylessness property of the exponential distribution: E[stay of 1st | stay of 1st ≥5] = 5 + E[stay of 1st] = 35. Also, P(1st student stays no more than 5 minutes) = 1 −exp \u0012 −5 30 \u0013 , P(1st student stays more than 5 minutes) = exp \u0012 −5 30 \u0013 . Substituting these into the formula, we get: E[Time] = (5 + 30) · \u0012 1 −exp \u0012 −5 30 \u0013\u0013 + (35 + 30) · exp \u0012 −5 30 \u0013 . E[Time] = 35 + 30 · exp \u0012 −5 30 \u0013 = 60.394."}
{"instruction": "Let X be a random variable uniformly distributed in [0, π 2]. Let Y = sin(X). Calculate the probability density function (PDF) of Y . Also, calculate the PDF of Y if X is uniformly distributed in \u0002 −π 2, π \u0003 .", "response": "Let X be a random variable uniformly distributed in \u0002 −π 2, π \u0003 , and let Y = sin(X). We wish to calculate the probability density function (PDF) of Y . Case 1: X uniformly distributed in \u0002 0, π 2 \u0003 The cumulative distribution function (CDF) of Y can be computed as follows: FY (y) = P(Y ≤y) = P(sin(X) ≤y). Since X is uniformly distributed in \u0002 0, π 2 \u0003 , we have P(sin(X) ≤y) = P(X ≤arcsin(y)). Thus, FY (y) = arcsin(y) π 2 = 2 arcsin(y) π , for 0 ≤y ≤1. The probability density function (PDF) fY (y) is the derivative of the CDF: fY (y) = d dyFY (y) = d dy \u00122 arcsin(y) π \u0013 = 2 π p 1 −y2. Thus, the PDF of Y is: fY (y) = ( 2 π√ 1−y2 for 0 ≤y ≤1, 0 otherwise. 2 Case 2: X uniformly distributed in \u0002 −π 2, π \u0003 The cumulative distribution function (CDF) of Y can be computed as follows: FY (y) = P(Y ≤y) = P(sin(X) ≤y). Since X is uniformly distributed in \u0002 −π 2, π \u0003 , we need to consider two intervals for X when y ∈[−1, 1]. Case 2a: −1 ≤y ≤0 In this case, sin(X) ≤y implies X ∈ \u0002 −π 2, arcsin(y) \u0003 . The CDF for this case is: FY (y) = P(X ≤arcsin(y)) = arcsin(y) + π 2 3π 2 = π 2 + arcsin(y) 3π 2 = 1 3+2 arcsin(y) 3π . Case 2b: 0 ≤y ≤1 Here, X ∈[0, arcsin(y)] or X ∈[π −arcsin(y), π]. - The probability for X ≤arcsin(y) is: P(X ≤arcsin(y)) = arcsin(y) + π 2 3π 2 = 1 3 + 2 arcsin(y) 3π . - The probability for X ≥π −arcsin(y) is: P(X ≥π −arcsin(y)) = arcsin(y) 3π 2 = 2 arcsin(y) 3π . Thus, the total CDF for 0 ≤y ≤1 is: FY (y) = P(X ≤arcsin(y)) + P(X ≥π −arcsin(y)) = 1 3 + 4 arcsin(y) 3π . PDF Calculation The probability density function (PDF) fY (y) is the derivative of the CDF: For −1 ≤y ≤0: fY (y) = d dy \u00121 3 + 2 arcsin(y) 3π \u0013 = 2 3π p 1 −y2. For 0 ≤y ≤1: fY (y) = d dy \u00121 3 + 4 arcsin(y) 3π \u0013 = 4 3π p 1 −y2. Thus, the PDF of Y is: fY (y) =        2 3π√ 1−y2 for −1 ≤y ≤0, 4 3π√ 1−y2 for 0 ≤y ≤1, 0 otherwise. 3"}
{"instruction": "Let X1, X2, . . . , Xn be n independent exponential random variables with the same parameter λ. Let Zmin = min(X1, X2, . . . , Xn) and Zmax = max(X1, X2, . . . , Xn). Calculate the probability density functions of Zmin and Zmax.", "response": "The cumulative distribution function (CDF) of Zmin is given by: FZmin(z) = P(Zmin ≤z) = 1 −P(Zmin > z). Since Zmin > z if and only if all Xi > z, we have: P(Zmin > z) = P(X1 > z) · P(X2 > z) · · · P(Xn > z). For an exponential random variable with parameter λ, P(Xi > z) = e−λz. Thus, P(Zmin > z) = \u0000e−λz\u0001n = e−nλz. Therefore, FZmin(z) = 1 −e−nλz. The probability density function (PDF) is the derivative of the CDF: fZmin(z) = d dzFZmin(z) = nλe−nλz. Thus, the PDF of Zmin is: fZmin(z) = ( nλe−nλz for z ≥0 0 otherwise . The cumulative distribution function (CDF) of Zmax is given by: FZmax(z) = P(Zmax ≤z) = P(X1 ≤z, X2 ≤z, . . . , Xn ≤z). Since the Xi are independent, P(X1 ≤z, X2 ≤z, . . . , Xn ≤z) = P(X1 ≤z) · P(X2 ≤z) · · · P(Xn ≤z). For an exponential random variable with parameter λ, P(Xi ≤z) = 1 −e−λz. Thus, P(Zmax ≤z) = \u00001 −e−λz\u0001n . Therefore, FZmax(z) = \u00001 −e−λz\u0001n . The probability density function (PDF) is the derivative of the CDF: fZmax(z) = d dzFZmax(z) = nλe−λz \u00001 −e−λz\u0001n−1 . Thus, the PDF of Zmax is: fZmax(z) = ( nλe−λz \u00001 −e−λz\u0001n−1 for z ≥0 0 otherwise . 4"}
{"instruction": "Let X be a non-negative continuous random variable. Show that E[X2] = Z ∞ x=0 2xP(X > x) dx", "response": "Consider a random variable Y = X2. Since Y is a non-negative continuous random variable, we have E[Y ] = Z ∞ y=0 P(Y > y)dy =⇒E[X2] = Z ∞ x2=0 P(X2 > x2)dx2 Since X is non-negative and dx2 = 2xdx =⇒E[X2] = Z ∞ x=0 2xP(X > x)dx"}
{"instruction": "Let Y be Geometric(p) where p = λh. Define X = Y h where λ, h > 0. Prove that for any x ∈(0, ∞), we have lim h→0 FX(x) = 1 −e−λx", "response": "The CDF of variable Y is FY (y) = P(Y ≤y) = 1 −(1 −p)y = 1 −(1 −λh)y Since X = Y h, FX(x) = P(Y h ≤x) = P \u0010 Y ≤x h \u0011 = FY \u0010x h \u0011 = 1 −(1 −λh) x h We can now evaluate the limit. lim h→0 FX(x) = lim h→0 1 −(1 −λh) x h Since limm→∞(1 −λ m)xm = e−λx where m = 1 h lim h→0 FX(x) = 1 −e−λx We have shown that as p →0, a geometric random variable becomes exponential. 5"}
{"instruction": "Let X and Y be two jointly continuous random variables with joint probability density function (PDF) given by: fXY (x, y) = ( x2 6 + y2 6 + xy 8 , 0 ≤x ≤2, 0 ≤y ≤3 0, otherwise For 0 ≤y ≤3, find: • E[X | Y = 2] • Var(X | Y = 2)", "response": "Given the joint probability density function (PDF): fXY (x, y) = ( x2 6 + y2 6 + xy 8 , 0 ≤x ≤2, 0 ≤y ≤3 0, otherwise we need to find E[X | Y = 2] and Var(X | Y = 2). Step 1: Find E[X | Y = 2] E[X | Y = 2] = Z ∞ −∞ xfX|Y (x|2) dx Since 0 ≤x ≤2 and 0 ≤y ≤3, the conditional distribution is: fX|Y (x|2) = fXY (x, 2) R 2 0 fXY (x, 2) dx The joint distribution for Y = 2 is: fXY (x, 2) = x2 6 + 4 6 + 2x 8 = x2 6 + 2 3 + x 4 Thus, E[X | Y = 2] = R 2 0 x \u0010 x2 6 + 2 3 + x 4 \u0011 dx R 2 0 \u0000 x2 6 + 2 3 + x 4 \u0001 dx Step 2: Solve the integral in the denominator Z 2 0 \u0012x2 6 + 2 3 + x 4 \u0013 dx = 1 6 Z 2 0 x2 dx + 2 3 Z 2 0 1 dx + 1 4 Z 2 0 x dx = 1 6 \u0014x3 3 \u00152 0 + 2 3 [x]2 0 + 1 4 \u0014x2 2 \u00152 0 = 1 6 × 8 3 + 2 3 × 2 + 1 4 × 2 1 = 4 9 + 4 3 + 1 2 = 20.5 9 Step 3: Solve the integral in the numerator Z 2 0 x \u0012x2 6 + 2 3 + x 4 \u0013 dx = 1 6 Z 2 0 x3 dx + 2 3 Z 2 0 x dx + 1 4 Z 2 0 x2 dx = 1 6 \u0014x4 4 \u00152 0 + 2 3 \u0014x2 2 \u00152 0 + 1 4 \u0014x3 3 \u00152 0 = 1 6 × 16 4 + 2 3 × 2 + 1 4 × 8 3 = 16 24 + 4 3 + 2 3 = 8 3 Step 4: Calculate E[X | Y = 2] E[X | Y = 2] = 8 3 20.5 9 = 8 3 × 9 20.5 = 24 20.5 ≈1.17 Step 5: Find E[X2 | Y = 2] E[X2 | Y = 2] = R 2 0 x2 \u0010 x2 6 + 2 3 + x 4 \u0011 dx R 2 0 \u0000 x2 6 + 2 3 + x 4 \u0001 dx Using the same denominator as in step 2, calculate the numerator: Z 2 0 x2 \u0012x2 6 + 2 3 + x 4 \u0013 dx = 1 6 Z 2 0 x4 dx + 2 3 Z 2 0 x2 dx + 1 4 Z 2 0 x3 dx = 1 6 \u0014x5 5 \u00152 0 + 2 3 \u0014x3 3 \u00152 0 + 1 4 \u0014x4 4 \u00152 0 = 1 6 × 32 5 + 2 3 × 8 3 + 1 4 × 16 4 = 32 30 + 16 9 + 4 = 6.85 Thus, E[X2 | Y = 2] = 6.85 20.5 9 ≈3.0 Step 6: Find Var(X | Y = 2) Var(X | Y = 2) = E[X2 | Y = 2] −(E[X | Y = 2])2 Var(X | Y = 2) = 3.0 −(1.17)2 = 3.0 −1.37 = 1.63 Thus, the conditional expectation and variance are: E[X | Y = 2] ≈1.17, Var(X | Y = 2) ≈1.63"}
{"instruction": "Let X and Y be two independent N(0, 1) random variables, and U = X + Y . (a) Find the conditional PDF of U given X = x, fU|X(u|x). (b) Find the PDF of U, fU(u). (c) Find the conditional PDF of X given U = u, fX|U(x|u). 2 (d) Find E[X|U = u], and Var(X|U = u).", "response": "(a) fU|X(u|x) ∼N(x, 1) To solve this, write the CDF of random variable U|X, which is given by FU|X(u|x) = P(U ≤u|X = x) = P(X + Y ≤u|X = x) = P(x + Y ≤u|X = x) = P(Y ≤u −x|X = x) = FY |X(u −x|x) = FY (u −x) since X and Y are independent. Now converting this into PDF, we get fU|X(u|x) = fY (u −x) When you substitute the value in N(0, 1) then you will see that this takes the form of Gaussian RV with mean x and variance 1. (b) fU(u) ∼N(0, 2) Solve this by getting marginal PDF from the PDF calculated above. Try to make the expression in numerator of exponential while calcu- lating a whole square (this method is also known as completing the square), and then convert the exponential obtained into a Gaussian RV with some mean and variance (you need to find corresponding values of mean and variance, which when simplified gives the expres- sion in exponent). Then use the fact that integration of PDF for a Gaussian RV will sum to 1, giving at the end PDF of Gaussian with mean 0 and vari- ance 2. A generalised result: Sum of N Gaussian RV is a Gaussian RV with mean and variance as sum of all the N Gaussian means and variances respectively. (c) fX|U(x|u) ∼N(u 2, 1 2) Apply Bayes Theorem using the results already calculated. (d) EX[X|U = u] = EX[N(u 2, 1 2)] = u 2 (e) VarX[X|U = u] = VarX[N(u 2, 1 2)] = 1 2 3"}
{"instruction": "Fraser runs a dolphin-watch business. Every day, he is unable to run the trip due to bad weather with probability p, independently of all other days. Fraser works every day except the bad-weather days, which he takes as holiday. Let Y be the number of consecutive days Fraser has to work between bad-weather days. Let X be the total number of customers who go on Fraser’s trip in this period of Y days. Conditional on Y , the distribution of X is (X|Y ) ∼Poisson(µY ). (a) Name the distribution of Y , and state E(Y ) and Var(Y ). (b) Find the expectation and the variance of the number of customers Fraser sees between bad-weather days, E(X) and Var(X). [Poisson(λ) Random Variable is a discrete random variable with mean λ and vari- ance λ.]", "response": "(a) Let ’success’ be ’bad-weather day’ and ’failure’ be ’work-day’. Then P(success) = P(bad-weather) = p. Y is the number of failures before the first success. So Y ∼Geometric(p). Thus E(Y ) = 1 −p p , Var(Y ) = 1 −p p2 . (b) We know (X|Y ) ∼Poisson(µY ) : so E(X|Y ) = Var(X|Y ) = µY. By the Law of Total Expectation: E(X) = EY {E(X|Y )} = EY (µY ) = µEY (Y ) ∴E(X) = µ(1 −p) p . 4 By the Law of Total Variance: Var(X) = EY (Var(X|Y )) + VarY (E(X|Y )) = EY (µY ) + VarY (µY ) = µEY (Y ) + µ2VarY (Y ) = µ \u00121 −p p \u0013 + µ2 \u00121 −p p2 \u0013 = µ(1 −p)(p + µ) p2 ."}
{"instruction": "The following is one formulation of a famous “two envelope” paradox. Jill is a money-loving individual who, given two options, invariably chooses the one that gives her the most money in expectation. One day Harry, a trusted (and capable of delivering) individual, offers her the following deal as a gift. He will secretly toss a fair coin until the first time that it comes up tails. If there are n heads before the first tails, he will place 10n dollars in one envelope and 10n+1 dollars in the second envelope.(Thus, the probability that one envelope has 10n dollars and the other has 10n+1 dollars is 2−n−1 for n ≥0.) Harry will then hand Jill the pair of envelopes (randomly ordered, indistinguishable from the outside) and invite her to choose one. After Jill chooses an envelope she will be allowed to open it. Once she does, she will be allowed to either keep the money in the first envelope or switch to the second envelope and keep whatever amount of money is in the second envelope. However, if she decides to switch envelopes, she has to pay", "response": "one dollar “switching fee.” (a) If Jill finds 100 dollars in the first envelope she opens, what is the condi- tional probability that the other envelope contains 1000 dollars? What is the conditional probability that the other envelope contains 10 dollars? (b) If Jill finds 100 dollars in the first envelope she opens, how much money does Jill expect to win from the game if she does not switch envelopes? (Answer: 100 dollars.) How much does she expect to win (net, after the switching fee) if she does switch envelopes? (c) Generalize the answers above to the case that the first envelope contains 10n dollars (for n ≥0) instead of 100. A: We solve (c) and then apply its results to (a) and (b) Let Y be the random variable for number of heads before the first tails, X1 be the amount of money in the envelope chosen by Jill, and X2 be the amount of money in the other envelope. The pmf of Y is pY (y) = 1 2y+1 PMF of X1 First let’s find the pmf of X1 pX1(x) = X y pX1|Y (x|y)pY (y) 5 If x = 10n, then pX1|Y (x|y) = 0 for y /∈{n −1, n} =⇒pX1(10n) = pX1|Y (10n|n −1)pY (n −1) + pX1|Y (10n|n)pY (n) Now, pX1|Y (10n|n −1) = pX1|Y (10n|n) = 1 2 since the envelopes are chosen randomly =⇒pX1(10n) = 1 2 \u0012 1 2n + 1 2n+1 \u0013 = 3 2n+2 Conditional PMF of X2 given X1 The conditional pmf of X2 conditioned on X1, pX2|X1(x2|x1) is given by (the identity can be verified easily) pX2|X1(x2|x1) = X y pX2|X1,Y (x2|x1, y)pY |X1(y|x1) = X y pX2|X1,Y (x2|x1, y)pX1|Y (x1|y) pY (y) pX1(x1) Let x1 = 10n If x2 = 10n+1, then (X1, X2) = (10n, 10n+1) is possible only for Y = n pX2|X1(10n+1|10n) = pX2|X1,Y (10n+1|10n, n)pX1|Y (10n|n) pY (n) pX1(10n) = 1 × 1 2 × 1 2n+1 3 2n+2 = 1 3 pX2|X1(10n−1|10n) = 1 −1 3 = 2 3 Net reward for switching Let R(X1, A) represent the reward for action A when the first envelope contains X1 dollars. R(10n, keep) = 10n R(10n, switch) = −1 + E(X2|X1 = 10n) = −1 + 10n+1 × 1 3 + 10n−1 × 2 3 = 34 × 10n−1 −1 (a) Probability of 1000 dollars = 1 3 Probability of 100 dollars = 2 3 (b) Net gain after switching = 340-1 = 339 dollars 6 Figure 1: Figure for question 10"}
{"instruction": "Harry Potter’s closet contains 12 numbered brooms, of which 8 are Comet Two Sixty’s (numbered 1 - 8) and 4 are Nimbus Two Thousand’s (Numbered 9-12). Harry, Ron, George and Fred want to sneak out for a game of Quidditch in the middle of the night. They don’t want to turn on the light in case Snape catches them. They reach in the closet and pull out a sample of 4 brooms. Give answers for both unordered and ordered samples. 3 (a) How many different samples are possible? (b) How many samples have exactly one Comet Two Sixty in them? (c) How many samples have at least 3 Comet Two Sixty’s? (d) Now, Ginny and Demelza wanna join so they grab 6 brooms, but Demelza believes that the both teams should have equal number of each type of broom for the game to be balanced. So, for any broom for a team we would need another broom of the same type for the other team. How many samples will keep Demelza happy?", "response": "(a) 12C4 = 495 12P4 = 11880 (b) 8C1.4C3 = 32 8C1.4C3.4! = 768 (c) 8C3.4C1 + 8C4.4C0 = 294 (8C3.4C1 + 8C4.4C0).4! = 7056 (d) So, we would need to look at three cases: A = (4Nimbus, 2 Comet), B = (2 Nimbus, 4 Comet) , C = (6 Comet), since these are mutually exclusive, Ans = P(A) + P(B) + P(C) A = 4C4.8C2 = 28 B = 4C2.8C4 = 420 B = 4C0.8C6 = 28 Total = A + B + C = 28 + 420 + 28 = 476 For ordered since there are 6 elements, and each is numbered, multi- plying total by 6! accounts for all samples Total = 6!(476) = 342720"}
{"instruction": "The Celtics and the Lakers are set to play a playoff series of n basketball games, where n is odd. The Celtics have a probability p of winning any one game, inde- pendent of other games. (a) Find the values of p for which n = 5 is better for the Celtics than n = 3. (b) Generalize part (a). For any k > 0, find the values for p for which n = 2k + 1 is better for the Celtics than n = 2k −1. 4", "response": "a For n = 5 and n = 3, we compare the probabilities of the Celtics winning the series. Let P(n) denote the probability of the Celtics winning the series when there are n games. For n = 3: The Celtics need to win 2 out of 3 games. The probability is: P(3) = \u00122 1 \u0013 p2(1 −p)1 + p3 = 2p2(1 −p) + p3 For n = 5: The Celtics need to win 3 out of 5 games. The probability is: P(5) = \u00124 2 \u0013 p3(1−p)2 + \u00124 1 \u0013 p4(1−p)1 +p5 = 6p3(1−p)2 +4p4(1−p)+p5 To find when n = 5 is better than n = 3, solve: P(5) > P(3) 6p3(1 −p)2 + 4p4(1 −p) + p5 > 2p2(1 −p) + p3 b Generalizing the problem to n = 2k + 1 and n = 2k −1: Let PA be the probability of winning a series of 2k + 1 games and PB be the probability of winning a series of 2k −1 games. The Celtics need to win k + 1 out of 2k + 1 games and k out of 2k −1 games. PA = 2k+1 X i=k+1 \u00122k i \u0013 pi(1 −p)2k+1−i PB = 2k−1 X i=k \u00122k −1 i \u0013 pi(1 −p)2k−1−i To determine when PA > PB, we need: PA −PB = \u0012 2k k + 1 \u0013 pk+1(1 −p)k − \u00122k −1 k \u0013 pk(1 −p)k+1 Simplify: PA −PB = (2k)! (k + 1)!(k −1)!pk+1(1 −p)k −(2k −1)! k!(k −1)!pk(1 −p)k+1 = (2k)! (k + 1)k!pk+1(1 −p)k −(2k −1)! k!(k −1)!pk(1 −p)k+1 = (2k)! k!(k + 1)!pk(1 −p)k(2p −1) Thus, n = 2k + 1 is better than n = 2k −1 if and only if p > 1 2."}
{"instruction": "In a company, there are three teams: Team A, Team B, and Team C. Each team has different success probabilities for their projects: 5 • Team A has a 70% chance of completing a project successfully. • Team B has a 60% chance of completing a project successfully. • Team C has a 50% chance of completing a project successfully. Projects are assigned to these teams with the following probabilities: • 40% of projects are assigned to Team A • 35% of projects are assigned to Team B • 25% of projects are assigned to Team C Consider a project is completed successfully. (a) What is the probability that the project was assigned to Team A given that it was completed successfully? (b) If you have two projects, what is the probability that both projects are com- pleted successfully? (c) Calculate the probability that a project assigned to Team B is not completed successfully. (d) Suppose the company has 12 projects to assign, and you want to assign exactly 5 projects to Team A, 4 to Team B, and 3 to Team C. How many different ways can you assign these projects? (e) Out of these 12 projects, how many ways can you select 6 projects such that exactly 3 are from Team A and 3 are from Team B?", "response": "(a) To find the probability that the project was assigned to Team A given that it was completed successfully, use Bayes’ Theorem: P(A | Success) = P(Success | A) · P(A) P(Success) where: P(Success) = P(Success | A)·P(A)+P(Success | B)·P(B)+P(Success | C)·P(C) Substituting the values: P(Success) = 0.70 · 0.40 + 0.60 · 0.35 + 0.50 · 0.25 P(Success) = 0.28 + 0.21 + 0.125 = 0.615 P(A | Success) = 0.70 · 0.40 0.615 = 0.28 0.615 ≈0.456 (b) If the success of each project is independent, the probability that both projects are completed successfully is: P(Both Success) = P(Success) × P(Success) Since the probabilities of success for two randomly chosen projects depend on their respective probabilities: P(Both Success) = 0.615 × 0.615 ≈0.378 6 (c) The probability that a project assigned to Team B is not completed successfully is: P(Not Success | B) = 1 −P(Success | B) P(Not Success | B) = 1 −0.60 = 0.40 (d) To assign 12 projects with 5 to Team A, 4 to Team B, and 3 to Team C, use the multinomial coefficient: 12! 5!4!3! Calculating this: 12! 5!4!3! = 479001600 120 · 24 · 6 = 27720 (e) To select 6 projects such that exactly 3 are from Team A and 3 are from Team B: \u00125 3 \u0013 × \u00124 3 \u0013 Calculating this: \u00125 3 \u0013 = 10 \u00124 3 \u0013 = 4 Total Ways = 10 × 4 = 40 7"}
{"instruction": "Let F be a σ-algebra of subsets of Ω. Show that F is closed under countable intersections T n An, under set differences (A \\ B), under symmetric differences (A∆B). Will it be closed under countable union S n An?", "response": "By the definition of σ algebra, it is closed under countable union ;-; (just asked here to confuse them a little) For countable intersection, refer to this proof; other proof could be to take Ai ∈F ∀i ∈N, and then combine them together as a basic set theory proof. For set difference, express (A\\B) as A∩BC and for symmetric difference, express (A∆B) as (A ∩BC) ∪(AC ∩B)."}
{"instruction": "Player X has $1 and Player Y has $2. They play a game in which the loser gives $1 to the winner. Player X is enough better than player Y that he wins 2 3 of the time. They play until one of them gets bankrupt. What is the probability that Player x wins ?", "response": "The game ends when one of the players has $3 and the other one has $0. At any time, Player X can have either $0, $1, $2 or $3. Let pn be probability of winning if Player X has $n. Then, p0 = 0 p3 = 1 When player X has 1, they have a probability p=2 3 of winning and 1 3 probability of losing. p1 = 1 3p0 + 2 3p2 Similarly, p2 = 1 3p1 + 2 3p3 Solving, we get p1 = 4 7"}
{"instruction": "In Problem 3, assume that all the appropriate paths are equally likely. What is the probability that the sensor located at point (10,5) receives the message? That is, what is the probability that a randomly chosen path from (0,0) to (20,10) goes through the point (10,5)?", "response": "We need to count the number of paths that pass through the point (10, 5). So, let’s break the problem into 2 variants of Problem 12. First one being: starting from point (0, 0) and reaching (10, 5) & second one: starting from point (10, 5) and reaching (20, 10). Solving both of these in the same way as Q.12, 1. Number of paths from (0, 0) to (10, 5): \u001215 5 \u0013 = 15! 5! · 10! 2. Number of paths from (10, 5) to (20, 10): \u001210 5 \u0013 = 10! 5! · 5! 2 3. Total number of paths from (0, 0) to (20, 10): \u001230 10 \u0013 = 30! 10! · 20! 4. Probability that the path goes through (10, 5): Will be the total no. of paths through (10, 5) (which is a product of 1 and 2) divided by the total paths from (0, 0) to (20, 10) P(through (10, 5)) = \u000015 5 \u0001 · \u000010 5 \u0001 \u000030 10 \u0001"}
{"instruction": "In Problem 3, given that the message has reached the node at (10, 5), find the probability of the message reaching the top-right node passing through the node at (14, 8).", "response": "To find the probability that the message reaches the node at (20, 10) passing through the node at (14, 8), given that it has already reached (10, 5), we use conditional probability. Let A be the event that the message passes through (14, 8) and let B be the event that the message has reached (10, 5). We need to find P(A | B), which is the probability of A given B. P(A | B) = P(A ∩B) P(B) To Calculate P(A ∩B): This is the probability that the message passes through both (10, 5) and (14, 8). - Number of paths from (0, 0) to (10, 5) and then from (10, 5) to (14, 8) and then from (14, 8) to (20, 10) is: \u001215 5 \u0013 × \u00127 3 \u0013 × \u00128 2 \u0013 - Total number of paths from (0, 0) to (20, 10): \u001230 10 \u0013 So, P(A ∩B) = \u000015 5 \u0001 × \u00007 3 \u0001 × \u00008 2 \u0001 \u000030 10 \u0001 To Calculate P(B): This is the probability that the message reaches (10, 5) from (0, 0) and then continues to (20, 10). P(B) = \u000015 5 \u0001 × \u000015 5 \u0001 \u000030 10 \u0001 3 Therefore, the conditional probability is: P(A | B) = (15 5 )×(7 3)×(8 2) (30 10) (15 5 )×(15 5 ) (30 10) = \u00007 3 \u0001 × \u00008 2 \u0001 \u000015 5 \u0001 Note: This can also be thought of as follows: since the signal has already reached (10, 5), the problem reduces to finding the probability that the remaining path from (10, 5) to (20, 10) passes through (14, 8). Thus, we calculate the number of ways to travel from (10, 5) to (20, 10) via (14, 8) and divide it by the total number of paths from (10, 5) to (20, 10)."}
{"instruction": "4 people are standing in a line, numbered 1,2,3,4 from left to right. A ball is initially given to 3. Each person passes the ball to their left and right neighbours with equal probability, and a person at the end always passes the ball back to their neighbour.", "response": "person wins if when they receive the ball for the first time, every other person has already received the ball atleast once. Find probability of winning for every person. A: Clearly, a person can win only if they are standing at one of the ends. ∴P(2 win) = P(3 win) = 0 Now let P(i|j) denote conditional probability of i winning, given j has the ball. By symmetry, P(1|3) = P(4|2) (1) P(4|3) = P(1|2) (2) Also, since only 1 or 4 can win, we have P(1|3) + P(4|3) = 1 (3) P(1|2) + P(4|2) = 1 (4) Since 3 initially has the ball, and can pass it to 2 or 4 with equal proba- bility, we have P(1|3) = 1 2P(1|2) + 1 2 = 1 2P(4|3) + 1 2 (from (1)) = 1 2(1 −P(1|3)) + 1 2 (from (3)) Solving, we get P(1|3) = 2 3 P(4|3) = 1 3 4"}
{"instruction": "Let X and Y be two independent N(0, 1) random variables, and define: Z = 1 + X + XY 2 W = 1 + X To find Cov(Z, W) .", "response": "We are asked to compute the covariance Cov(Z, W), where: Z = 1 + X + XY 2, W = 1 + X Using the properties of covariance: Cov(Z, W) = Cov(1 + X + XY 2, 1 + X) = Cov(X + XY 2, X) = Cov(X, X) + Cov(XY 2, X) = Var(X) + E[X2Y 2] −E[XY 2]E[X] Since X and Y are independent, we have: Var(X) = 1, E[X2] = 1, E[Y 2] = 1, E[X] = 0 Thus: Cov(Z, W) = 1 + E[X2]E[Y 2] −0 = 1 + 1 −0 = 2 Therefore, the covariance is: Cov(Z, W) = 2"}
{"instruction": "The joint density function is given as fX,Y (x, y) = cx(y −x)e−y for 0 ≤x ≤y < ∞. (a) Find c. (b) Show that: fX|Y (x|y) = 6x(y −x) y3 , 0 ≤x ≤y fY |X(y|x) = (y −x)ex−y, 0 ≤x ≤y < ∞ 1 (c) Deduce that: E(X|Y ) = Y 2", "response": "(a) Z Z x,y fX,Y (x, y)dxdy = 1 =⇒ Z y Z x fX,Y (x, y)dxdy = 1 Since x is upper bounded by y, we take the limit of x from 0 to y. And since we are initially calculating marginal pdf of fY (y), the outside integral will be from 0 to ∞as y can take all these values. Z ∞ 0 Z y 0 c · x(y −x)e−y dx dy = 1 =⇒ Z ∞ 0 c · e−y dy Z y 0 x(y −x) dx = 1 =⇒ Z ∞ 0 c · e−y \u0014yx2 2 −x3 3 \u0015y 0 dy = 1 =⇒ Z ∞ 0 c · e−y · y3 6 dy = 1 =⇒c 6 Z ∞ 0 y3e−y dy = 1 =⇒c 6[−(y3 + 3y2 + 6y + 6)e−y]∞ 0 = 1 =⇒c 6 · 6 = 1 =⇒ c = 1 (b) For conditional PDF fX|Y (x|y) = fX,Y (x, y) fY (y) = fX,Y (x, y) R x f(x, y) · dx Similarly fY |X(y|x) = f(x, y) fX(x) = f(x, y) R y f(x, y) · dy Let us first calculate all the marginal pdfs. fX(x) = Z ∞ 0 fX,Y (x, y) · dy =⇒fX(x) = Z x 0 fX,Y (x, y) · dy + Z ∞ x fX,Y (x, y) · dy 2 Since for the interval 0 ≤y ≤x does not have any density =⇒fX(x) = 0 + Z ∞ x fX,Y (x, y) · dy =⇒fX(x) = Z ∞ x x · (y −x) · e−y · dy = x · Z ∞ x (y −x) · e−y · dy = x2e−x + xe−x −x2e−x ∴fX(x) = x · e−x Now for fY (y) fY (y) = Z y 0 fX,Y (x, y) · dx =⇒fY (y) = Z y 0 x · (y −x) · e−y · dx = e−y · Z ∞ x x · (y −x) · dy = e−y · (y · y2 2 −y3 3 ) = e−y · (y3 6 ) ∴fY (y) = e−y · y3 6 Substituting the values in the formulas specified above, we will get these expressions. (c) EX[X|Y = y] = Z x x · fX|Y (x|y) · dx EX[X|Y = y] = Z y 0 x · 6x · (y −x) y3 · dx = 6 y3 · Z y 0 x2 · (y −x) · dx = 6 y3[yx3 3 −x4 4 ]y 0 = 6 y3(y4 12) = y 2 ∴EX[X|Y = y] = y 2 =⇒ EX[X|Y ] is a random variable function g(Y ) and takes the value EX[X|Y ] = Y 2 3"}
{"instruction": "You throw a fair six-sided die until you get 6. What is the expected number of throws (including the throw giving 6) conditioned on the event that all throws gave even numbers?", "response": "Let N be the random variable representing the number of throws till the first 6, and let E be the event that all throws are even. The conditional expectation is given by E[N|E] = ∞ X n=1 npN|E(n|E) The conditional pmf is given by pN|E(n|E) = P({N = n} ∩E) P(E) P({N = n} ∩E) is equivalent to the probability of rolling n −1 2s or 4s and then rolling a 6 P({N = n} ∩E) = \u00122 6 \u0013n−1 \u00121 6 \u0013 P(E) = X N P({N = n} ∩E) = ∞ X n=1 \u00122 6 \u0013n−1 \u00121 6 \u0013 = 1 4 Substituting, we get pN|E(n|E) = \u00121 3 \u0013n−1 \u00122 3 \u0013 E[N|E] = ∞ X n=1 npN|E(n|E) = ∞ X n=1 n \u00121 3 \u0013n−1 \u00122 3 \u0013 = 2 3 × 9 4 = 3 2"}
{"instruction": "Let X and Y be two independent Uniform(0, 1) random variables, and define: Z = X Y 4 (a) Find CDF of Z . (b) Find PDF of Z", "response": "Let X and Y be two independent Uniform(0, 1) random variables. We aim to find the cumulative distribution function (CDF) and probability density function (PDF) of the random variable: Z = X Y . CDF of Z: The CDF of Z is defined as: FZ(z) = P (Z ≤z) = P \u0012X Y ≤z \u0013 . Since X and Y are independent and uniformly distributed over (0, 1), we can write this as: FZ(z) = P (X ≤zY ) . We now express the probability as an integral over the possible values of Y : FZ(z) = Z 1 0 P (X ≤zy | Y = y) fY (y) dy. For X ∼Uniform(0, 1), we have P(X ≤zy) = min(1, zy), so the CDF becomes: FZ(z) = Z 1 0 min(1, zy) dy. Now, let’s evaluate the integral in two parts, based on the value of z. • If z ≤1, the integration of min(1, zy) is over zy ≤1, which simplifies to zy for y ∈[0, 1]. • If z > 1, the minimum value becomes 1 for y ∈[0, 1], so the integral is over the entire interval. Therefore, for z ≤1: FZ(z) = Z 1 0 zy dy = z 2. For z > 1: FZ(z) = Z 1/z 0 zy dy + Z 1 1/z 1 dy = 1 2z + \u0012 1 −1 z \u0013 . 5 Thus, the CDF of Z is: FZ(z) = ( z 2, if z ≤1, 1 −1 2z, if z > 1. PDF of Z: To find the PDF of Z, we differentiate the CDF: fZ(z) = d dzFZ(z). For z ≤1: fZ(z) = d dz \u0010z 2 \u0011 = 1 2. For z > 1: fZ(z) = d dz \u0012 1 −1 2z \u0013 = 1 2z2. Thus, the PDF of Z is: fZ(z) = ( 1 2, if z ≤1, 1 2z2, if z > 1."}
{"instruction": "Let X, Y , and Z be discrete random variables. Show the following generalizations of the law of iterated expectations. (a) E[Z] = E [E[Z | X, Y ]]. (b) E[Z | X] = E [E[Z | X, Y ] | X].", "response": "(a) To prove: E[Z] = E [E[Z | X, Y ]] By the law of iterated expectation, the expectation of Z can be com- puted by first conditioning on both X and Y , and then taking the expectation: E[Z] = X x X y P(X = x, Y = y)E[Z | X = x, Y = y] Since E[Z | X = x, Y = y] is the conditional expectation, it is weighted by the joint probability P(X = x, Y = y), and taking the overall expectation gives us the desired result: E[Z] = E [E[Z | X, Y ]] 6 (b) To prove: E[Z | X] = E [E[Z | X, Y ] | X] By the law of iterated expectation applied conditionally on X, we condition on both X and Y , and then take the expectation over Y , given X: E[Z | X = x] = X y P(Y = y | X = x)E[Z | X = x, Y = y] This shows that the conditional expectation of Z, given X, can be written as the expectation of the conditional expectation of Z given X and Y , with respect to Y conditioned on X. Hence, we conclude: E[Z | X] = E [E[Z | X, Y ] | X]"}
{"instruction": "If X and Y are arbitrary random variables for which the necessary expectations and variances exist, then prove that Var(Y ) = E[VarX(Y |X)] + Var[EX(Y |X)].", "response": "We know that Var[Y ] = E[Y 2] −(E[Y ])2 Applying law of iterated expectation with rv X on RHS above, we get Var[Y ] = EX[EY [Y 2|X]] −(EX[EY [Y |X]])2 We define conditional variance Var[Y |X] as VarY [Y |X = x] = EY [Y 2|X = x] −(EY [Y |X = x])2 Note that VarY [Y |X] is also a random variable function in X. So we can substitute the value of EY [Y 2|X] from the above equation as: Var[Y ] = EX[VarY [Y |X] + (EY [Y |X])2] −(EX[EY [Y |X]])2 =⇒Var[Y ] = EX[VarY [Y |X]] + EX[(EY [Y |X])2] −(EX[EY [Y |X]])2 Let’s define a random variable Z = EY [Y |X]. Then we can write the above expression as: =⇒Var[Y ] = EX[VarY [Y |X]] + E[Z2] −(E[Z])2 =⇒Var[Y ] = EX[VarY [Y |X]] + Var[Z] by definition of Variance. Substituting the value of Z we get Var[Y ] = EX[VarY [Y |X]] + VarX[EY [Y |X]]"}
{"instruction": "Consider a gambler who at each gamble either wins or loses his bet with probabilities p and 1 −p, independent of earlier gambles. When p > 1 2, a popular gambling system, known as the Kelly strategy, is to always bet the fraction 2p −1 of the current fortune. Compute the expected fortune after n gambles, starting with x units and employing the Kelly strategy. 7", "response": "If the gambler’s fortune at the beginning of a round is a, the gambler bets a(2p −1). He therefore gains a(2p −1) with probability p, and loses a(2p −1) with probability 1 −p. Thus, his expected fortune at the end of a round is: a (1 + p(2p −1) −(1 −p)(2p −1)) = a \u00001 + (2p −1)2\u0001 Let Xk be the fortune after the kth round. Using the preceding calcula- tion, we have : E[Xk+1|Xk] = (1 + (2p −1)2)Xk Taking expectation and using law of iterated expectations, we obtain : E[Xk+1] = (1 + (2p −1)2)E[Xk] and E[X1] = (1 + (2p −1)2)x So, we conclude that : E[Xn] = (1 + (2p −1)2)nx"}
{"instruction": "There are n letters and n envelopes. You put the letters randomly in the envelopes so that each letter is in one envelope. (Effectively a random permutation of n numbers chosen uniformly). Calculate the expected number of envelopes with the correct letter inside them.", "response": "Let Xi be the indicator random variable such that: Xi = ( 1 if the ith letter ends up in the ith envelope, 0 otherwise. The expected value of Xi is: E[Xi] = P(Xi = 1) = 1 n for any i. Let X be the number of letters that end up in their respective envelopes. Then, X = X1 + X2 + · · · + Xn. The expected value of X is: E[X] = E \" n X i=1 Xi # Using the linearity of expectation, we have: E[X] = n X i=1 E[Xi] 8 Since E[Xi] = 1 n for each i, we get: E[X] = n X i=1 1 n = n n = 1. Therefore, we expect on average one letter to be in the correct envelope. 9"}
{"instruction": "During each day, the probability that an athlete misses training due to illness is 5%, independent of every other day. Find the probability that the athlete will attend training on at least 45 out of the next 50 days using the Central Limit Theorem (CLT) and otherwise.[Gopal]", "response": "Let Xi be a Bernoulli random variable that equals 1 if the athlete attends training on day i, and 0 otherwise. The probability of attending training on a single day is: P(attend) = 1 −P(miss) = 1 −0.05 = 0.95 Thus, Xi ∼Bernoulli(0.95). We are interested in the total number of training days attended over the next 50 days, Y = X1 + X2 + · · · + X50. Since Y is a sum of independent Bernoulli random variables, it follows a binomial distribution: Y ∼Binomial(50, 0.95) We are asked to find: P(Y ≥45) Using Exact Binomial Distribution The exact probability can be calculated by summing up the binomial probabilities from 45 to 50. The probability mass function for a binomial random variable is: P(Y = k) = \u001250 k \u0013 (0.95)k(0.05)50−k However, calculating this exactly can be tedious, so we proceed with an approxi- mation using the Central Limit Theorem. 1 Using Central Limit Theorem (CLT) By the Central Limit Theorem, for large n, a binomial distribution can be approx- imated by a normal distribution: Y ∼N(µ, σ2) where the mean µ and variance σ2 are given by: µ = np = 50 × 0.95 = 47.5 σ2 = np(1 −p) = 50 × 0.95 × 0.05 = 2.375 σ = √ 2.375 ≈1.541 We want to find P(Y ≥45). Using the normal approximation: P(Y ≥45) ≈P \u0012 Z ≥45 −47.5 1.541 \u0013 = P \u0012 Z ≥−2.5 1.541 \u0013 = P(Z ≥−1.622) Using the standard normal table: P(Z ≥−1.622) ≈0.947 Thus, the probability that the athlete will attend training on at least 45 out of the next 50 days is approximately 94.7% using the CLT approximation."}
{"instruction": "The quadratic form of a random vector X is given by XTAX. Find the expectation of the quadratic form. [Kavin]", "response": "Since XTAX is a scalar E[XTAX] = E[tr(XTAX)] Using the property of the trace operator E[tr(XTAX)] = E[tr(AXXT)] We can interchange the expectation and trace operators E[tr(AXXT)] = tr(AE[XXT]) We know that E[XXT] = Σ + µµT E[XTAX] = tr(A[Σ + µµT]) = tr(AΣ) + tr(AµµT)]) = tr(AΣ) + tr(µTAµ)]) = µTAµ + tr(AΣ) 3"}
{"instruction": "Using the central limit theorem show that lim n→∞e−n n X k=0 nk k! = 1 2 Hint: Let Sn be Poisson with mean n. Use the central limit theorem to show that P{Sn ≤n} →1 2.", "response": "Let X1, X2, . . . i.i.d. with Xi ∼Poisson(1). Then µ = E[Xi] = 1 = Var[Xi] = σ2. Further let Sn = X1 + · · · + Xn, thus Sn ∼Poisson(n). e−n n X k=0 nk k! = n X k=0 e−nnk k! = n X k=0 Pr(Sn = k) = Pr(Sn ≤n) = Pr \u0014Sn −nµ σ√n ≤n −nµ σ√n \u0015 = Pr \u0014Sn −nµ √n ≤0 \u0015 Using the central limit theorem, we approximate Sn−nµ √n with N(0, 1), so Pr \u0014Sn −nµ √n ≤0 \u0015 = 1 2"}
{"instruction": "Let X = [X1, X2]T be a two-dimensional zero-mean Gaussian random vector with covariance matrix C given by: C = \u00141 r r 2 \u0015 1. Give an expression for fX2(x2). 2. Determine the conditional pdf, conditional mean, and conditional variance of X1 given X2 = x2.", "response": "1. Marginal Distribution of X2 We are given that the random vector X follows a multivariate Gaussian distribu- tion with mean zero and covariance matrix C. The marginal distribution of X2 is 4 also Gaussian, with mean 0 and variance given by the corresponding entry in the covariance matrix. Therefore: X2 ∼N(0, 2) The marginal pdf of X2 is: fX2(x2) = 1 √ 2π · 2 exp \u0012 −x2 2 2 · 2 \u0013 = 1 √ 4π exp \u0012 −x2 2 4 \u0013 2. Conditional Distribution of X1 Given X2 = x2 The conditional distribution of X1 given X2 = x2 for a multivariate Gaussian dis- tribution can be derived using the following properties of conditional distributions: For a bivariate normal distribution, the conditional distribution of one variable given the other is still a normal distribution X1|(X2 = x2 ∼N) \u0000µX1|X2, σ2 X1|X2 \u0001 where: - The conditional mean is given by: µX1|X2 = E[X1|X2 = x2] = Cov(X1, X2) Var(X2) x2 = r 2x2 - The conditional variance is: σ2 X1|X2 = Var(X1|X2) = Var(X1) −Cov2(X1, X2) Var(X2) = 1 −r2 2 Thus, the conditional pdf of X1 given X2 = x2 is: fX1|X2(x1|x2) = 1"}
{"instruction": "You are given the random vector Y ′ = [Y1, Y2, Y3, Y4] with mean vector µY = [5, −1, 4, −3] 5 and variance-covariance matrix ΣY =   4 0 0 0 0 5 0 0 0 0 4 0 0 0 0 5  . Let B =   2 −1 0 1 −1 2 −1 0 0 1 1 −2  . (a) Find E(BY ), the mean of BY . (b) Find Cov(BY ), the variances and covariances of BY . (c) Which pairs of linear combinations have zero covariances?", "response": "Consider the (4 × 1)-dimensional random vector y =   Y1 Y2 Y3 Y4  , whereby µY = E(Y ) =   E(Y1) E(Y2) E(Y3) E(Y4)  =   µ1 µ2 µ3 µ4  =   5 −1 4 −3   and ΣY = Cov(Y ) =   σ11 σ12 σ13 σ14 σ21 σ22 σ23 σ24 σ31 σ32 σ33 σ34 σ41 σ42 σ43 σ44  =   4 0 0 0 0 5 0 0 0 0 4 0 0 0 0 5  . Let B =   2 −1 0 1 −1 2 −1 0 0 1 1 −2  . So, E(BY ) = BµY and Cov(BY ) = BΣY B′. Hence, (a) E(BY ) =   2 −1 0 1 −1 2 −1 0 0 1 1 −2     5 −1 4 −3  =   16 9 1  . 6 (b) Cov(BY ) =   2 −1 0 1 −1 2 −1 0 0 1 1 −2     4 0 0 0 0 5 0 0 0 0 4 0 0 0 0 5     2 −1 0 −1 2 1 0 −1 1 1 0 −2  . Calculating this yields: Cov(BY ) =   21 −6 −10 −6 13 8 −10 8 21  . (c) Define Z = BY =   Z1 Z2 Z3  , where Z1 = 2Y1 −Y2 + Y4, Z2 = −Y1 + 2Y2 −Y3, Z3 = Y2 + Y3 −2Y4. Then, clearly, Cov(BY ) = ΣZ, and therefore, according to (b), Cov(Zi, Zj) = 0 for i ̸= j, where i, j = 1, 2, 3. 7"}
{"instruction": "Let A and B be two independent Poisson random variables with parameters a and b respectively. Let C = A + B. Using MGF, show that C is also a Poisson random variable.", "response": "First, let’s derive the MGF of a Poisson random variable X with parameter λ. Given the probability mass function of Poisson distribution: P(X = n) = λne−λ n! , n = 0, 1, 2, ... The moment generating function is defined as: MX(t) = E(etX) = ∞ X n=0 etnP(X = n) = ∞ X n=0 etn λne−λ n! = e−λ ∞ X n=0 (λet)n n! = e−λeλet (using power series expansion of ex) = eλ(et−1), −∞< t < ∞ Clearly, the MGF for the Poisson distribution converges for all real values of t. Therefore, the ROC is t ∈(−∞, ∞). Using the above derivation: (since, A ∼Poisson(a) and B ∼Poisson(b)) MA(t) = ea(et−1) MB(t) = eb(et−1) where, −∞< t < ∞ 1 Derivation of MGF of C can be done in any one of the following ways: Method 1: MC(t) = MA(t) · MB(t) (MGF of sum of independent random variables, A and B) = ea(et−1) · eb(et−1) = e(a+b)(et−1), −∞< t < ∞ Method 2: MC(t) = E[et(A+B)] = ∞ X m=0 ∞ X n=0 et(m+n)P(A = m, B = n) = ∞ X m=0 ∞ X n=0 et(m+n)P(A = m)P(B = n) (Since A and B are independent) = ∞ X m=0 ∞ X n=0 et(m+n) ame−a m! bne−b n! = e−(a+b) ∞ X m=0 ∞ X n=0 (aet)m m! (bet)n n! = e−(a+b)(eaet)(ebet) (using power series expansion of ex) = e(a+b)(et−1) Method 3: MC(t) = E[et(A+B)] = E[etAetB] = E[etA]E[etB] (Since A and B are independent) = MA(t) · MB(t) = ea(et−1)eb(et−1) = e(a+b)(et−1) This is the MGF of a Poisson distribution with parameter (a+b). Since moment generating functions uniquely determine distributions, we can conclude that: C = A + B ∼Poisson(a + b) Therefore, the sum of two independent Poisson random variables with pa- rameters a and b is a Poisson random variable with parameter (a+b). Marking Scheme: • Correct derivation of MGF of Poisson distribution [1.5 marks] – Setting up MGF definition correctly: MX(t) = E(etX) = P∞ n=0 etnP(X = n) [0.5 marks]; getting final form eλ(et−1) [1 mark] • Correct derivation of MGF of C [2 marks for any one method] 2 – Method 1: Applying property of MGF for sum of independent vari- ables [1 mark] and getting final expression MC(t) = e(a+b)(et−1) [1 mark] – Method 2: Setting up double sum E[et(A+B)] [0.5 marks], using independence to split probabilities [0.5 marks] and final simplification to e(a+b)(et−1) [1 mark] – Method 3: Using independence to get E[etA]E[etB] [1 mark] and substituting MGFs and simplifying to e(a+b)(et−1) [1 mark] • Recognition that e(a+b)(et−1) is MGF of Poisson(a+b) [0.5 marks], stating uniqueness property of MGF [0.5 marks], and concluding C ∼Poisson(a+ b) [0.5 marks] 1.2"}
{"instruction": "Derive an expression for the kth moment of an exponential random variable with parameter λ using MGF.", "response": "Let X be an exponential random variable with rate parameter λ. The prob- ability density function (PDF) of X is given by: fX(x) = λe−λx, x ≥0 The moment generating function MX(t) of X is: MX(t) = E[etX] MX(t) = Z ∞ 0 etxλe−λx dx MX(t) = λ Z ∞ 0 e−(λ−t)x dx For λ > t, this integral evaluates to: MX(t) = λ λ −t, t < λ The k-th moment of X, denoted by E[Xk], can be obtained by differentiating the MGF MX(t) k times with respect to t and then evaluating the result at t = 0: E[Xk] = dk dtk MX(t) t=0 We have: MX(t) = λ λ −t 3 Now, differentiate this expression k times: • First derivative: d dtMX(t) = λ (λ −t)2 • Second derivative: d2 dt2 MX(t) = 2λ (λ −t)3 • In general, the k-th derivative is: dk dtk MX(t) = k!λ (λ −t)k+1 Evaluating this at t = 0, we get: E[Xk] = k!λ (λ −t)k+1 t=0 = k! λk Thus, the k-th moment of an exponential random variable with rate param- eter λ is: E[Xk] = k! λk Marking Scheme: • Correct MGF - 1.5 Mark • Correct ROC t < λ - 1 Mark • Correct kth moment - 2.5 marks (1.5 marks for steps + 1 mark for final expression) • No marks for deriving without the use of MGF 1.3"}
{"instruction": "Let X1, X2, . . . , Xn be independent and identically distributed (i.i.d.) random variables, where Xi ∼Uniform(−1, 1). Define the sequence of random variables: Yn = Xn n Show that Yn converges in probability to a limit, and identify the limit.", "response": "We are given that X1, X2, . . . , Xn are i.i.d. random variables, where Xi ∼Uniform(−1, 1). We need to investigate the convergence of Yn = Xn n as n →∞. Since Xn ∼Uniform(−1, 1), the random variable Xn takes values in the interval [−1, 1]. Hence, for any n, Yn = Xn n is bounded by: 4 −1 n ≤Yn ≤1 n. As n →∞, the bounds 1 n and −1 n both converge to 0. This suggests that Yn becomes arbitrarily close to 0 as n grows. So, the limit is 0. To show that Yn converges in probability to 0, we need to prove that for every ϵ > 0: lim n→∞P(|Yn −0| ≥ϵ) = 0. This is equivalent to: P(|Yn| ≥ϵ) = P(Yn ≥ϵ) + P(Yn ≤−ϵ). Here, the random variable Yn = Xn n P(|Xn| ≥nϵ) = P(Xn ≥nϵ) + P(Xn ≤−nϵ). So WLOG for some ϵ there exists two cases : Case 1: nϵ > 1 , Case 2: nϵ ≤1 because Xn is a uniform random variable whose realisations can lie in the interval (-1,1) Case 1: n > 1 ϵ For this case, we compute the probability: P(|Xn| ≥nϵ) = P(Xn ≥nϵ) + P(Xn ≤−nϵ). Since nϵ > 1, and we know that |Xn| ≤1 always holds (since Xn ∈[−1, 1]), and hence: P(Xn ≥nϵ) = 0. and similarly, P(Xn ≤−nϵ) = 0. Thus, for any n > 1 ϵ , we have: P(|Yn| ≥ϵ) = 0. Case 2: n ≤1 ϵ For this case, again we start with the probability: P(|Xn| ≥nϵ) = P(Xn ≥nϵ) + P(Xn ≤−nϵ). Here, the random variable Xn lies between −1 and 1. However, when nϵ ≤1, it is possible that Xn lies between nϵ and 1, or between −1 and −nϵ. Since Xn ∼Uniform(−1, 1), we have: 5 P(Xn ≥nϵ) = 1 −nϵ 2 , for nϵ ≤1. Similarly, P(Xn ≤−nϵ) = 1 −nϵ 2 , for nϵ ≤1. Thus, the total probability is: P(|Yn| ≥ϵ) = 1 −nϵ 2 + 1 −nϵ 2 = 1 −nϵ, for nϵ ≤1. So on combining the cases, for an ϵ, we get, P(|Yn| ≥ϵ) = ( 1 −nϵ if 0 ≤n ≤1/ϵ, 0 if n > 1/ϵ. For sufficiently large n (n →∞), n will be greater than any fixed k = 1/ϵ where ϵ > 0 . Hence we have, lim n→∞P(|Yn| ≥ϵ) = 0. Therefore, Yn p−→0 . Marking Scheme: • 2 marks for finding the limit • 3 marks for proving convergence in probability. • Any other valid method will be considered and given marks appropriately 1.4"}
{"instruction": "Let X1, X2, . . . be a sequence of random variables such that: FXn(x) = en(x−1) 1 + en(x−1) for x > 0. Show that Xn converges in distribution. Identify the limiting random vari- able.", "response": "A sequence of random variables X1, X2, . . . converges in distribution to a random variable X, denoted by: Xn d−→X, if: 6 lim n→∞FXn(x) = FX(x) for all x where FX(x) is continuous. We do not require the CDF to converge at points where FX(x) is discontin- uous. Case 1: x < 1 For x < 1, as n →∞, n(x −1) →−∞. Therefore: lim n→∞FXn(x) = lim n→∞ en(x−1) 1 + en(x−1) = 0 1 + 0 = 0. Thus: lim n→∞FXn(x) = 0. Case 2: x > 1 For x > 1, as n →∞, n(x −1) →∞. Therefore: lim n→∞FXn(x) = lim n→∞ 1 1 + e−n(x−1) = 1 1 + 0 = 1. Thus: lim n→∞FXn(x) = 1. Case 3: x = 1 At x = 1, the CDF value for each n is: lim n→∞FXn(1) = en(1−1) 1 + en(1−1) = 1 2. We should define the limiting CDF FX(x) from limn→∞FXn(x) such that: FX(x) = lim n→∞FXn(x) for all x where FX(x) is continuous. So, FX(x) = lim n→∞FXn(x) for x ̸= 1. Since directly assigning the value limn→∞FXn(1) would violate the right- continuous property of CDFs, we instead assign: 7 FX(1) = 1 for x = 1, to ensure FX(x) is a valid CDF. Conclusion: The limiting CDF FX(x) is given by: FX(x) = ( 0 for x < 1, 1 for x ≥1. This corresponds to a constant random variable equal to 1. Therefore: Xn d−→1 Marking Scheme: • 2 marks for correctly determining the limiting CDF for x < 1. • 2 marks for correctly determining the limiting CDF for x > 1. • 1 mark for correctly identifying the limiting random variable. 2 10-Marks Questions 2.1"}
{"instruction": "Given samples x1, . . . xn from an exponential random variable X with parameter λ, convert it into samples from another exponential random variable with parameter µ. Explain the procedure in detail with justifications", "response": "The solution involves 2 steps: • Sampling a uniform U[0, 1] random variable from X. This involves con- verting samples of X - x1 . . . xn to samples of U- u1 . . . un • Sampling Y from U[0, 1]. This involves converting samples of U - u1 . . . un to samples of Y - y1 . . . yn Sampling U[0, 1] from X Let ˆU = FX(X). Then the cdf of ˆU is FU(.) Proof: 8 The CDF of ˆU is given by F ˆU(u) = P[ ˆU ≤u] = P[FX(X) ≤u] = P[X ≤F −1 X (u)] = FX(F −1 X (u)) = u = FU(u) The cdf of X ∼exp(λ) is given by FX(x) = 1 −e−λx =⇒ˆU = FX(X) = 1 −e−λX We can convert samples of X to samples of U ui = 1 −e−λxi, i = 1 . . . n Sampling Y from ˆU Now using the samples of ˆU, we generate samples of Y using inverse transform sampling Let ˆY = F −1 Y ( ˆU). Then the cdf of ˆY is FY (.) Proof: F ˆY (y) = P[ ˆY ≤y] = P[F −1 Y ( ˆU) ≤y] = P[ ˆU ≤FY (y)] = F ˆU(FY (y)) = FY (y) since 0 ≤FY (y) ≤1, The CDF of Y ∼exp(µ) is given by FY (y) = 1 −e−µy =⇒F −1 Y (y) = −1 µ ln(1 −y) 9 ˆY = F −1 Y ( ˆU) = −1 µ ln(1 −ˆU) = −1 µ ln(1 −(1 −e−λX)) = −1 µ ln(e−λX) = λ µX We can convert samples of X : x1 . . . xn to samples of Y yi = −1 µ ln(1 −ui) =⇒yi = λ µxi, i = 1 . . . n Marking Scheme: • Correct proof for ˆU - 2.5 marks • Correct formula for ˆU - 2.5 marks • Correct proof for ˆY -2.5 marks • Correct formula for ˆY - 2.5 marks • Marks will also be awarded for accept reject method 10"}
{"instruction": "Forty nine measurements are recorded to several decimal places. Each of these 49 numbers is rounded off to the nearest integer. The sum of the original 49 numbers is approximated by the sum of those integers. Assume that the errors made in rounding off are independent, identically distributed random variables with a uniform distribution over the interval (−0.5, 0.5). Compute approximately the probability that the sum of the integers is within two units of the true sum.", "response": "Let X1, X2, ..., Xn, where n = 49, denote the 49 measurements, and Y1, Y2, ..., Yn be the corresponding nearest integers after rounding off. Then Xi = Yi + Ui for i = 1, 2, ..., n, where U1, U2, ..., Un are independent identically distributed uniform ran- dom variables on the interval (−0.5, 0.5). We then have that for all i, E(Ui) = 0 for all i, and Var(Ui) = σ2 = 1 12. The sum, S, of the original measurements is S = n X i=1 Yi + n X i=1 Ui, where Pn i=1 Yi is the sum of the integer approximations. Let the difference W = S − n X i=1 Yi = n X i=1 Ui. We would like to estimate Pr(|W| ≤2). We will do this by applying the Central Limit Theorem to U1, U2, U3, . . .. Observe that W = nU n, where U n is the sample mean of the rounding off values U1, U2, . . . , Un. By the Central Limit Theorem Pr \u0012 U n σ/√n ≤z \u0013 ≈Pr(Z ≤z), for all z ∈R, where Z ∼Normal(0, 1). We therefore get that, for z > 0, Pr \u0012 |U n| σ/√n ≤z \u0013 ≈Pr(|Z| ≤z), It then follows that 1 Pr(|W| ≤2) = Pr(|U n| ≤2/n) = Pr \u0012 |U n| σ/√n ≤ 2 σ√n \u0013 ≈Pr \u0012 |Z| ≤ 2 σ√n \u0013 = 2FZ \u0012 2 σ√n \u0013 −1 = 2FZ 4 √ 3 √ 49 ! −1 ≈2FZ(0.99) −1 ≈2(0.8389) −1 ≈0.6778,"}
{"instruction": "Let X1 be a uniform random variable with support RX1 = [1, 2] and probability density function fX1(x1) = ( 1 if x1 ∈RX1 0 if x1 /∈RX1 Let X2 be a continuous random variable, independent of X1, with support RX2 = [0, 2] and probability density function fX2(x2) = ( 3 8x2 2 if x2 ∈RX2 0 if x2 /∈RX2 Let Y = \u0014Y1 Y2 \u0015 = \u0014 X2 1 X1 + X2 \u0015 Find the joint probability density function of the random vector Y.", "response": "Since X1 and X2 are independent, their joint probability density function is equal to the product of their marginal density functions: fX1,X2(x1, x2) = fX1(x1)fX2(x2) = ( 3 8x2 2 if x1 ∈[1, 2] and x2 ∈[0, 2] 0 otherwise The support of Y1 is RY1 = [1, 4] and the support of Y2 is RY2 = [1, 4]. The support of Y is RY = {(y1, y2) : y1 ∈[1, 4], y2 ∈[√y1, 4]} The function y = g(x) is one-to-one and its inverse g−1(y) is defined by x1 = √y1 x2 = y2 −√y1 with Jacobian matrix Jg−1(y) = \" ∂x1 ∂y1 ∂x1 ∂y2 ∂x2 ∂y1 ∂x2 ∂y2 # = \" 1 2y −1 2 1 0 −1 2y −1 2 1 1 # 2 The determinant of the Jacobian matrix is det(Jg−1(y)) = 1 2√y1 · 1 −0 · (− 1 2√y1 ) = 1 2√y1 which is greater than zero for any y belonging to RY . The formula for the joint probability density function of Y is fY(y) = ( fX(g−1(y))| det(Jg−1(y))| if y ∈RY 0 if y /∈RY and fX(g−1(y))| det(Jg−1(y))| = fX1(x1)fX2(x2) · 1 2√y1 = 3 8x2 2 · 1 2√y1 = 3 16(y2 −√y1)2 1 √y1 = ( 3 16(y2 −√y1)2 1 √y1 if y1 ∈[1, 4] and y2 ∈[√y1, 4] 0 otherwise ."}
{"instruction": "Let x = \u0014x1 x2 \u0015 belong to a bivariate normal distribution N \u0012\u0014µ1 µ2 \u0015 , \u0014Σ11 Σ12 Σ21 Σ22 \u0015\u0013 . Show that x1|x2 ∼N(µ1|2, Σ1|2) where µ1|2 = µ1 + Σ12Σ−1 22 (x2 −µ2) Σ1|2 = Σ11 −Σ12Σ−1 22 Σ21", "response": "The marginal distribution of x2 is given by N(µ2, Σ2). Using condi- tional probability p(x1|x2) = N(x; µ, Σ) N(x2; µ2, Σ22) = p(x1|x2) = 1 2π√ |Σ| exp \u0002 −1 2(x −µ)TΣ−1(x −µ) \u0003 1 √ (2π)Σ22 exp h −1 2 (x2−µ2)2 Σ22 i = 1 p (2π)|Σ11| · p |Σ22| p |Σ| exp \u0014 −1 2(x −µ)TΣ−1(x −µ) + 1 2 (x2 −µ2)2 Σ22 \u0015 = 1 p (2π)|Σ11| · p |Σ22| p |Σ| exp \" −1 2 \u0014x1 −µ1 x2 −µ2 \u0015T Σ−1 \u0014x1 −µ1 x2 −µ2 \u0015 + 1 2 (x2 −µ2)2 Σ22 # 4 For a 2x2 matrix A = \u0014a b c d \u0015 the inverse is given by A−1 = 1 |A| \u0014 d −b −c a \u0015 Using this and expanding p(x1|x2) = 1 p (2π)|Σ11| · p |Σ22| p |Σ| exp \u0014 −1 2|Σ| \u0000Σ11(x2 −µ2)2 + 2Σ12(x2 −µ2)(x1 −µ1) + Σ22(x1 −µ1)2\u0001 + 1 2 (x2 −µ2)2 Σ22 \u0015 = 1 p (2π)|Σ11| · p |Σ22| p |Σ| exp \u0014 − 1 2|Σ|Σ22 \u0000Σ2 12(x2 −µ2)2 −2Σ12Σ22(x2 −µ2)(x1 −µ1) + Σ2 22(x1 −µ1)2\u0001\u0015 = 1 p (2π)|Σ11| · p |Σ22| p |Σ| exp \u0014 − 1 2|Σ|Σ22 \u0000Σ22(x1 −µ1) −Σ12(x2 −µ2) \u00012 \u0015 = 1 p (2π)|Σ11| · p |Σ22| p |Σ| exp \u0014 −Σ22 2|Σ| \u0000x1 −µ1 −Σ12 Σ22 (x2 −µ2) \u00012 \u0015 = 1 p (2π)|Σ11| · p |Σ22| p |Σ| exp \u0014 −1 2 \u0012x1 −(µ1 −Σ12Σ−1 22 (x2 −µ2)) p Σ11 −Σ12Σ−1 22 Σ12 \u00132\u0015 Thus the mean and variance are µ1|2 = µ1 + Σ12Σ−1 22 (x2 −µ2) Σ1|2 = Σ11 −Σ12Σ−1 22 Σ21"}
{"instruction": "X and Y are said to be bivariate normal if aX + bY is normal for all a and b. If X and Y are bivariate normal with 0 mean, variance of 1, and ρ correlation, then their joint pdf is: f(x, y) = 1 2π p 1 −ρ2 exp \u0012 − 1 2(1 −ρ2) \u0000x2 −2ρxy + y2\u0001\u0013 Find the joint pdf of X + Y and X −Y .", "response": "Let U = X + Y and V = X −Y . Since X and Y are bivariate normal with means 0, variances 1, and correlation ρ, the joint distribution of (X, Y ) is: f(x, y) = 1 2π p 1 −ρ2 exp \u0012 − 1 2(1 −ρ2) \u0000x2 −2ρxy + y2\u0001\u0013 Step 1: Define the Transformation We define the transformation: U = X + Y and V = X −Y 5 Step 2: Find the Inverse Transformation Solving for X and Y in terms of U and V : X = U + V 2 and Y = U −V 2 Step 3: Calculate the Jacobian The Jacobian of the transformation from (X, Y ) to (U, V ) is: J = ∂X ∂U ∂X ∂V ∂Y ∂U ∂Y ∂V = 1 2 1 2 1 2 −1 2 = −1 2 Thus, |J| = 1 2. Step 4: Distribution of U and V Since X and Y are jointly normal with variances 1 and correlation ρ, we can derive the variances and covariance of U and V : Var(U) = Var(X+Y ) = Var(X)+Var(Y )+2 Cov(X, Y ) = 1+1+2ρ = 2(1+ρ) Var(V ) = Var(X−Y ) = Var(X)+Var(Y )−2 Cov(X, Y ) = 1+1−2ρ = 2(1−ρ) Cov(U, V ) = Cov(X + Y, X −Y ) = Var(X) −Var(Y ) = 0 Therefore, U and V are independent with variances 2(1+ρ) and 2(1−ρ), respectively. Step 5: Joint pdf of U and V Since U and V are independent, their joint pdf is the product of their marginal pdfs: fU,V (u, v) = fU(u)fV (v) where fU(u) = 1 p 4π(1 + ρ) exp \u0012 − u2 4(1 + ρ) \u0013 and fV (v) = 1 p 4π(1 −ρ) exp \u0012 − v2 4(1 −ρ) \u0013 Thus, the joint pdf of U = X + Y and V = X −Y is: fU,V (u, v) = 1 4π p (1 + ρ)(1 −ρ) exp \u0012 − u2 4(1 + ρ) − v2 4(1 −ρ) \u0013"}
{"instruction": "Let Z = [Z1, Z2]T be a normal random vector with the following mean and covari- ance matrices: m = \u00143 5 \u0015 , C = \u00145 2 2 3 \u0015 . Let also: 6", "response": "=   1 0 2 3 4 1  , b =   1 2 −1  , W =   W1 W2 W3  = AZ + b. Answer the following: 1. Find P(Z2 > 1). 2. Find the expected value vector of W, denoted as mW = E[W]. 3. Find the covariance matrix of W, denoted as CW. 4. Find P(W3 ≤4). Solution 1. Finding P(Z2 > 1) We are given that Z2 is part of a bivariate normal distribution. The marginal distribution of Z2 is: Z2 ∼N(5, 3) Thus, we need to find P(Z2 > 1). This is equivalent to calculating: P(Z2 > 1) = 1 −P(Z2 ≤1) We standardize Z2 by using the formula: P(Z2 ≤1) = P \u0012Z2 −5 √ 3 ≤1 −5 √ 3 \u0013 = P \u0012 Z′ ≤−4 √ 3 \u0013 Using the standard normal table: P \u0012 Z′ ≤−4 √ 3 \u0013 ≈P(Z′ ≤−2.309) ≈0.0105 Thus, P(Z2 > 1) = 1 −0.0105 = 0.9895 2. Expected Value of W The transformation of Z to W involves a linear transformation: W = AZ + b The expected value of W is given by: mW = E[W] = AE[Z] + b = Am + b 7 Substituting the values of A, m, and b: mW =   1 0 2 3 4 1   \u00143 5 \u0015 +   1 2 −1   mW =   1 · 3 + 0 · 5 2 · 3 + 3 · 5 4 · 3 + 1 · 5  +   1 2 −1  =   3 21 17  +   1 2 −1   mW =   4 23 16   Thus, the expected value vector of W is: mW =   4 23 16   3. Covariance Matrix of W The covariance matrix of W is given by: CW = ACZAT where CZ is the covariance matrix of Z. Substituting the values of A and CZ: CW =   1 0 2 3 4 1   \u00145 2 2 3 \u0015 \u00141 2 4 0 3 1 \u0015 First, compute ACZ: ACZ =   1 0 2 3 4 1   \u00145 2 2 3 \u0015 =   5 2 16 13 22 11   Now compute the product with AT: CW =   5 2 16 13 22 11   \u00141 2 4 0 3 1 \u0015 =   5 11 21 16 67 89 22 85 129   Thus, the covariance matrix of W is: CW =   5 11 21 16 67 89 22 85 129   8 4. Finding P(W3 ≤4) Since W3 is a linear combination of normal variables, it is normally distributed with mean µW3 = 16 and variance σ2 W3 = 129. We need to find P(W3 ≤4). Standardize W3: P(W3 ≤4) = P \u0012W3 −16 √ 129 ≤4 −16 √ 129 \u0013 = P \u0012 Z ≤−12 √ 129 \u0013 Using the standard normal table: P (Z ≤−1.056) ≈0.1451 Thus, P(W3 ≤4) ≈0.1451. 9"}
{"instruction": "Suppose a student scores exactly 100 marks across three subjects, with the marks in each subject represented by s1, s2, and s3. Find the number of distinct ways the student can achieve this, given that at least one subject has a passing mark, defined as more than 40 marks (si > 40 for at least one i). The marks in each subject are non-negative integers.", "response": "We need to find the number of solutions to the equation s1 +s2 +s3 = 59 where at least one of the variables si ≥41 (let’s assume s1 ≥41). This problem is equivalent to finding the number of solutions to s′ 1 +s2 + s3 = 59, where s′ 1 = s1 −41 and s′ 1 ≥0. The number of solutions to this equation is given by 61C2 (using the ”stars and bars” method, where n+r−1 is the total number of units plus dividers, and r−1 is the number of dividers). Since si ≥41 can apply to any one of the three variables s1, s2, or s3, we need to multiply this result by 3. However, this counts cases where two variables are greater than or equal to 41 more than once. So, we need to subtract double-counted solutions. Let’s assume s1 ≥41 and s2 ≥41. This is equivalent to finding the number of solutions to s′ 1 + s′ 2 + s3 = 18. Finally, the total number of solutions is: 3(61C2) −3(20C2)"}
{"instruction": "Consider a tetrahedral die with 3 of its sides painted red, blue and green and the fourth side has all the three colours. The colour of the side on which the die lands is to be considered. When the die lands on the fourth side, all 3 colours need to be considered. (a) Find the probability of getting red P(R), green P(G) and blue P(B). (b) Find the probability of getting red and blue P(R∩B), red and green P(R∩G) and blue and green P(B ∩G). (c) Is the collection of these 3 events (getting red, blue and green) pairwise inde- pendent? Mutually independent?", "response": "(a) There are 2 sides on which red appears hence P(R) = 1/2. Similarly, P(G) = 1/2 and P(B) = 1/2. (b) For getting red and blue, the die must land on the side containing all the 3 colours. Hence P(R ∩B) = 1/4. Similarly, P(R ∩G) = 1/4 and P(B ∩G) = 1/4. 1 (c) The collection of events is pairwise independent but not mutually independent. • A collection of events {Ai, i ∈I} are said to be mutually inde- pendent if the P \u0010T j∈J Aj \u0011 = Q j∈J P(Aj) for any subset J of I. • A collection of events {Ai, i ∈I} are said to be pairwise inde- pendent if any pair of events from the collection are independent. From the events R, G and B, select any pair of events (P and Q) and check P(P ∩Q) = P(P)P(Q) - it holds true and hence the events are pairwise independent. But for the collection of events to be mutually independent this should hold for any subset. Consider the set itself: P(R ∩G ∩B) = 1 4 ̸= P(R)P(G)P(B) = 1 8"}
{"instruction": "Percy Jackson and his two close friends, Annabeth Chase and Grover Underwood, are part of a group of ten demigods preparing for a quest. To decide who will go on the first mission, Chiron randomly splits the group into two teams of five. What is the probability that Percy, Annabeth, and Grover will end up on the same team for this mission? (Assume, teams are not labeled)", "response": "Suppose Percy’s slot is fixed in one of the teams. Now, Annabeth has 4 remaining slots (in Percy’s team) to pick from the leftover 9 slots. After Annabeth picks a slot, Grover has 3 remaining slots to pick from the leftover 8 slots. Note that, the order in which Percy, Annabeth, and Grover pick their slots doesn’t matter, so we can assume any one order. So, the probability that they end up together: Probability = 4 9 × 3 8 = 1 6 Alternatively, this can also be expressed as: Probability = \u00007 2 \u0001 1 2 × \u000010 5 \u0001 = 1 6 where \u00007 2 \u0001 represents choosing the 2 people (apart from Percy, Annabeth and Grover) from the remaining 7 for their team, and 1 2 × \u000010 5 \u0001 represents the total number of ways to form two teams of 5."}
{"instruction": "Consider two fair six-sided dice. Let event A be the first die showing a 2 or 3. Let event B be the sum of the dice being less than equal to 3. Are these events independent? Now, you are given the event C that the first dice does not show a 4. Are the events A and B conditionally independent? 3", "response": "P(A) = 2 6 = 1 3 Now, we know that the number of possible cases for two dice is 36. Let’s count the cases of sum being less than equal to 3 . The cases are {(1, 1), (1, 2), (2, 1)} There are 5 such cases, so P(B) = 3 36 = 1 12 Now for event A ∩B, we want the sum of dice less than equal to 3 and the first die showing 2 or 3, there is only one such case : {(2,1)}. Thus, P(A∩B) = 1 36 While, P(A) × P(B) = 1 3 × 1 12 = 1 36 Clearly P(A) × P(B) = P(A ∩B) Thus, events A and B are independent Now, let’s consider the event C, since the first dice cannot show a 4, the sample space for event A, reduces to {1,2,3,5,6}. So, P(A|C) = 2 5 For B the sample space remains unaffected So, P(B|C) = 3 30 = 1 10 (Since, sample space is now 30 elements and the 3 elements ({(1,1) , (2,1), (1,2)}) are still a part of the sample space) Now, P((A ∩B)|C) = 1 30 (Since the sample is 30 elements and only one element {(2,1)} lies in the space) While, P(A|C) × P(B|C) = 2 5 × 1 10 Thus, P(A|C) × P(B|C) = 1 25 4 Clearly, P((A ∩B)|C) ̸= P(A|C) × P(B|C) Thus, the events A and B are independent. But events A and B are not conditionally independent given C. This, might seem counter intuitive since two independent events turn out not to be conditionally independent, but use this example to remem- ber that we should use the formula to check conditional independance, we cannot assume that since the events are independent they will be conditionally independent."}
{"instruction": "Kushal and Medha play a game where they toss coins and compete to see who can get the most heads. Kushal gets to toss 100 coins and Medha gets to toss 101 coins, but if they get the same number of heads, Kushal wins the game. What is the probability that Kushal wins?", "response": "The answer is indeed 1/2. Let’s look at the probability that Medha wins the game. So, let’s assume both of them have tossed their 100 coins and Medha is about to toss the 101st coin. There are 3 possibilities here, either Kushal is ahead or Medha is ahead or they both have equal number of heads. Let the probability that Kushal is ahead be p. Since there is no difference until the 100th toss, probability that Medha is ahead is also p and they are tied is 1 −2p. Now, for Medha to win, either the total was tied and she has to get a heads in the 101st or she has to be ahead of Kushal (last toss doesn’t matter). If Medha after 100 tosses has lesser number of heads than Kushal, she can’t win as the best that can happen is a tie even then Kushal wins. So, the probability that Medha wins is (1 −2p) · 1/2 + p · 1 = 1/2 Hence, the probability that Kushal wins is also 1/2."}
{"instruction": "Consider a machine that produces a defective item with probability p and a non- defective item with probability 1−p. Suppose that items produced by the machine are selected at random and inspected one at a time until exactly five defective items have been obtained. Determine the probability p that exactly n items must be selected to obtain the five defectives.", "response": "To determine the probability that exactly n items must be selected to obtain exactly five defective items, we can use the following reasoning: The fifth defective item will be the n-th item inspected if and only if there are exactly four defectives among the first n −1 items and the n-th item is defective. 1. Probability of Exactly Four Defectives Among the First n −1 Items: The number of ways to choose 4 defective items out of the first n −1 items is given by the binomial coefficient \u0000n−1 4 \u0001 . The probability of having 5 exactly 4 defectives among these n −1 items, and the remaining n −5 items being non-defective, is: \u0012n −1 4 \u0013 p4(1 −p)n−5 2. Probability That the n-th Item is Defective: The probability that the n-th item is defective is p. Since the event of having exactly four defectives among the first n −1 items and the event of the n-th item being defective are independent, the total probability that exactly n items are selected to obtain the five defectives is the product of these probabilities. Therefore, the probability P is given by: P = \u0012n −1 4 \u0013 p5(1 −p)n−5 6"}
{"instruction": "Let X be a discrete random variable with the following PMF: pX(x) =                0.25 for x = 2, 0.15 for x = 4, 0.35 for x = 7, 0.25 for x = 9, 0 otherwise. Find and plot the CDF of X.", "response": "The CDF is defined by FX(x) = P(X ≤x). We have: FX(x) =                0 for x < 2, pX(2) = 0.25 for 2 ≤x < 4, pX(2) + pX(4) = 0.40 for 4 ≤x < 7, pX(2) + pX(4) + pX(7) = 0.75 for 7 ≤x < 9, 1 for x ≥9."}
{"instruction": "The median of a random variable X is defined as any number m that satisfies both of the following conditions: P(X ≥m) ≥1 2 and P(X ≤m) ≥1 2. Note that the median of X is not necessarily unique. Find the median of X if (a) The PMF of X is given by PX(k) =          0.4 for k = 1, 0.3 for k = 2, 0.3 for k = 3, 0 otherwise. (b) X is the result of rolling a fair die. (c) X ∼Geometric(p), where 0 < p < 1.", "response": "pX(X ≥m) ≥1 2 pX(X ≤m) ≥1 2 1 pX(X > m) + pX(X = m) ≥1 2 FX(m) ≥1 2 1 −FX(m) + PX(X = m) ≥1 2 1 2 ≤FX(m) ≤1 2 + PX(X = m) (a) FX(x) =          0 x < 1 0.4 1 ≤x < 2 0.7 2 ≤x < 3 1 x ≥3 Case 1: m is not a discrete number: pX(X = m) = 0 (since X is a discrete random variable) FX(m) = 1 2 for m /∈Z+ Case 2: m is discrete: PX(X = m) ̸= 0 1 2 ≤FX(m) ≤1 2 + PX(X = m) For m ≥2: m ≥2 will always satisfy condition (2), but m > 3 will not satisfy it =⇒m might lie in [2, 3] For non-integer values of m in [2, 3]: FX(m) = 1 2, which is not true. ∴We only consider discrete points where PMF is non-zero and satisfies (1) and (2). m = 2 (b) FX(x) =                          0 x < 1 1 6 1 ≤x < 2 2 6 2 ≤x < 3 3 6 3 ≤x < 4 4 6 4 ≤x < 5 5 6 5 ≤x < 6 1 x ≥6 2 For m ≥3, we see that: FX(x) ≥1 2 For m = 3, we have: FX(3) ≤1 2 + PX(3) 1 2 ≤1 2 + 1 6 (satisfied) For m = 4, we have: FX(4) ≤1 2 + PX(4) 4 6 ≤1 2 + 1 6 = 4 6 (satisfied) For m = 5, we get: FX(5) ̸= 1 2 + PX(5) ∴Discrete points satisfying the condition are{3, 4}. To check the interval (3, 4): FX(x) x ∈(3, 4) = 1 2 ∴All points that are non-integer in (3, 4) will satisfy the condition. =⇒m ∈(3, 4) ∪{3, 4} = m ∈[3, 4] (c) Let X ∼Geometric(p). PX(X = k) = (1 −p)k−1p k = 1, 2, . . . FX(x = k) = 1 −(1 −p)k For FX(m) ≥1 2: 1 −(1 −p)m ≥1 2 (1 −p)m ≤1 2 m ln(1 −p) ≤ln 1 2 m ≥ −ln 2 ln(1 −p) For FX(m) ≤1 2 + PX(m): 1 −(1 −p)m ≤1 2 + p(1 −p)m−1 1 2 ≤p + (1 −p)m−1 3 (1 −p)m−1 ≥1 2 (m −1) ln(1 −p) ≤ln 1 2 m ≤1 + −ln 2 ln(1 −p) For p = 1 2, there will be two discrete points that satisfy this: m = {1, 2} For the interval [1, 2): FX(m) = PX(1) = (1 −p)1 2 = 1 2 =⇒m ∈[1, 2) ∪{2} m ∈[1, 2] For p ̸= 1 2, there will be only one discrete point that satisfies this condition. The answer might not entirely be the range, but only discrete points (just like in part a)."}
{"instruction": "Consider a random variable X and another random variable Y defined as a function of X: Y = ( 2 if X < 2, X if X ≥2. Express Y using the indicator variables of the events {X < 2} and {X ≥2}.", "response": "Denote 1{X<2} as the indicator variable for the event {X < 2}, and 1{X≥2} as the indicator variable for the event {X ≥2}. Since both of these variables can take values of 0 or 1 for any value of X, and are mutually complementary to each other (i.e., they cannot take the same value at the same time), we can express Y as the sum of a linear combination of these two indicator random variables: Y = 2 · 1{X<2} + X · 1{X≥2} =⇒Y = 2 · 1{X<2} + X · (1 −1{X<2}) =⇒Y = (2 −X) · 1{X<2} + X"}
{"instruction": "We roll n dice and sum the highest 3. What is the probability that the sum is 18? Compute formula for general n, and give the value for n=5. 4", "response": "The sum will be 18 when there are atleast 3 rolls of 6, since we sum the highest 3 rolls. So the probability will be equal to probability of getting atleast 3 rolls of 6 in n rolls. Let X be a random variable indicating the number of 6s rolled in n rolls. Then X is a binomial random variable with p = 1 6 We can calculate the complement i.e. probability of getting less than 3 rolls of 6. The number of 6s is a binomial random variable with p = 1 6. P(X < 3) = PX(0) + PX(1) + PX(2) where PX(x) = \u0012n x \u0013 px(1 −p)n−x Substituting, we get P(X < 3) = \u00125 6 \u0013n + n · 1 6 · \u00125 6 \u0013n−1 + n(n −1) 2 · \u00121 6 \u00132 · \u00125 6 \u0013n−2 And the required probability is the complement of this Substituting n = 5, we get P(X < 3) = 0.94 P(X >= 3) = 0.06"}
{"instruction": "Two coins are simultaneously tossed until one of them comes up a head and the other a tail. The first coin comes up a head with probability p and the second with probability q. All tosses are assumed independent. (a) Find the PMF, the expected value, and the variance of the number of tosses. (b) What is the probability that the last toss of the first coin is a head?", "response": "(a) Let X be the number of tosses until the game is over. Noting that X is geometric with the probability of success P({HT, TH}) = p(1 −q) + q(1 −p), we obtain the probability mass function (PMF): pX(k) = (1 −p(1 −q) −q(1 −p))k−1 (p(1 −q) + q(1 −p)) , k = 1, 2, . . . Therefore, the expected value of X is: E[X] = 1 p(1 −q) + q(1 −p) and the variance of X is: Var(X) = pq + (1 −p)(1 −q) (p(1 −q) + q(1 −p))2. 5 (b) The probability that the last toss of the first coin is a head is: P(HT | {HT, TH}) = p(1 −q) p(1 −q) + (1 −p)q."}
{"instruction": "Let X be a random variable that takes values from 0 to 9 with equal probability 1 10. (a) Find the PMF of the random variable Y = X mod 3. (b) Find the PMF of the random variable Y = 5 mod (X + 1).", "response": "(a) Using the formula pY (y) = X {x|x mod 3=y} pX(x), we obtain: pY (0) = pX(0) + pX(3) + pX(6) + pX(9) = 4 10, pY (1) = pX(1) + pX(4) + pX(7) = 3 10, pY (2) = pX(2) + pX(5) + pX(8) = 3 10, pY (y) = 0 if y /∈{0, 1, 2}. (b) Similarly, using the formula pY (y) = X {x|5 mod (x+1)=y} pX(x), we obtain: pY (y) =                2 10, if y = 0, 2 10, if y = 1, 1 10, if y = 2, 5 10, if y = 5, 0, otherwise. 6"}
{"instruction": "You purchase a certain product. The manual states that the lifetime T of the product, defined as the amount of time (in years) the product works properly until it breaks down, satisfies P(T ≥t) = e−t/5, for all t ≥0. For example, the probability that the product lasts more than (or equal to) 2 years is P(T ≥2) = e−2/5 = 0.6703. I purchase the product and use it for two years without any problems. What is the probability that it breaks down in the third year?", "response": "Let A be the event that a purchased product breaks down in the third year. Also, let B be the event that a purchased product does not break down in the first two years. We are interested in P(A | B). We have P(B) = P(T ≥2) = e−2/5. We also have P(A) = P(2 ≤T ≤3) = P(T ≥2) −P(T ≥3) = e−2/5 −e−3/5. Finally, since A ⊆B, we have A ∩B = A. Therefore, P(A | B) = P(A ∩B) P(B) = P(A) P(B) = e−2/5 −e−3/5 e−2/5 = 0.1813."}
{"instruction": "There are 30 people in a room. What is the chance that any two of them celebrate their birthday on the same day? Assume 365 days in a year.", "response": "First, we calculate the probability that no two people share a birthday: P(no shared birthday) = 365 365 × 364 365 × 363 365 × . . . × 336 365 This product can be expressed as: P(no shared birthday) = 29 Y i=0 \u0012 1 − i 365 \u0013 In numerical terms, this evaluates to approximately: P(no shared birthday) ≈0.294 1 The probability that at least two people share a birthday is then: P(shared birthday) = 1 −P(no shared birthday) = 1 −0.294 ≈0.706 Thus, the probability that at least two people in a room of 30 share the same birthday is approximately 70.6%."}
{"instruction": "Prove the following inequality without the use of induction: P ∞ [ i=1 Ai ! ≤ ∞ X i=1 P(Ai).", "response": "We know that if B1, B2, B3, . . . are disjoint subsets of the probability space then P [ i Bi ! = X i P(Bi); We can construct the sets Bi from Ai such that they are disjoint, Bi = Ai − i−1 [ j=1 Aj and show that ∞ [ i=1 Bi = ∞ [ i=1 Ai. Suppose x ∈S∞ i=1 Ai. Then x ∈Ak for some minimum k such that i < k =⇒ x /∈Ai. Therefore x ∈Bk = Ak −Sk−1 j=1 Aj. So the first inclusion is true: S∞ i=1 Ai ⊆S∞ i=1 Bi. Next suppose that x ∈S∞ i=1 Bi. It follows that x ∈Bk for some k. And Bk = Ak −Sk−1 j=1 Aj so x ∈Ak, and we have the other inclusion: S∞ i=1 Bi ⊆S∞ i=1 Ai. By construction of each Bi, Bi ⊂Ai. For B ⊂A =⇒P(B) ≤P(A). So, we can conclude that the desired inequality is true: P [ i Ai ! = P [ i Bi ! = X i P(Bi) ≤ X i P(Ai)."}
{"instruction": "Let (Ω, F, P) be a probability space. Let G = {A ∈F : P(A) = 0 or 1}. Show that G is a σ-algebra.", "response": "(a) To prove the first condition: we need to show that ϕ ∈G and Ω∈G. From axioms of probability, P(ϕ) = 0 and P(Ω) = 1. Hence by definition of G, ϕ ∈G and Ω∈G. 2 (b) To prove the second condition: Let A ∈G =⇒P(A) = 0 OR P(A) = 1. =⇒1 −P(A) = 1 OR 1 −P(A) = 0 =⇒P(AC) = 1 OR P(AC) = 0 =⇒AC ∈G. (c) To prove the third condition: Let {Ai}∞ i=1 be a countable collection of sets in G. We need to show that S∞ i=1 Ai ∈G. There are two possibilities to consider for each Ai: • P(Ai) = 0 • P(Ai) = 1 First, let’s consider the case where S∞ i=1 P(Ai) = 0: If P(Ai) = 0 for all i, then the union S∞ i=1 Ai is also of measure 0. This follows from the countable subadditivity property of measures: P ∞ [ i=1 Ai ! ≤ ∞ X i=1 P(Ai) = 0. Hence, S∞ i=1 Ai ∈G. Now, let’s consider the case where S∞ i=1 P(Ai) = 1: If there exists at least one Ai such that P(Ai) = 1, then the union S∞ i=1 Ai will be of measure 1. This follows because if any set in a countable collection has measure 1, the union of the entire collection must also have measure 1: P ∞ [ i=1 Ai ! ≥P(Ai) = 1. Hence, S∞ i=1 Ai ∈G."}
{"instruction": "Let E1, E2, . . . , En be n events, each with positive probability. Prove that P n\\ i=1 Ei ! = P{E1} · P{E2 | E1} · P{E3 | E1 ∩E2} · · · P ( En | n−1 \\ i=1 Ei ) .", "response": "By expanding the right-hand side using the definition of conditional probability, we get: P{E1} · P(E1 ∩E2) P(E1) · P(E1 ∩E2 ∩E3) P(E1 ∩E2) · · · P (Tn i=1 Ei) P \u0000Tn−1 i=1 Ei \u0001. After cancelling terms, we are left with only the numerator of the last fraction, which is equal to the left-hand side."}
{"instruction": "Queueville Airlines knows that on average 5% of the people making flight reserva- tions do not show up. (They model this information by assuming that each person independently does not show up with probability of 5%.) Consequently, their pol- icy is to sell 52 tickets for a flight that can only hold 50 passengers. What is the probability that there will be a seat available for every passenger who shows up? ‘", "response": "Probability that everyone gets a seat = probability that at most 50 people show up = 1−probability that 51 or 52 people show up. The probability of any given passenger showing up is 0.95. Since the arrival of each passenger is an independent event, the probability that all 52 show up is (0.95)52. Similarly, the probability that 51 people show up is \u000052 1 \u0001 (0.95)51(0.05). Probability of everyone getting a seat = 1 −(0.95)52 − \u000052 1 \u0001 (0.95)51(0.05) 4"}
{"instruction": "Suppose a machine can be either operational or in maintenance, and the machine’s status on successive days follows a Markov chain with stationary transition probabilities. Suppose the transition matrix is as follows: Operational Maintenance Operational 0.7 0.3 Maintenance 0.6 0.4 (a) If the machine is in maintenance on a given day, what is the probability that it will also be in maintenance the next day? (b) If the machine is operational on a given day, what is the probability that it will remain operational for the next two days? (c) If the machine is in maintenance on a given day, what is the probability that it will be operational on at least one of the next three days?", "response": "(a) Probability of Maintenance the Next Day Given Maintenance Today Let sn denote the machine’s status on a given day. From the transition matrix, the probability P(sn+1 = Maintenance | sn = Maintenance) is given by the bottom- right element of the transition matrix: P(sn+1 = Maintenance | sn = Maintenance) = 0.4 (b) Probability of Operational Status for the Next Two Days Given Operational Today We need to find P(sn+2 = Operational ∩sn+1 = Operational | sn = Operational). This can be written as: P(sn+2 = Operational ∩sn+1 = Operational ∩sn = Operational) = P(sn = Operational) · P(sn+1 = Operational | sn = Operational) · P(sn+2 = Operational | sn+1 = Operational) Since P(sn = Operational) = 1 (we start with an operational day), this simplifies to: P(sn+2 = Operational | sn+1 = Operational) · P(sn+1 = Operational | sn = Operational) = (0.7)(0.7) = 0.49 (c) Probability of Operational Status on At Least One of the Next Three Days Given Maintenance Today We are asked to find the probability that the machine is operational on at least one of the next three days, given that today it is in maintenance. This probability is given by: 1−P(sn+3 = Maintenance∩sn+2 = Maintenance∩sn+1 = Maintenance | sn = Maint) 1 Using the transition matrix, we have: P(sn+3 = Maintenance, sn+2 = Maintenance, sn+1 = Maintenance | sn = Maintenance) = (0.4)(0.4)(0.4) = 0.064 Thus, the required probability that the machine will be operational on at least one of the next three days is: 1 −0.064 = 0.936"}
{"instruction": "Simulate a markov chain with transition probability matrix P =   0.2 0.7 0.1 0.9 0 0.1 0.2 0.8 0   and find its limiting distribution. 4", "response": "import numpy as np import matplotlib . pyplot as plt P = np . array ( [ [ 0 . 2 , 0.7 , 0 . 1 ] , [ 0 . 9 , 0.0 , 0 . 1 ] , [ 0 . 2 , 0.8 , 0 . 0 ] ] ) def simulate (P, num iterations =1000, t o l=1e −8): state = np . random . rand (P. shape [ 0 ] ) state = state / state .sum() s t a t e h i s t o r y = [ state ] for i in range( num iterations ) : new state = np . dot ( state , P) s t a t e h i s t o r y . append ( new state ) i f np . a l l c l o s e ( new state , state , atol=t o l ) : print ( f ”Converged a f t e r { i +1} i t e r a t i o n s ” ) break state = new state return np . array ( s t a t e h i s t o r y ) num trials = 5 num iterations = 1000 plt . f i g u r e ( f i g s i z e =(12 , 8)) for t r i a l in range( num trials ) : print ( f ”\\ nTrial { t r i a l + 1}” ) s t a t e h i s t o r y = simulate (P, num iterations=num iterations ) s t a t i o n a r y d i s t r i b u t i o n = s t a t e h i s t o r y [ −1] print ( f ” Stationary Distribution for Trial { t r i a l + 1}: { s t a t i o n a r y d for state index in range(P. shape [ 0 ] ) : plt . plot ( s t a t e h i s t o r y [ : , state index ] , l a b e l=f ” State { state ind f i n a l v a l u e = s t a t e h i s t o r y [ −1 , state index ] plt . text ( len ( s t a t e h i s t o r y ) , f i n a l v a l u e −0.008 , f ”{ f i n a l v a l u e : . verticalalignment=’ center ’ , horizontalalignment=’ right ’ color=f ”C{ state index }” , f o n t s i z e =10) plt . xlabel ( ” I t e r a t i o n s ” ) plt . ylabel ( ” Probability ” ) plt . t i t l e ( ”Convergence to Stationary Distribution of Markov Chain” ) plt . legend ( loc=” best ” ) plt . show () From the results, we can see that the probability distribution of the states converges to a fixed value irrespective of the starting distribution. This is the limiting distribution 5 Figure 2: Simulation Results of the markov chain. The stationary/ limiting distribution obtained is α = \u0002 0.492 0.417 0.091 \u0003 We can verify this by finding the stationary distribution of the markov chain π(P −I) = 0 π   −0.8 0.7 0.1 0.9 −1 0.1 0.2 0.8 −1  = 0 We get the following sytem of equations −8π1 + 9π2 −2π3 = 0 9π1 −10π2 + π3 = 0 2π1 + 8π2 −10π3 = 0 π1 + π2 + π3 = 0 Solving these, we get π = \u0002 92 187 78 187 1 11 \u0003 = \u0002 0.491 0.417 0.091 \u0003 Which is the same as the distribution obtained from the simulation"}
{"instruction": "Purpose-flea zooms around the vertices of the transition diagram shown below. Let Xt represent Purpose-flea’s state at time t (where t = 0, 1, . . .). (a) Find the transition matrix P. (b) Find P(X2 = 3 | X0 = 1). 6 Figure 3: Transition Diagram of Purpose-flea’s Movement (c) Suppose that Purpose-flea is equally likely to start on any vertex at time 0. Find the probability distribution of X1. (d) Suppose that Purpose-flea begins at vertex 1 at time 0. Find the probability distribution of X2.", "response": "(a) The transition matrix P is constructed based on the probabilities from the diagram: P =   0.6 0.2 0.2 0.4 0 0.6 0 0.8 0.2   (b) To find P(X2 = 3 | X0 = 1), we calculate P 2 and find the entry in the first row and third column. P 2 = P · P =   0.6 0.2 0.2 0.4 0 0.6 0 0.8 0.2     0.6 0.2 0.2 0.4 0 0.6 0 0.8 0.2   Calculate P 2 , and use the value in position (1, 3) for P(X2 = 3 | X0 = 1). (c) Let the initial probability distribution vector be π0 = \u0000 1 3 1 3 1 3 \u0001 . The distribution at X1 is then: π1 = π0 · P = \u0000 1 3 1 3 1 3 \u0001   0.6 0.2 0.2 0.4 0 0.6 0 0.8 0.2   This calculation yields the probability distribution of X1. (d) If Purpose-flea begins at vertex 1 at time 0, the initial distribution vector is π0 = \u00001 0 0 \u0001 . The distribution at X2 is given by: π2 = π0 · P 2 where P 2 is the squared transition matrix. Use the result from part (b) to find the distribution at X2."}
{"instruction": "Consider a Markovian Coin, S = {0, 1}. Where 0 denotes Head and 1 denotes Tails. Suppose that the transition matrix is given by P = \u00141 −a", "response": "b 1 −b \u0015 , 7 where a and b are two real numbers in the interval [0, 1] such that 0 < a + b < 2. Suppose that the system is in state 0 at time n = 0 with probability α, i.e., π(0) = [P(X0 = 0) P(X0 = 1)] = [α 1 −α], where α ∈[0, 1]. (a) How does transition matrix define the nature of the coin. (b) Using induction (or any other method), show that P n = 1 a + b \u0014b a b a \u0015 + (1 −a −b)n a + b \u0014 a −a −b b \u0015 . (c) Show that lim n→∞P n = 1 a + b \u0014b a b a \u0015 . (d) Show that lim n→∞π(n) = \u0002 b a+b a a+b \u0003 . A: (a) Nature of the Markovian coin: The probability that there is a Heads to Tails transition is a, and the probability that there is a Tails to Heads transition is b. The probability that it retains its memory is 1 −α where α is the probability that chain changes whatever state it is in. (b) For n = 1, we have P 1 = \u00141 −a a b 1 −b \u0015 = 1 a + b \u0014b a b a \u0015 + 1 −a −b a + b \u0014 a −a −b b \u0015 . Assuming that the statement of the problem is true for n, we can write P n+1 as P n+1 = P nP = 1 a + b \u0012\u0014b a b a \u0015 + (1 −a −b)n \u0014 a −a −b b \u0015\u0013 · \u00141 −a a b 1 −b \u0015 = 1 a + b \u0014b a b a \u0015 + (1 −a −b)n+1 a + b \u0014 a −a −b b \u0015 , which completes the proof. (c) By assumption 0 < a + b < 2, which implies −1 < 1 −a −b < 1. Thus, lim n→∞(1 −a −b)n = 0. Therefore, lim n→∞P n = 1 a + b \u0014b a b a \u0015 . (d) lim n→∞π(n) = lim n→∞[π(0)P n] = π(0) lim n→∞P n = [α 1 −α] · 1 a + b \u0014b a b a \u0015 = \u0002 b a+b a a+b \u0003 . 8"}
{"instruction": "For the Markovian coin described above: (a) Calculate the stationary distribution. What do you observe? (b) Find the mean return times, r0 and r1, for this Markov chain. Do you observe anything? (c) Can you intuitively explain the result above?", "response": "(a) The stationary distribution is the same as the limiting distribution. (b) To calculate r0: r0 = E[R | X1 = 0, X0 = 0] · P(X1 = 0 | X0 = 0) + E[R | X1 = 1, X0 = 0] · P(X1 = 1 | X0 = 0) = E[R | X1 = 0] · (1 −a) + E[R | X1 = 1] · a. If X1 = 0, then R = 1, so E[R | X1 = 0] = 1. If X1 = 1, then R ∼1 + Geometric(b), so E[R | X1 = 1] = 1 + E[Geometric(b)] = 1 + 1 b. Therefore, r0 = 1 · (1 −a) + \u0012 1 + 1 b \u0013 · a = a + b b . Similarly, we can obtain the mean return time to state 1: r1 = a + b a . We can notice that: r0 = 1 πo r1 = 1 π1 (c) The larger the πi, the smaller the ri will be. For example, if πi = 1 4, we conclude that the chain is in state i one-fourth of the time. In this case, ri = 4, which means that on average it takes the chain four time units to return to state i. 9"}
{"instruction": "Show that convergence in mean square implies convergence in probability.", "response": "We can apply the Markov inequality to a generic term of the sequence {(Xn −X)2}: P \u0000(Xn −X)2 ≥ϵ2\u0001 ≤E \u0002 (Xn −X)2\u0003 ϵ2 For any strictly positive real number ϵ, taking the square root of both sides of the left-hand inequality, we obtain: P(|Xn −X| ≥ϵ) ≤E \u0002 (Xn −X)2\u0003 ϵ2 Taking limits on both sides, we get: lim n→∞P(|Xn −X| ≥ϵ) ≤lim n→∞ E \u0002 (Xn −X)2\u0003 ϵ2 = limn→∞E \u0002 (Xn −X)2\u0003 ϵ2 = 0 Since, lim n→∞E[(Xn −X)2] = 0 And by the definition of probability, P(|Xn −X| ≥ϵ) ≥0 Then it must be that also: lim n→∞P(|Xn −X| ≥ϵ) = 0"}
{"instruction": "Chebyshev Inequality states that: If X is any random variable, then for any b > 0 we have: P \u0000|X −EX| ≥b \u0001 ≤V ar(X) b2 . Let X ∼Binomial(n, p). Using Chebyshev’s inequality, find an upper bound on P(X ≥αn), where p < α < 1. Evaluate the bound for p = 1 2 and = 3 4. Calculate using Markov’s inequality for the similar parameters, and comment on the betterness of the bounds obtained. 1", "response": "We can write this bound as P(X ≥αn) = P(X −np ≥αn −np) ≤P \u0000|X −np| ≥nα −np \u0001 ≤ V ar(X) (nα −np)2 = p(1 −p) n(α −p)2. Substituting the values for p and α we get: P(X ≥3n 4 ) ≤4 n. On applying Markov’s inequality, with E[X] = np P(X ≥αn) ≤E[X] αn = pn αn = p α Substituting the values for p and α we get: P(X ≥3n 4 ) ≤2 3. We can see that Chebyshev gives a better and stronger bound than Markov. It is constant and does not change as n increases. Statistics Classical/Frequentist Methods"}
{"instruction": "Prove that maximising the likelihood is the same as maximising the log likelihood. [Hint: Start by taking 2 different values of the parameter; one maximises the likelihood function, and the other maximises the log-likelihood function].", "response": "Let L(θ) = the likelihood function for parameter θ given data D: L(θ) = p(D|θ) The log-likelihood function, ℓ(θ) = log L(θ) = log p(D|θ) Proof by Contradiction: Assume there exist two different parameter values θ1 and θ2 such that: L(θ1) > L(θ2) l(θ2) > ℓ(θ1) The logarithm function log(x) is monotonically increasing. Hence if L(θ1) > L(θ2) then 2 log L(θ1) > log L(θ2) which implies ℓ(θ1) > ℓ(θ2) Note: log(x) is monotonically increasing (can be verified from derivative) From our assumption, L(θ1) > L(θ2) =⇒ℓ(θ1) > ℓ(θ2) However, this contradicts the initial assumption that ℓ(θ2) > ℓ(θ1)."}
{"instruction": "Let X1, X2, . . . , Xn be a random sample from a Geometric(p) distribution. Suppose we observe the data {x1, x2, x3, x4} = {2, 1, 7, 3} . The probability mass function of the Geometric distribution is given by: PX(x; p) = p(1 −p)x−1 Find the maximum likelihood estimate (MLE) of p", "response": "The likelihood function for the sample {x1, x2, . . . , xn} is: L(x1, . . . , xn; p) = n Y i=1 p(1 −p)xi−1 = pn(1 −p) Pn i=1 xi−n. The MLE of p, denoted as ˆpML, is given by: ˆpML = arg max p L(x1, . . . , xn; p) = arg max p log L(x1, . . . , xn; p) [Since, log is monotonically increasing] = arg max p n log(p) + n X i=1 xi −n ! log(1 −p) ! To find the MLE, we differentiate log L(p) with respect to p, set the derivative to zero, and solve: d dp log L(p) = n p − Pn i=1 xi −n 1 −p = 0. Simplifying: n p = Pn i=1 xi −n 1 −p , n(1 −p) = p n X i=1 xi −n ! , n = p n X i=1 xi. Thus, the MLE is: ˆpML = n Pn i=1 xi = 4 13"}
{"instruction": "In the Cilantro experiment, assume 55 out of 100 people said Cilantro tastes like soap. Find the maximum likelihood estimate for p, the true proportion of people who feel that way. 3", "response": "The likelihood function for p is L(p) = \u0012100 55 \u0013 p55(1 −p)45. Because the log function turns multiplication into addition, it is often convenient to use the log of the likelihood function: log likelihood = ln(likelihood) = ln(P(data | p)). In our example: Log likelihood l(p) = ln \u0012\u0012100 55 \u0013\u0013 + 55 ln(p) + 45 ln(1 −p). Now we can set the derivative of l(p) to 0 to find the MLE: l′(p) = 55 p − 45 1 −p = 0. This is easy to solve for p. We get ˆp = 0.55. Adding a hat is a standard way of indicating an estimate, i.e., ˆp is an estimate of the unknown parameter p."}
{"instruction": "Let D = {x1, ..., xn} denote i.i.d samples from a uniform random variable U[0, a], where a is unknown. Find an MLE estimate for the unknown parameter a.", "response": "Since we know that the samples are drawn from the uniform distribution U[0, a], we have that the PDF of a sample xi is given by f(xi) = ( 1 a if 0 ≤xmin ≤xmax ≤a 0 otherwise Now, the likelihood function L is given by L(x1, ..., xn; a) = P(x1, ..., xn; a) Since we have that the samples are i.i.d., P(x1, ..., xn; a) = n Y i=1 P(xi; a) ⇒L(x1, ..., xn; a) = n Y i=1 P(xi; a) = 1 an ⇒L(x; a) = 1 an ∀0 ≤x ≤a On calculating the derivative of L(x; a) with respect to a and setting it to 0 to maximize L(a), we get the following expression: dL da = −n an+1 ̸= 0 4 So, we analyze the expression on the RHS of the likelihood function and we can infer that 1 an is a decreasing function. Hence, the maximum value of the likelihood function will be at the minimum possible value of a, i.e., max(L) = min(a). We also have to note the constraint on a that 0 ≤xmin ≤xmax ≤a and hence, the maximum likelihood estimate for the unknown parameter a is given by aMLE = max(x1, ..., xn)"}
{"instruction": "Assume our data Y = (y1, y2, ..., yn)T given X is independently identically distributed, i.i.d. Y |X = x ∼Exponential(λ = x), and we chose the prior to be X ∼Gamma(α, β).", "response": "Find the likelihood of the function, L(Y; X) = fY|X(y1, y2, ..., yn|x). b. Using the likelihood function of the data, show that the posterior distribution is Gamma(α + n, β + Pn i=1 yi). c. Write out the PDF for the posterior distribution, fX|Y(x|y). A: (a) Since Yi|X = x ∼Exp(x), We have that fYi|X(y|x) = ( xe−xy for y > 0 0 otherwise. The likelihood function is thus: L(Y ; x) = fY1,Y2,...,Yn|X(y1, y2, . . . , yn|x) = n Y i=1 fYi|X(yi|x) (by independence) = n Y i=1 xe−xyi = xne−x Pn i=1 yi. (b) Since X ∼Gamma(α, β), We have that fX(x) ∝xα−1e−βx for x > 0 and fX(x) = 0 otherwise. Therefore, for x > 0,the posterior is: fX|Y1,Y2,...,Yn(x|y1, y2, . . . , yn) ∝fY1,Y2,...,Yn|X(y1, y2, . . . , yn|x)fX(x) = L(Y ; x)fX(x) ∝xne−x Pn i=1 yixα−1e−βx = xα+n−1e−x( Pn i=1 yi+β), while for x ≤0, fX|Y1,Y2,...,Yn(x|y1, y2, . . . , yn) = 0. Now, since α and n are greater than 0, so too is α + n. Further, since it is assumed that Yi|X ∼Exp(X), it is implicit that all yis are greater than 0, and since β > 0, so too is Pn i=1 yi + β. Therefore, we see that, up to a normalizing constant, the posterior has the functional form of a Gamma(α + n, Pn i=1 yi + β) distribution, so that X|Y = y ∼ Gamma(α + n, Pn i=1 yi + β). (c) The posterior PDF is given by: fX|Y1,Y2,...,Yn(x|y1, y2, . . . , yn) = ( (Pn i=1 yi+β)α+nxα+n−1e−x( Pn i=1 yi+β) Γ(α+n) for x > 0 0 otherwise."}
{"instruction": "Let X1, . . . , Xn be a random sample from a Poisson(λ) distribution. 5 (a) Find the likelihood function, L(x1, . . . , xn; λ) (b) Find the log-likelihood function and use that to obtain the MLE for λ, ˆλML.", "response": "(a) L(x1, . . . , xn; λ) = n Y i=1 PXi(xi; λ) = n Y i=1 e−λλxi xi! = e−nλλ Pn i=1 xi n Y i=1 1 xi! (b) The log-likelihood, L, is: L(λ) = ln L(x1, . . . , xn; λ) = −nλ + n X i=1 xi ln λ − n X i=1 ln xi! Differentiating this with respect to λ, and setting it equal to zero, we have: 0 = −n + 1 ˆλML n X i=1 xi Solving for the maximum likelihood estimate, we have that: ˆλML = 1 n n X i=1 xi That is, the maximum likelihood estimate of λ is simply the sample mean."}
{"instruction": "Suppose you are trying to fit a distribution P(X = x|θ) = ( θ 2)|x|(1 −θ)1−|x| where the support set is {−1, 0, 1} and θ is a real number in the range [0, 1]. (a) Define an estimator as T(X) = 2 if x = 1 otherwise T(X) = 0. Show that T(X) is an unbiased estimator of θ. (b) Now define another estimator as G(X) = |X|. Show that G(x) is also an unbiased estimator of θ. (c) Which of the estimators is better for θ? Justify your answer.", "response": "(a) Note that the distribution for T(X) is given by: T(X) = ( 2 w.p. θ 2 0 w.p. 1 −θ 2 6 So, the expectation of T(X) is E[T(X)] = 2 \u0012θ 2 \u0013 + 0 \u0012 1 −θ 2 \u0013 = θ So, T(X) is an unbiased estimator of θ. (b) Note that the distribution for G(X) is given by: G(X) = ( 1 w.p. θ 0 w.p. 1 −θ G(X) is hence a Bernoulli random variable. So, we get E[G] = θ. So, G is also an unbiased estimator of θ. (c) Since both estimators are unbiased, we need to compare their variances. For T(X),the variance is σ2 T = (2 −θ)θ. For G(X), it is a Bernoulli random variable so we get σ2 G = (1 −θ)θ. Clearly, the variance of G is smaller than T so we can say that G is a better estimator than T, even though both are unbiased estimators."}
{"instruction": "Using a rod of length µ, you lay out a square plot whose length of each side is µ. Thus, the area of the plot will be µ2 (unknown). Based on n independent measurements X1, X2, . . . , Xn of the length, estimate µ2. Assume that each Xi has mean µ and variance σ2. (a) Show that X 2 is not an unbiased estimator for µ2. (b) For what value of k is the estimator X 2 −kS2 unbiased for µ2? [Divyaraj]", "response": "(a) Note that: E(X 2) = Var(X) + [E(X)]2 = σ2 n + µ2. Thus, the bias of the estimator X 2 is: E(X 2 −µ2) = σ2 n . Therefore, X 2 tends to overestimate µ2. (b) Consider the estimator X 2 −kS2. Its expected value is: E(X 2 −kS2) = E(X 2) −kE(S2). Substituting the known expectations: E(X 2) = µ2 + σ2 n , E(S2) = σ2, we get: E(X 2 −kS2) = µ2 + σ2 n −kσ2. To make the estimator unbiased, set: µ2 + σ2 n −kσ2 = µ2. 7 Simplifying: σ2 n −kσ2 = 0 =⇒k = 1 n. Hence, with k = 1 n, the estimator X 2 −kS2 is unbiased for µ2."}
{"instruction": "Consider an experiment with two possible outcomes: • {Success}, with probability p • {Failure}, with probability 1 −p The probability of success, p, is known to lie within the interval \u0002 1 10, 1 5 \u0003 . Suppose the experiment is repeated independently n times. The estimator for p is defined as: bp = Successes obtained Total experiments performed. Our objective is to determine the minimum value of n such that the standard deviation of the estimator bp is guaranteed to be less than 1 100 for all p ∈ \u0002 1 10, 1 5 \u0003 . [Divyaraj]", "response": "The estimator bp can be written as: bp = 1 n n X i=1 Xi, where n is the number of repetitions of the experiment, and Xi are n independent random variables, each following a Bernoulli distribution with parameter p. The variance of bp is given by: Var(bp) = Var(Xi) n = p(1 −p) n . Since p ∈ \u0002 1 10, 1 5 \u0003 , the maximum value of p(1 −p) occurs at p = 1 5: p(1 −p) = 1 5 \u0012 1 −1 5 \u0013 = 4 25. Thus, Var(bp) ≤ 4 25n. To ensure that the standard deviation of bp is less than 1 100, we need: p Var(bp) ≤ 1 100. Squaring both sides: Var(bp) ≤ 1 10, 000. Substituting the maximum variance: 4 25n ≤ 1 10, 000. Simplifying: 4 · 10, 000 ≤25n =⇒n ≥40, 000 25 = 1, 600. Thus, the minimum number of experiments required is: n = 1, 600 . 8"}
{"instruction": "Let X1, X2, . . . , Xn be a random sample from the following distribution: fX(x) = ( θ \u0000x −1 2 \u0001 + 1 for 0 ≤x ≤1, 0 otherwise, where θ ∈[−2, 2] is an unknown parameter. We define the estimator ˆΘn as: ˆΘn = 12X −6 to estimate θ. (a) Is ˆΘn an unbiased estimator of θ? (b) Is ˆΘn a consistent estimator of θ? (c) Find the mean squared error (MSE) of ˆΘn.", "response": "(a) To see this, we write: E[ˆΘn] = E[12X −6] = 12E[X] −6. Since: E[X] = E[X] = 12 · θ + 6 12 , it follows that: E[ˆΘn] = 12 · θ + 6 12 −6 = θ. Thus, ˆΘn is an unbiased estimator of θ. (b) To show that ˆΘn is a consistent estimator of θ, we need to show: lim n→∞P(|ˆΘn −θ| ≥ϵ) = 0, for all ϵ > 0. Since: ˆΘn = 12X −6 and E[X] = E[X], we conclude: P(|ˆΘn −θ| ≥ϵ) = P(12|X −E[X]| ≥ϵ) = P(|X −E[X]| ≥ϵ/12), which goes to zero as n →∞by the law of large numbers. Therefore, ˆΘn is a consistent estimator of θ. (c) To find the mean squared error (MSE) of ˆΘn, we write: MSE(ˆΘn) = Var(ˆΘn) + B(ˆΘn)2. Since ˆΘn is unbiased, the bias term B(ˆΘn) is 0. Thus: MSE(ˆΘn) = Var(ˆΘn). Now: Var(ˆΘn) = Var(12X −6) = 144Var(X). Using: Var(X) = Var(X) n , 9 we get: Var(X) = 12 −θ2 12 , and so: Var(ˆΘn) = 144(12 −θ2) 12n = 12 −θ2 n . Therefore: MSE(ˆΘn) = 12 −θ2 n . Note that this gives us another way to argue that ˆΘn is a consistent estimator of θ. In particular, since: lim n→∞MSE(ˆΘn) = 0, we conclude that ˆΘn is a consistent estimator of θ."}
{"instruction": "Let X1, X2, X3, ..., Xn be a random sample from a distribution with mean E[Xi] = θ and variance V ar(Xi) = σ2. Consider the following two estimators for θ: 1. ˆΘ1 = X1 2. ˆΘ2 = X = X1+X2+...+Xn n Find MSE(ˆΘ1) and MSE(ˆΘ2) and show that for n > 1 we have MSE(ˆΘ1) > MSE(ˆΘ2).", "response": "We have MSE(ˆΘ1) = E[(ˆΘ1 −θ)2] = E[(X1 −EX1)2] = V ar(X1) = σ2. To find MSE(ˆΘ2), we can write MSE(ˆΘ2) = E[(ˆΘ2 −θ)2] = E[(X −θ)2] = V ar(X −θ) + (E[X −θ])2. Since E[Y 2] = V ar(Y ) + (E[Y )2, where Y = X −θ. Now, note that V ar(X −θ) = V ar(X) since θ is a constant. Also, E[X −θ] = 0. Thus, we conclude MSE(ˆΘ2) = V ar(X) = σ2 n . Therefore, for n > 1, we have MSE(ˆΘ1) > MSE(ˆΘ2). Bayesian Inference"}
{"instruction": "Let X ∼Uniform(0, 1). Suppose that we know Y |X = x ∼Geometric(x). Find the posterior density of X given Y = 2, fX|Y (x|2).", "response": "Using Bayes’ rule we have fX|Y (x|2) = PY |X(2|x)fX(x) PY (2) . 10 We know Y |X = x ∼Geometric(x), so PY |X(y|x) = x(1 −x)y−1, for y = 1, 2, ... Therefore, PY |X(2|x) = x(1 −x). To find PY (2), we can use the law of total probability PY (2) = Z ∞ −∞ PY |X(2|x)fX(x)dx = Z 1 0 x(1 −x) · 1dx = 1 6. Therefore, we obtain fX|Y (x|2) = x(1 −x) · 1 1 6 = 6x(1 −x), for 0 ≤x ≤1."}
{"instruction": "Let X be a continuous random variable with the following PDF: fX(x) = ( 3x2 if 0 ≤x ≤1 0 otherwise Also, suppose that Y |X = x ∼Geometric(x). Find the MAP estimate of X given Y = 5.", "response": "From Bayes’ rule, we know that the posterior density for 0 ≤x ≤1 is: fX|Y (x|5) ∝PY |X(5|x)fX(x) = 3x2 · x(1 −x)4 = 3x3(1 −x)4 (and 0 otherwise), where the symbol ∝means proportional to as a function of x. Therefore, the MAP estimate is given by ˆxMAP = arg max x {3x3(1 −x)4} which can be found by setting the derivative of the argument equal to zero and solving for x: 0 = 9ˆx2 MAP(1 −ˆxMAP)4 −12ˆx3 MAP(1 −ˆxMAP)3 ⇒ˆxMAP = 3 7 This value is indeed in the interval [0, 1]."}
{"instruction": "Suppose D = {x1, ..., xn} is a data set consisting of independent samples of a Bernoulli random variable with unknown parameter θ, i.e., f(xi|θ) = θxi(1 −θ)1−xi for xi ∈{0, 1}. We are also given that θ ∼U[0, 1]. Obtain an expression for the posterior distribution on θ. Using this, obtain ˆθMAP and the conditional expectation estimator ˆθCE. (Hint: R 1 0 θm(1 −θ)rdθ = m!r! (m+r+1)!) 11", "response": "f(θ|x1, ..., xn) = f(x1, ..., xn, θ) f(x1, ..., xn) = f(x1, ..., xn|θ)p(θ) R 1 0 f(x1, ..., xn|θ)p(θ)dθ = θ Pn i=1 xi(1 −θ)n−Pn i=1 xi R 1 0 θ Pn i=1 xi(1 −θ)n−Pn i=1 xidθ Now using the fact that for integral values m and r Z 1 0 θm(1 −θ)rdθ = m!r! (m + r + 1)! and letting s = Pn i=1 xi, the expression for the posterior becomes: f(θ|x1, ..., xn) = (n + 1)!θs(1 −θ)n−s s!(n −s)! Now, solving for ˆθMAP: ˆθMAP = arg max θ P(x1, . . . , xn|θ) = arg max θ θs(1 −θ)n−s Taking the derivative and setting to 0, we get: sθs−1(1 −θ)n−s −(n −s)θs(1 −θ)n−s−1 = 0 θs−1(1 −θ)n−s−1[s(1 −θ) −(n −s)θ] = 0 Since θ cannot take the value of 0 or 1 for maximizing the posterior, the second part of the above expression must go to 0. s(1 −θ) −(n −s)θ = 0 s −sθ −nθ + sθ = 0 θ = s n We got that the MAP estimate for θ is s n, which is just the sample mean ¯X of the data. For θCE, we have: θCE = E[θ|x1, . . . , xn] = Z 1 0 θf(θ|x1, . . . , xn)dθ = (n + 1)! s!(n −s)! Z 1 0 θ1+s(1 −θ)n−sdθ = (n + 1)! s!(n −s)! (1 + s)!(n −s)! (n + 2)! = s + 1 n + 2 12"}
{"instruction": "Suppose we have a prior θ ∼N(4, 8), and the likelihood function is ϕ(x1|θ) ∼N(θ, 5). Suppose also that we have one measurement x1 = 3. Show that the posterior distribution is normal. [Divyaraj]", "response": "(a) Prior: f(θ) = c1e−(θ−4)2/16 (b) Likelihood: ϕ(x1|θ) = c2e−(x1−θ)2/10 = c2e−(3−θ)2/10 (c) Posterior: We multiply the prior and likelihood to get the posterior: f(θ|x1) = c3e−(θ−4)2/16e−(3−θ)2/10 = c3 exp \u0012 −(θ −4)2 16 −(3 −θ)2 10 \u0013 We complete the square in the exponent: −(θ −4)2 16 −(3 −θ)2 10 = −5(θ −4)2 80 + −8(3 −θ)2 80 = −130θ2 + 88θ + 152 80 = −θ2 + 88 13θ + 152 13 80/13 Therefore, the posterior is: f(θ|x1) = c4e−(θ−44 13 )2 80 13 This has the form of the probability density function for N(44 13, 40 13)."}
{"instruction": "Suppose that the signal X ∼N(0, σ2 X), is transmitted over a communication channel. Assume that the received signal is given by: Y = aX + bW where W ∼N(0, σ2 W) and W is independent of X. (a) Find the ML estimate of X, given Y=y is observed. (b) Find the MAP estimate of X, given Y=y is observed.", "response": "(a) Proving the distribution using MGF: The moment generating function of W ∼N(0, σ2 W) is: MW(t) = exp \u0012t2σ2 W 2 \u0013 . The received signal is: Y = aX + bW. Conditional on X = x, Y is a linear transformation of W: Y | X = x = ax + bW. The MGF of Y | X = x is: MY |X=x(t) = E[exp(t(ax + bW))]. 13 Substitute Y = ax + bW: MY |X=x(t) = exp(tax) · MW(bt). Since MW(t) = exp(t2σ2 W/2): MY |X=x(t) = exp(tax) · exp \u0012(bt)2σ2 W 2 \u0013 . Simplify: MY |X=x(t) = exp \u0012 tax + b2t2σ2 W 2 \u0013 . This is the MGF of a normal distribution: Y | X = x ∼N(ax, b2σ2 W). (b) The log-likelihood function is: log fY |X(y | x) = −1 2 log(2πb2σ2 W) −(y −ax)2 2b2σ2 W . Ignoring the constant terms, this reduces to: L(x) = −(y −ax)2 2b2σ2 W . To maximize the log-likelihood, minimize the squared error term: (y −ax)2. Differentiating with respect to x and setting the derivative to zero: d dx(y −ax)2 = −2a(y −ax) = 0 =⇒x = y a. Thus, the ML estimate is: ˆXML = y a. (c) Using Bayes’ theorem: fX|Y (x | y) ∝fY |X(y | x)fX(x), where: fX(x) = 1 p 2πσ2 X exp \u0012 −x2 2σ2 X \u0013 , and: fY |X(y | x) ∝exp \u0012 −(y −ax)2 2b2σ2 W \u0013 . Thus: fX|Y (x | y) ∝exp \u0012 −(y −ax)2 2b2σ2 W −x2 2σ2 X \u0013 . The log-posterior is: log fX|Y (x | y) = −(y −ax)2 2b2σ2 W −x2 2σ2 X + constant. 14 Simplify: log fX|Y (x | y) = − a2 2b2σ2 W x2 + ay b2σ2 W x − y2 2b2σ2 W − 1 2σ2 X x2 + constant. Group the quadratic terms: log fX|Y (x | y) = −1 2 \u0012 a2 b2σ2 W + 1 σ2 X \u0013 x2 + ay b2σ2 W x + constant. The posterior is maximized at: xMAP = −B 2A, where: A = 1 2 \u0012 a2 b2σ2 W + 1 σ2 X \u0013 , B = ay b2σ2 W . Simplify: xMAP = ay b2σ2 W a2 b2σ2 W + 1 σ2 X = ayσ2 X a2σ2 X + b2σ2 W . Thus, the MAP estimate is: ˆXMAP = ayσ2 X a2σ2 X + b2σ2 W ."}
{"instruction": "Let Θ be a continuous random variable with pdf as 1 6 for θ ∈[4, 10] and 0 elsewhere. And we know that X = Θ + U[−1, 1]. Find the conditional expectation estimator.", "response": "We aim to derive the conditional expectation estimator E[Θ | X = x] for the random variables Θ and X, given: 1. Θ ∼Uniform[4, 10], with pdf: fΘ(θ) = ( 1 6, 4 ≤θ ≤10, 0, otherwise. 2. X = Θ + U, where U ∼Uniform[−1, 1], and U is independent of Θ. (a) The random variable X has pdf determined by the convolution of fΘ(θ) and fU(u). First, compute the conditional pdf fX|Θ(x | θ). Since X = Θ + U, and U ∼ Uniform[−1, 1], we have: fX|Θ(x | θ) = fU(x −θ) = ( 1 2, θ −1 ≤x ≤θ + 1, 0, otherwise. The joint pdf fX,Θ(x, θ) is: fX,Θ(x, θ) = fΘ(θ)fX|Θ(x | θ). Substituting the values: fX,Θ(x, θ) = ( 1 12, 4 ≤θ ≤10 and θ −1 ≤x ≤θ + 1, 0, otherwise. 15 (b) To find fX(x), integrate fX,Θ(x, θ) over all θ: fX(x) = Z ∞ −∞ fX,Θ(x, θ) dθ. The range of θ depends on x because x ∈[θ −1, θ + 1]. Thus, θ ∈[x −1, x + 1]. Additionally, since θ ∈[4, 10], the valid limits for θ are: max(4, x −1) ≤θ ≤min(10, x + 1). Now, compute fX(x): fX(x) = Z min(10,x+1) max(4,x−1) 1 12 dθ. Evaluate the integral: fX(x) = ( 0, x /∈[3, 11], min(10,x+1)−max(4,x−1) 12 , x ∈[3, 11]. Note: The cases in which the pdf gets divided can be seen from the max and min conditions. Check where the conditions change, those are your case boundaries! Simplify fX(x): - For x ∈[3, 5]: min(10, x + 1) = x + 1 and max(4, x −1) = 4, fX(x) = (x + 1) −4 12 = x −3 12 . - For x ∈[5, 9]: min(10, x + 1) = x + 1 and max(4, x −1) = x −1, fX(x) = (x + 1) −(x −1) 12 = 2 12 = 1 6. - For x ∈[9, 11]: min(10, x + 1) = 10 and max(4, x −1) = x −1, fX(x) = 10 −(x −1) 12 = 11 −x 12 . Thus: fX(x) =          x−3 12 , 3 ≤x < 5, 1 6, 5 ≤x ≤9, 11−x 12 , 9 < x ≤11, 0, otherwise. (c) The conditional pdf is: fΘ|X(θ | x) = fX,Θ(x, θ) fX(x) . For θ ∈[max(4, x −1), min(10, x + 1)]: fΘ|X(θ | x) = ( 1 12 fX(x), max(4, x −1) ≤θ ≤min(10, x + 1), 0, otherwise. (d) Using the conditional pdf: E[Θ | X = x] = Z ∞ −∞ θfΘ|X(θ | x) dθ. Substitute fΘ|X(θ | x): E[Θ | X = x] = 1 fX(x) Z min(10,x+1) max(4,x−1) θ 12 dθ. 16 Evaluate the integral: Z θ 12 dθ = θ2 24. Thus: E[Θ | X = x] = 1 fX(x) \u0014min(10, x + 1)2 24 −max(4, x −1)2 24 \u0015 ."}
{"instruction": "Show that the conditional expectation estimator is the best guess, in terms of minimizing mean square error, i.e. show the following - E[(θ −E[Θ|X])2|X] ≤E[(θ −g(x))2|X] What would be the estimated value of conditional expectation?", "response": "Let us first address the simpler case of no conditioning. What is the value of c for which E[(θ −c)2] is minimum? This is same as E[θ2] + c2 −2cE[θ]. We can just differentiate this expression with c and set it to 0. This yeilds c = E[θ]. We have just shown the following inequality - E[(θ −E[Θ])2] ≤E[(θ −c)2] Now when we enter a conditional world our task is to find c such that E[(θ −c)2|X] is minimized. The answer is just c = E[Θ|X = x]). One can redo the calculation, but there is a clever way to see why this is obvious. Conditioning fundamentally means adding new information to the system. This may or may not revise our relative beliefs about the likelihood of the occurrence of events. If we know that X = x happened, our distribution of Θ will change. In which case the result would still hold for this new distribution, as it is true for all distributions of Θ! Just that expectation will now be over this newer distribution. For expected value of conditional expectation/MMSE, we can see that E[ ˆXM] = E[E[X|Y ]] = E[X] (by the law of iterated expectations). To get a better understanding of the reasoning, refer to this. 17"}
{"instruction": "Let X be a continuous random variable with distribution FX(.) and density fX(x).Find the probability density and cummulative distribution for Y = X2 + 4. [Anush]", "response": "Let FY (y), fY (y) be the CDF and PDF of Y , and FX(x), fX(x) be the CDF and PDF of X, respectively. We have: 1. Cumulative Distribution Function (CDF) FY (y) = P(Y ≤y) = P(X2 + 4 ≤y) = P(X2 ≤y −4) = P(|X| ≤ p y −4) for y > 4 = P \u0010 − p y −4 ≤X ≤ p y −4 \u0011 = FX \u0010p y −4 \u0011 −FX \u0010 − p y −4 \u0011 = Z √y−4 −√y−4 fX(x) dx ∴FY (y) = (R √y−4 −√y−4 fX(x) dx, if y > 4 0, otherwise 2. Probability Density Function (PDF) Now, to find the PDF fY (y), we differentiate the CDF FY (y) with respect to y. fY (y) = d dyFY (y) For y ≤4, we have FY (y) = 0, so fY (y) = 0 for y ≤4. For y > 4, we use Leibniz’s rule for differentiating an integral with vari- able limits: fY (y) = d dy Z √y−4 −√y−4 fX(x) dx ! Applying Leibniz’s rule, we differentiate the integral with respect to y, considering both upper and lower limits: fY (y) = fX \u0010p y −4 \u0011 · d dy \u0010p y −4 \u0011 −fX \u0010 − p y −4 \u0011 · d dy \u0010 − p y −4 \u0011 Now, apply the chain rule to differentiate √y −4 and −√y −4 with respect to y: d dy \u0010p y −4 \u0011 = 1 2√y −4, d dy \u0010 − p y −4 \u0011 = − 1 2√y −4 1 Substituting these into the expression for fY (y), we get: fY (y) = 1 2√y −4 \u0010 fX \u0010p y −4 \u0011 + fX \u0010 − p y −4 \u0011\u0011 3. Final Expressions Thus, the cumulative distribution function FY (y) is: FY (y) = ( 0, if y ≤4 FX \u0000√y −4 \u0001 −FX \u0000−√y −4 \u0001 , if y > 4 The probability density function fY (y) is: fY (y) = ( 0, if y ≤4 1 2√y−4 \u0000fX \u0000√y −4 \u0001 + fX \u0000−√y −4 \u0001\u0001 , if y > 4 Grading Criteria ∗CDF FY in terms of fX - 3 marks ∗PDF fY in terms of fX - 3 marks"}
{"instruction": "Suppose X and Y are independent and exponential random variables with parameter", "response": "and b respectively. Then find P(X < Y ). [Ronak] A: We are given two independent exponential random variables X and Y with parameters a and b, respectively. The goal is to compute P(X < Y ). fX(x) = ae−ax, fY (y) = be−by, x, y ≥0 P(X < Y ) = Z ∞ 0 P(X < y | Y = y)fY (y) dy Since X and Y are independent, we have: P(X < y | Y = y) = P(X < y) P(X < y) = 1 −e−ay (CDF of X) Thus, the expression for P(X < Y ) becomes: P(X < Y ) = Z ∞ 0 (1 −e−ay)be−by dy = Z ∞ 0 be−by dy − Z ∞ 0 be−(a+b)y dy Now, evaluate each integral: Z ∞ 0 be−by dy = 1 Z ∞ 0 be−(a+b)y dy = b a + b Therefore, the final probability is: 2 P(X < Y ) = 1 − b a + b = a a + b Alternate Approach: We can compute P(X < Y ) using the expectation of an indicator variable: P(X < Y ) = E[1{X<Y }] This expectation is written as a double integral over the joint distribution of X and Y : P(X < Y ) = Z ∞ 0 Z ∞ 0 1{x<y}fXY (x, y) dx dy Since X and Y are independent, the joint PDF factors as fX(x)fY (y), and the indicator function 1{x<y} restricts the limits of the inner integral to 0 ≤x < y. Thus, we have: P(X < Y ) = Z ∞ 0 Z y 0 ae−axbe−by dx dy and proceed similarly. Grading Criteria ∗Setting up integral(s) using conditioning and independence - 3 marks ∗Solving the integral(s) and final answer - 3 marks"}
{"instruction": "We are given random variables X1, X2, . . . , Xn with finite variances, and they are not necessarily independent. We need to find the variance of Sn = Pn i=1 Xi and then check how the expression changes when the Xi’s are independent. [Gopal]", "response": "We want to find the variance of the sum Sn: Sn = n X i=1 Xi The variance of a sum of random variables can be written as: Var(Sn) = Var n X i=1 Xi ! Expanding the Variance of the Sum Using the properties of variance, we expand the above expression as fol- lows: Var \u0010X Xi \u0011 = E \u0014\u0010X Xi \u00112\u0015 − \u0010 E hX Xi i\u00112 3 [1 Marks] = E \" n X i=1 X2 i + 2 n X i=1 n X j=i+1 XiXj # − n X i=1 E[Xi] !2 [1 Marks] = E \" n X i=1 X2 i # + 2 n X i=1 n X j=i+1 E[XiXj] − n X i=1 E[Xi] !2 = n X i=1 E[X2 i ] + 2 n X i=1 n X j=i+1 E[XiXj] − n X i=1 (E[Xi])2 −2 n X i=1 n X j=i+1 E[Xi]E[Xj] [1 Marks] = n X i=1 E[X2 i ] − n X i=1 (E[Xi])2 + 2 n X i=1 n X j=i+1 E[XiXj] −2 n X i=1 n X j=i+1 E[Xi]E[Xj] [0.5 Marks for reducing terms to Variance part] [0.5 Marks for reducing terms to Cov part] = n X i=1 E[X2 i ] −(E[Xi])2 + 2 n X i=1 n X j=i+1 E[XiXj] −E[Xi]E[Xj] = n X i=1 Var(Xi) + 2 n X i=1 n X j=i+1 Cov(Xi, Xj) [0.5 for correct answer] B). Special case (when Xi’s are independent): Covariance of independent variables is 0. [0.5 for writing this condi- tion] Var(Sn) = n X i=1 Var(Xi) Thus, when the random variables are independent, the covariance terms drop out, leaving just the sum of the individual variances. [1 Marks for getting final expression]"}
{"instruction": "Let X be a standard normal variable (Gaussian with zero mean and unit variance). Let Z = σX + µ. Obtain the pdf and cdf of Z. [Kavin]", "response": "1 To find the CDF: FZ(z) = P(Z ≤z) (1 for formula) = P(σX + µ ≤z) (where X ∼N(0, 1)) (1 for steps) = P \u0012 X ≤z −µ σ \u0013 (1 for expression) = Φ \u0012z −µ σ \u0013 5 To find the PDF, we can take the derivative of FZ: fZ(z) = d dzFZ(z) (1 for formula) = d dzΦ \u0012z −µ σ \u0013 = 1 σΦ′ \u0012z −µ σ \u0013 (chain rule for derivative) (1 for steps) = 1 σfX \u0012z −µ σ \u0013 = 1 σ √ 2π exp \u001a −(z −µ)2 2σ2 \u001b . (1 for expression) Solution 2 To find the PDF: Z = g(X) = σX + µ =⇒fZ(z) = 1 g′(z−µ σ ) fX(z −µ σ ) (1 for formula) =⇒fZ(z) = 1 σfX(z −µ σ ) (1 for steps) =⇒fZ(z) = 1 σ √ 2π exp \u001a −(z −µ)2 2σ2 \u001b (1 for expression) To find the CDF: FZ(z) = Z z −∞ fZ(u) du (1 for formula) =⇒FZ(z) = Z z −∞ 1 σ √ 2π exp \u001a −(u −µ)2 2σ2 \u001b du (1 for steps) Let t = (u −µ) σ , then σdt = du =⇒FZ(z) = Z z−µ σ −∞ 1 √ 2πe−t2 dt (1 for expression) =⇒FZ(z) = Φ \u0012z −µ σ \u0013 Section B"}
{"instruction": "Suppose U1 and U2 are independent uniform random variables on the segments [−1, 1] and [0, 1] respectively. Let Z = U1 + U2. Derive an expression for the pdf and cdf of Z. 6", "response": "Let X = U1 and Y = U2. Using convolution, fZ(z) = Z ∞ −∞ fX(x) · fY (z −x) dx = Z ∞ −∞ fY (y) · fX(z −y) dy The integration is performed over y, but the parallel case for x will be similar, except the limits will change during the integration (the result will not change). fZ(z) = Z ∞ −∞ fY (y) · fX(z −y) dy The pdf for X ∼U[a, b] (where a < b) is: fX(x) = ( 1 b−a, x ∈[a, b] 0, x ̸∈[a, b] Since the support of Y is [0, 1], for values of y outside this range, fY (y) = 0. Hence, modifying the limits of integration, we get: fZ(z) = Z 1 0 fY (y) · fX(z −y) dy = Z 1 0 1 · fX(z −y) dy = Z 1 0 fX(z −y) dy We haven’t yet substituted the value of fX(z −y) as 1 2 because we don’t know whether z−y will lie in the range of the random variable X. Hence, to get a non-zero value of fX(z −y): −1 ≤z −y ≤1 The range of Z = X + Y is: −1 ≤X ≤1 and 0 ≤Y ≤1 =⇒−1 ≤X + Y ≤2 =⇒−1 ≤Z ≤2 We will now break z into 3 cases: • Case 1: z ∈[−1, 0] =⇒−2 ≤z −y ≤0 But we need z −y ≥−1, which gives: =⇒y ≤z + 1 7 This will act as the new upper limit of our integration. For y ≥z+1, the pdf will take 0 as its value. fZ(z) = Z z+1 0 fX(z −y) dy + Z 1 z+1 fX(z −y) dy = Z z+1 0 fX(z −y) dy + 0 = Z z+1 0 1 2 dy = 1 2 · (z + 1) • Case 2: z ∈[0, 1] =⇒−1 ≤z −y ≤1 This is already within the range of X, so the pdf of X will take a non-zero value for this entire interval. fZ(z) = Z 1 0 fX(z −y) dy = Z 1 0 1 2 dy = 1 2 • Case 3: z ∈[1, 2] =⇒0 ≤z −y ≤2 But we need z −y ≤1, which gives: =⇒y ≥z −1 This will act as the new lower limit of our integration. For y ≤z −1, the pdf will take 0 as its value. fZ(z) = Z z−1 0 fX(z −y) dy + Z 1 z−1 fX(z −y) dy = 0 + Z 1 z−1 1 2 dy = 1 2 · (2 −z) Combining all three cases, the pdf of Z is: fZ(z) =          1 2(z + 1) for z ∈[−1, 0] 1 2 for z ∈[0, 1] 1 2(2 −z) for z ∈[1, 2] 0 otherwise 8 The cdf FZ(z) is obtained by integrating the pdf in each case: FZ(z) =                0 for z < −1 (z+1)2 4 for z ∈[−1, 0] 1 2z + 1 4 for z ∈[0, 1] 1 −(2−z)2 4 for z ∈[1, 2] 1 for z > 2 Note: • For finding cdf, if you plot the graph of pdf and find the area under it for suitable limits, then you can reduce your calculations. • There are other methods to solve this question too. The overall distribution of correct answer would be same for all the methods, but the partial marking would depend on the coherence of the method used (if different from the one given above). Marking Scheme Q1 [Aanvik]: (a) For calculation of pdf, 6 marks will be given. • 3 marks if no calculation for each case given and only the final expression is given. • 2 marks for each case solved (1 mark for the limit simplification and 1 mark for the correct answer.) • 1.5 mark for writing the formulas for convolution and pdf of X and Y correctly. This will only be considered if there is no simplification of any cases mentioned above. (b) For calculation of cdf, 4 marks will be given. • 2 marks if no calculation for each case given and only the final expression is given. • 1 mark combined for mentioning sub case 1 and 5, 1 mark each for the remaining sub cases. 0.5 marks for working and 0.5 marks for correct expression. • 0.5 marks for writing the formula for cdf in terms of pdf. This will only be considered if there is no simplification of any cases mentioned above. Note: The answering scheme is as generic as possible, the split for marks and the weightage of each component will remain same across all the methods."}
{"instruction": "Let X and Y be jointly continuous random variables with joint probability density function (PDF): fX,Y (x, y) = ( 6e−(2x+3y) if x, y ≥0, 0 otherwise. We are required to solve the following: (a) Find E[X] and E[Y ]. 9 (b) Are X and Y independent? Justify. (c) Find E[Y |X > 2]. (d) Find P(X > Y ).", "response": "(a) The marginal PDF of X, denoted as fX(x), is found by integrating the joint PDF fX,Y (x, y) over all values of y: fX(x) = Z ∞ 0 fX,Y (x, y) dy Substitute the joint PDF fX,Y (x, y) = 6e−(2x+3y) for x, y ≥0: fX(x) = Z ∞ 0 6e−(2x+3y) dy Evaluate the integral: fX(x) = 6e−2x Z ∞ 0 e−3y dy The integral R ∞ 0 e−3y dy = 1 3, so: fX(x) = 6e−2x · 1 3 = 2e−2x Thus, the marginal PDF of X is: fX(x) = 2e−2x, x ≥0 The expectation E[X] is given by: E[X] = Z ∞ 0 xfX(x) dx Substitute fX(x) = 2e−2x: E[X] = Z ∞ 0 x · 2e−2x dx Using integration by parts, we get: E[X] = 1 2 ALT: The marginal pdf calculated is the PDF of an exponential random variable with rate parameter λ = 2. The expectation of an exponential random variable is given by: E[X] = 1 λ 10 Thus, the expectation of X is: E[X] = 1 2 Similarly, the marginal PDF of Y , denoted as fY (y), is found by integrat- ing the joint PDF fX,Y (x, y) over all values of x: fY (y) = Z ∞ 0 fX,Y (x, y) dx Substitute fX,Y (x, y) = 6e−(2x+3y): fY (y) = Z ∞ 0 6e−(2x+3y) dx Evaluate the integral: fY (y) = 6e−3y Z ∞ 0 e−2x dx The integral R ∞ 0 e−2x dx = 1 2, so: fY (y) = 6e−3y · 1 2 = 3e−3y Thus, the marginal PDF of Y is: fY (y) = 3e−3y, y ≥0 E[Y ] = 1 λ E[Y ] = 1 3 Ans: E[X] = 1 2; E[Y ] = 1 3 (b) To check if X and Y are independent, we check if the joint PDF can be factored as the product of marginal PDFs: fX(x) = Z ∞ 0 fX,Y (x, y) dy = 6e−2x · 1 3 = 2e−2x fY (y) = Z ∞ 0 fX,Y (x, y) dx = 6e−3y · 1 2 = 3e−3y The joint PDF fX,Y (x, y) = 6e−(2x+3y) can be written as fX(x) · fY (y) = 2e−2x · 3e−3y. Thus, X and Y are independent. (c) 11 Since X and Y are independent, we have E[Y |X > 2] = E[Y ] Ans: E[Y |X > 2] = 1/3 (d) To find P(X > Y ), we compute the following double integral: P(X > Y ) = Z ∞ 0 Z x 0 fX,Y (x, y) dy dx = Z ∞ 0 Z x 0 6e−(2x+3y) dy dx The inner integral evaluates to: Z x 0 e−3y dy = 1 −e−3x 3 Thus, the probability is: P(X > Y ) = Z ∞ 0 6e−2x · 1 −e−3x 3 dx Splitting the integral: P(X > Y ) = 2 Z ∞ 0 e−2x dx −2 Z ∞ 0 e−5x dx = 1 −2 5 = 3 5 ALT: We are given that X and Y are independent exponential random variables with parameters λX = 2 and λY = 3. The probability P(X > Y ) can be computed as: P(X > Y ) = Z ∞ 0 P(X > y | Y = y)fY (y) dy Since P(X > y | Y = y) = P(X > y) = e−2y (because X and Y are independent and X ∼Exp(2)) and the PDF of Y is fY (y) = 3e−3y (since Y ∼Exp(3)), we have: P(X > Y ) = Z ∞ 0 e−2y · 3e−3y dy Simplifying the integrand: P(X > Y ) = 3 Z ∞ 0 e−5y dy The integral of e−5y is: Z ∞ 0 e−5y dy = 1 5 Thus, the probability is: P(X > Y ) = 3 × 1 5 = 3 5 Marking Scheme Q2 [Divyaraj] 12 (a) 2 marks for E[X] and 2 marks for E[Y] • 1 mark for showing integration steps to reach E[X]. • 1 mark for correct answer of E[X]. • The above is also true for E[Y]. (b) For part (b) following Rubric is used:- • 1 mark for writing that X and Y are independent if the joint PDF can be factored as the product of marginal PDFs. • 1 mark for showing it for this Joint PDF. (c) For part (c) following Rubric is used:- • 1 mark for mentioning the fact that since X and Y are indepen- dent, E[Y |X > 2] = E[Y ] . • 1 mark for correctly writing answer. (d) Following rubric is used if you solved by double integral:- • 1 mark for writing the expression of double integral of P(X > Y ). • 0.5 mark for solving correctly each of integral of double integra- tion. Following rubric is used if you solved by conditioning on Y:- • 1 mark for writing expression of P(X > Y ) with conditioning on Y. • 0.5 mark for mentioning how independence is used to simplify expression of P(X > Y ). • 0.5 mark for solving final answer correctly. 13"}
{"instruction": "Consider the Markov chain with three states S = {1, 2, 3} and the state transition diagram given below: Suppose P(X1 = 1) = 1 2 and P(X1 = 2) = 1 4. (a) Find the state transition matrix for this chain. (b) Find P(X1 = 3, X2 = 2, X3 = 1). (c) Find P(X1 = 3, X3 = 1). Figure 1: Transition Diagram Q1", "response": "(a) P =   1 2 0 1 2 1 4 1 2 1 4 0 1 4 3 4   (b) First, we obtain P(X1 = 3) = 1 −P(X1 = 1) −P(X1 = 2) = 1 −1 2 −1 4 = 1 4. Hence, P(X1 = 3, X2 = 2, X3 = 1) = P(X1 = 3) · P32 · P21 = 1 4 · 1 4 · 1 2 = 1 32. 1 (c) Hence, P(X1 = 3, X3 = 1) = P(X1 = 3, X2 = 2, X3 = 1) + P(X1 = 3, X2 = 1, X3 = 1) + P(X1 = 3, X2 = 3, X3 = 1) = P(X1 = 3) · P32 · P21 + P(X1 = 3) · P31 · P11 + P(X1 = 3) · P33 · P31 = 1 4 · 1 4 · 1 2 + 1 4 · 1 2 · 1 + 1 4 · 3 4 · 1 2 = 1 32 + 1 8 + 3 32 = 3 16."}
{"instruction": "Write the transition matrix of the following Markov chains", "response": ") n black balls and n white balls are placed in two urns so that each urn contains n balls. At each stage one ball is selected at random from each urn and the two balls interchange. The state of the system is the number of white balls in the first urn. b) Consider two urns A and B containing a total of n balls. An experiment is performed in which a ball is selected at random at time t(t = 1, . . . ) from among the totality of n balls. Then an urn is selected at random (probability of selecting A is p) and the ball previously drawn is placed in this urn. The state of the system at each trial is the number of balls in A. A: a): Let An denote the stochastic process of the number of white balls in the first urn. We want to find the transition probabilities P(An+1 = j|An = i) for i = 0, 1, . . . n Suppose at stage n there are i white balls in the first urn, and n −i white balls in the second urn (i = 0, 1, . . . n). Since the total number of balls in each urn is n, there will be n −i black balls in the first urn and i black balls in the second urn. Then at stage n + 1, there can be i white balls (if the two balls selected from each urn are both white or black), i −1 white balls (if we select a white ball from the first urn and a black ball from the second urn) or i + 1 (if we select a black ball from the first urn and a white ball from the second urn). Therefore P(An+1 = j|An = i) =          \u0000 i n \u00012 j = i −1 2i(n−i) n2 j = i \u0000 n−i n \u00012 j = i + 1 0 o.w. for i = 1, · · · , n −1. Similarly, for the special cases i = 0 and i = n we have P(An+1 = j|An = 0) = ( 1 j = 1 0 o.w. P(An+1 = j|An = n) = ( 1 j = n −1 0 o.w. b) Let An denote the stochastic process of the number of balls in urn A. We want to find the transition probabilities P(An+1 = j|An = i) for i = 0, 1, . . . n Suppose at stage n there are i balls in urn A and. Then at stage n + 1 there can there can be i balls (select ball from urn A, place in urn A, or select ball from urn B, place in urn B), i −1 balls (select ball from urn A, place in urn B) or i + 1 balls (select from urn B, place in urn A). Therefore, P(An+1 = j|An = i) =          i n (1 −p) j = i −1 i np + n−i n (1 −p) j = i \u0000 n−i n \u0001 p j = i + 1 0 o.w. for i = 1, · · · , n −1. Similarly, for the special cases i = 0 and i = n we have P(An+1 = j|An = 0) =      1 −p j = 0 p j = 1 0 o.w. 3 P(An+1 = j|An = n) =      1 −p j = n −1 p n 0 o.w."}
{"instruction": "Consider a spinner with numbers 1 through 4 that is spun repeatedly. Define the following processes: (a) Let Sn represent the highest number observed on the spinner up to the n-th spin. (b) At the n-th spin, let Tn denote the number of spins required to observe the next “4.” Prove that both Sn and Tn follow the Markov property, and determine the transition probabilities for each process.", "response": "(a) The largest number up to the n-th spin is a number from the set {1, 2, 3, 4}. Since Sn+1 = max{Sn, outcome of the (n + 1)th spin}, Sn+1 depends only on Sn and not on the past. Therefore, Sn satisfies the Markov property. The transition probabilities are: P(Sn+1 = j | Sn = i) =      i 4 if j = i 1 4 if j > i 0 otherwise where i, j ∈{1, 2, 3, 4}. (b) For Tn, if Tn ∈{2, 3, 4, . . .}, then Tn+1 = Tn −1. For example, at time n, if it is given that the next “4” is going to appear in the 8th spin from now, then at time n + 1, we know that the next “4” will appear in the 7th spin from that point. The only non-trivial case is when Tn = 1, meaning that the next “4” will appear on the next spin (i.e., the n + 1-th spin). In this case, the process restarts at time n + 1 and Tn+1 follows a Geometric distribution with probability 1 4. The transition probabilities for Tn are: P(Tn+1 = j | Tn = i) =      1 if j = i −1 and i ≥2 1 4 \u0000 3 4 \u0001j−1 if i = 1 and j ≥1 0 otherwise"}
{"instruction": "Consider the Markov chain in figure below. (a) Find the recurrent classes R1 and R2. (b) Assuming X0 = 3, find the probability that the chain gets absorbed in R1. Figure 2: Markov Chain", "response": "5 Figure 3: Reduced Markov Chain (a) There are two recurrent classes, R1 = {1, 2}, and R2 = {5, 6, 7}. (b) Here, we can replace each recurrent class with one absorbing state. The resulting state diagram is shown below. Now we can apply our standard methodology to find the probability of absorption in state R1. In particular, define ai = P(absorption in R1 | X0 = i), for all i ∈S. By the above definition, we have aR1 = 1, and aR2 = 0. To find the unknown values of ai’s, we can use the following equations ai = X k akpik, for i ∈S. We obtain a3 = 1 2aR1 + 1 2a4 = 1 2 + 1 2a4, a4 = 1 4aR1 + 1 4a3 + 1 2aR2 = 1 4 + 1 4a3. Solving the above equations, we obtain a3 = 5 7, a4 = 3 7. Therefore, if X0 = 3, the chain will end up in class R1 with probability a3 = 5 7."}
{"instruction": "Let X = [X0, X1, . . . ] be a Markov chain having transition matrix P. Recall that for any non- negative integer n, we have P (n) ij = Pr(Xn = j | X0 = i). Then for any m ≥0 and n ≥0, we get P (m+n) ij = X k P (m) ik P (n) kj . This equation is called the Chapman-Kolmogorov equation. Prove this. 6 If X has a finite state space, we can write P (n) as a matrix, called the n-step transition matrix. Then P (n) = P n for all n ≥0.", "response": "By the definition of P (n), we get that P (0)(i, j) = ( 1 if i = j 0 if i ̸= j Hence, the Chapman-Kolmogorov equations are trivially true if m = 0 or n = 0. Now let m ≥1 and n ≥1. Then P (m+n) ij = Pr(Xm+n = j | X0 = i) = X k Pr(Xm+n = j, Xm = k | X0 = i) = X k Pr(Xm+n = j | Xm = k, X0 = i) Pr(Xm = k | X0 = i) (marginalisation) = X k Pr(Xn = j | Xm = k) Pr(Xm = k | X0 = i) (Markov Property) = X k P (m) ik P (n) kj (We can consider m as the starting point of another markov chain.) = [P (m)P (n)]ij When X has a finite state space, the Chapman-Kolmogorov equation can be expressed in matrix form: P (m+n) = P (m)P (n) for all m ≥0 and n ≥0. P (0) = I and P (1) = P by the definition of P (n). The Chapman-Kolmogorov equation gives us P (n+1) = P (n)P (1) = P (n)P. Using math- ematical induction, we can prove that P (n) = P n for all n ≥0. 7"}
{"instruction": "Suppose X ∼N(µ, Σ). Let Y = W −1(X −µ), where W is a matrix that satisfies W 2 = Σ. Obtain the distribution for the random vector Y .", "response": "Let the length of X be n and X = H(Y) = WY + µ. We denote the jacobian of H with J and let W = [wij]n×n. Then J =   w11 w12 · · · w1n w21 w22 · · · w2n ... ... ... ... wn1 wn2 · · · wnn   J = W (Refer to Question 4 solution for explanation to calculate the Jacobian) The pdf of Y is given by fY(y) = fX(H(y))| det(J)| = fX(Wy + µ)|W| = 1 (2π) n 2 p |Σ| exp \u001a −1 2(Wy + µ −µ)T Σ−1(Wy + µ −µ) \u001b |W| = 1 (2π) n 2 |W| exp \u001a −1 2(Wy)T W −1W −1(Wy) \u001b |W| = 1 (2π) n 2 exp \u001a −1 2yT y \u001b Which is the same pdf as the n length standard normal vector. Y ∼N(0, In) . Note that W is a symmetric matrix, because it is decomposition of a given covariance matrix Σ. Note: Other solutions will be given marks appropriately, if they follow correct logic and are coherent with the information given in the question. 1"}
{"instruction": "1. State the Central Limit Theorem. 2. Write the three equivalent definitions for a multivariate Gaussian.", "response": "1. Central Limit Theorem: The Central Limit Theorem states that, given a sufficiently large sample size from a population with a finite level of variance, the mean of all sam- ples from the same population will be approximately normally distributed. This holds regardless of the original distribution of the population, as long as the sample size is large enough. Figure 1: CLT Definition (Refer to L19 Slide 3) 2. Equivalent Definitions for a Multivariate Gaussian: (a) A random vector X ∈Rn is said to follow a multivariate Gaussian (normal) distribution if its probability density function is given by: fX(x) = 1 p (2π)n|Σ| exp \u0012 −1 2(x −µ)⊤Σ−1(x −µ) \u0013 2 where µ ∈Rn is the mean vector and Σ ∈Rn×n is the covariance matrix. (b) A random vector X is multivariate Gaussian if every linear combina- tion of its components is univariate Gaussian. That is, for any vector a ∈Rn, the scalar a⊤X is normally distributed. (c) A random vector X is multivariate Gaussian if it can be written as X = µ + AZ, where Z is a vector of independent standard normal variables and A is a matrix such that Σ = AA⊤. Figure 2: Gaussian Vector Definitions (Refer to L20 Slide 5)"}
{"instruction": "Find the stationary distribution π for Markov chain with the fol- lowing transition probability matrix. (3 marks) State if π is unique. (1 mark) Is the chain irreducible? Give reasons (1 mark) P =   0.2 0.8 0 0 0.9 0.1 0.1 0.9 0  ", "response": "To find the stationary distribution π, we need to solve π = πP and π1 + π2 + π3 = 1 3 This gives us the following equations: π1 = 0.2π1 + 0π2 + 0.1π3 π2 = 0.8π1 + 0.9π2 + 0.9π3 π3 = 0π1 + 0.1π2 + 0π3 π1 + π2 + π3 = 1 Solving these equations, we get: π = ( 1 89, 80 89, 8 89) We can independently verify the uniqueness of this stationary distribution in the following way: πP = π, can be written as: P T πT = πT . which implies that π belongs to the null space of P T −I, where I is the identity matrix. Specifically, we have P T −I =   −0.8 0 0.1 0.8 −0.1 0.9 0 0.1 −1  , which has the following row-reduced echelon form:   1 0 −0.125 0 1 −10 0 0 0  . The row-reduced form indicates that P T −I has rank 2. So by the rank-nullity theorem, its null space (π) is one-dimensional (3-2 = 1). Since π must also be non-negative and sum to 1 (as it’s a probability distribution), these additional constraints uniquely determine the stationary distribution. Irreducibility: Markov chain: 1 2 3 0.2 0.8 0.9 0.1 0.9 0.1 4 p(n) ij denotes the n-step transition probability from state i to state j. It is defined as: p(n) ij = P(Xn = j | X0 = i) The 2-step transition matrix P² is: P 2 =   0.04 0.88 0.08 0.01 0.90 0.09 0.02 0.89 0.09   State 1 and State 2: p1 12 = 0.8 > 0, so 1 →2 p2 21 = 0.1 × 0.1 = 0.01 > 0, so 2 →1 ⇒1 ↔2. State 1 and State 3: p2 13 = 0.8 × 0.1 = 0.08 > 0, so 1 →3 p1 31 = 0.1 > 0, so 3 →1 ⇒1 ↔3. State 2 and State 3: p1 23 = 0.1 > 0, so 2 →3 p1 32 = 0.9 > 0, so 3 →2 ⇒2 ↔3. Since we have demonstrated that any pair of states i and j communicate with each other (i ↔j), the Markov chain is irreducible. In other words, the chain is irreducible since we can go from any state to any other state in a finite number of steps."}
{"instruction": "Suppose X is a standard normal vector of size n. Let Y = AX + b, where A is", "response": "square symmetric invertible matrix. Derive the expression for fY (y). Answer: Let H denote the inverse of G(X) = AX + b Since A is an invertible matrix H(y) = A−1(y −b) where J is the Jacobian of H defined by J =   ∂H1 ∂y1 ∂H1 ∂y2 · · · ∂H1 ∂yn ∂H2 ∂y1 ∂H2 ∂y2 · · · ∂H2 ∂yn ... ... ... ... ∂Hn ∂y1 ∂Hn ∂y2 · · · ∂Hn ∂yn   We can see that, ∂Hi ∂yj is nothing but the (i, j) element of the inverse matrix of A. (Since differentiation drops the constant term b) 5 J =   A−1 11 A−1 12 · · · A−1 1n A−1 21 A−1 22 · · · A−1 2n ... ... ... ... A−1 n1 A−1 n2 · · · A−1 nn   |det(J)| = det(A−1) = 1 | det(A)| Now, we know that fY (y) = fX(H(y) · |det(J)| Thus, fY (y) = fX(A−1(y −b)) · det(A−1) Substitute fX(x) [Note: X is a standard normal vector of size n] Thus,: fX(x) = 1 (2π)n/2 exp \u0012 −1 2xT x \u0013 Thus: fY (y) = 1 (2π)n/2 exp \u0012 −1 2H(y)T H(y) \u0013 · 1 | det(A)| Now, H(y)T H(y) = (y −b)T (A−1)T A−1(y −b) Since (AT )−1 = (A−1)T H(y)T H(y) = (y −b)T (AT )−1A−1(y −b) Since A is symmetric: H(y)T H(y) = (y −b)T (A2)−1(y −b) Thus, fY (y) = 1 (2π)n/2| det(A)| exp \u0012 −1 2(y −b)T (A2)−1(y −b) \u0013 2 10-Marks Questions 2.1"}
{"instruction": "Let (X, Y ) be a pair of random variables with joint PDF fX,Y (x, y). Define", "response": "transformation from (X, Y ) to (U, V ) given by U = X + Y, V = X −Y 6 (a) Find the joint PDF fU,V (u, v) of the transformed random vector (U, V ). (5 mks) (b) Assume fX,Y (x, y) = ce−(x2+y2) for all x, y ∈R. Find c. Find fU,V (u, v) for this specific case and elaborate on what kind of random variables are U and V . Answer: (a) \u0014U V \u0015 = \u0014G1(X, Y ) G2(X, Y ) \u0015 = \u0014X + Y X −Y \u0015 Solving for X and Y in terms of U and V we get X = U + V 2 , Y = U −V 2 Let (x, y) = H(u, v) = \u0000 u+v 2 , u−v 2 \u0001 We now find the determinant of the Jacobian. J = ∂X ∂U ∂X ∂V ∂Y ∂U ∂Y ∂V = 1 2 1 2 1 2 −1 2 = −1 2 We can now use the formula for FU,V (u, v). fU,V (u, v) = |J| fX,Y (H(u, v)) = 1 2fX,Y \u0012u + v 2 , u −v 2 \u0013 (b) To find c we do the following integration. 1 = c Z ∞ −∞ Z ∞ −∞ e−(x2+y2) dxdy = c Z ∞ −∞ e−x2 dx Z ∞ −∞ e−y dy = c√π · √π =⇒c = 1 π Substituting into the formula from the previous question, fU,V (u, v) = 1 2 1 π exp ( − \u0012u + v 2 \u00132 + \u0012u −v 2 \u00132!) = 1 2π exp \u001a −1 4 \u0000(u + v)2 + (u −v)2\u0001\u001b = 1 2π exp \u001a −1 2(u2 + v2) \u001b 7 U, V have the standard bivariate normal distribution. 8"}
{"instruction": "Let X1, X2, . . . , Xn be n i.i.d exponential random variables with parameter λ. Let Zmin = min(X1, X2, . . . , Xn) and Zmax = max(X1, X2, . . . , Xn). Generate Zmin and Zmax.", "response": "The CDF of Zmin is: Gmin(z) = P(Zmin ≤z) = 1 −P(Zmin > z) Since Zmin = min(X1, X2, . . . , Xn): P(Zmin > z) = P(X1 > z, X2 > z, . . . , Xn > z) = n Y i=1 P(Xi > z) = (P(X1 > z))n For Xi ∼Exp(λ): P(Xi > z) = e−λz P(Zmin > z) = e−nλz Therefore, the CDF of Zmin is: Gmin(z) = 1 −e−nλz To generate Zmin: Gmin(z) = U 1 −e−nλz = U z = −1 nλ ln(1 −U) Thus, Zmin = −1 nλ ln(U) The CDF of Zmax is: Gmax(z) = P(Zmax ≤z) = P(X1 ≤z, X2 ≤z, . . . , Xn ≤z) Gmax(z) = (P(X1 ≤z))n For Xi ∼Exp(λ): P(Xi ≤z) = 1 −e−λz Therefore: Gmax(z) = (1 −e−λz)n To generate Zmax: Gmax(z) = U 1 (1 −e−λz)n = U z = −1 λ ln(1 −U 1/n) Thus, to generate from Zmax: Zmax = −1 λ ln(1 −U 1/n)"}
{"instruction": "Let X be a discrete random variable with the following moment-generating function: M(t) = 1 10et + 2 10e2t + 3 10e3t + 4 10e4t for all t. Determine the p.m.f of X.", "response": "The moment-generating function is defined as: M(t) = E[etX] = X x pX(x)etx where pX(x) is the probability mass function. By comparing the given mgf with the general form, we can identify the probabilities associated with the discrete values of X: pX(1) = 1 10, pX(2) = 2 10, pX(3) = 3 10, pX(4) = 4 10. The probability mass function (p.m.f.) pX(x) of X can be expressed as: pX(x) =                1 10 if x = 1 2 10 if x = 2 3 10 if x = 3 4 10 if x = 4 0 otherwise To verify that this is a valid p.m.f., we check that the probabilities sum to 1: pX(1) + pX(2) + pX(3) + pX(4) = 1 10 + 2 10 + 3 10 + 4 10 = 10 10 = 1. 2"}
{"instruction": "Let X and Y be two independent random variables with respective moment gener- ating functions mX(t) = 1 1 −5t, if t < 1 5, mY (t) = 1 (1 −5t)2, if t < 1 5. Find E(X + Y )2.", "response": "First recall that if we let W = X + Y , and using that X, Y are independent, then we see that mW(t) = mX+Y (t) = mX(t)mY (t) = 1 (1 −5t)3, recall that E[W 2] = m′′ W(0), which we can find from m′ W(t) = 15 (1 −5t)4, m′′ W(t) = 300 (1 −5t)5, thus E[W 2] = m′′ W(0) = 300 (1 −0)5 = 300."}
{"instruction": "True or False? If X ∼Exp(λx) and Y ∼Exp(λy), then X + Y ∼Exp(λx + λy). Justify your answer.", "response": "We first find the MGF of X + Y and compare it to the MGF of a random variable V ∼Exp(λx + λy). The MGF of V is mV (t) = λx + λy λx + λy −t, for t < λx + λy. By independence of X and Y , mX+Y (t) = mX(t)mY (t) = λx λx −t · λy λy −t. but λx + λy λx + λy −t ̸= λx λx −t · λy λy −t, and hence the statement is false."}
{"instruction": "Given an integral I = R 2π 0 f(x)dx, solve the following: (a) Write the Monte Carlo Estimate, assuming X′ is are sampled uniformly over the domain. (b) Write the Monte Carlo Estimate, assuming X′ is are sampled according to some PDF g(Xi). 3 (c) Prove that the Monte Carlo Estimates from the previous questions compute the right answer on average.", "response": "(a) We are given samples from U ∼[0, 2π]. Using SLLN, I = 2πE[f(U)] ≈2π N N X i=0 f(Ui) (b) We are given samples of Y with PDF g(·). I = Z 2π 0 f(y) g(y)g(y)dy = E \u0014f(y) g(y) \u0015 ≈1 N N X i=0 f(Yi) g(Yi) (c) We want to show that the expected value of the estimate of I is equal to I. Using linearity of expectation, E \" 2π N N X i=0 f(Ui) # = 2π N N X i=0 E[Ui] = 2πE[U] = I and E \" 1 N N X i=0 f(Yi) g(Yi) # = 1 N N X i=0 E \u0014f(Yi) g(Yi) \u0015 = E \u0014f(Y ) g(Y ) \u0015 = I"}
{"instruction": "Let X ∼Gamma(α, β). Find the MGF of X and its region of convergence. Note: The pdf of Gamma(α, β) is given by fX(x) = βα Γ(α)xα−1e−βx for x ≥0 and Γ(z) = R ∞ 0 tz−1e−tdt.", "response": "MX(t) = E[etX] =⇒MX(t) = βα Γ(α) Z ∞ 0 etxe−βxxα−1dx =⇒MX(t) = βα Γ(α) Z ∞ 0 e−x(β−t)xα−1dx Let x′ = x(β −t) then dx = dx′ β−t =⇒MX(t) = βα Γ(α) Z ∞ 0 e−x′ x′α−1 (β −t)α−1 dx′ β −t =⇒MX(t) = βα Γ(α)(β −t)α Z ∞ 0 e−x′x′α−1dx′ =⇒MX(t) = \u0012 β β −t \u0013α Now looking at the initial expression MX(t) = βα Γ(α) Z ∞ 0 etxe−βxxα−1dx If we take β = t, then our integral R ∞ 0 xα−1dx diverges. If β < t, then our integral R ∞ 0 ekxxk′dx diverges again due to k > 0 and exponential dominating polynomials. So our region of convergence is t < β 4"}
{"instruction": "St. Petersburg Paradox: “A casino offers a game of chance for a single player in which a fair coin is tossed at each stage. The pot starts at 1 dollar and is doubled every time a head appears. The first time a tail appears, the game ends and the player wins whatever is in the pot. Thus the player wins 1 dollar if a tail appears on the first toss, 2 dollars if a head appears on the first toss and a tail on the second, 4 dollars if a head appears on the first two tosses and a tail on the third, 8 dollars if a head appears on the first three tosses and a tail on the fourth, and so on. In short, the player wins 2k−1 dollars if the coin is tossed k times until the first tail appears. What would be a fair price to pay the casino for entering the game?”", "response": "Let X be the amount of money (in dollars) that the player wins. Find E[X]. b. Now suppose that the casino only has a finite amount of money. Specifically, suppose that the maximum amount of the money that the casino will pay you is 230 dollars (around 1.07 billion dollars). That is, if you win more than 230 dollars, the casino is going to pay you only 230 dollars. Let Y be the money that the player wins in this case. Find E[Y ]. A: (a) P(X = 2k−1) = P(coin is tossed k times until the first tail appears) =⇒P(X = 2k−1) = \u00121 2 \u0013k−1 ·1 2 (Since this is a Geometric distribution with p = 1 2) =⇒P(X = 2k−1) = \u00121 2 \u0013k , k = 1, 2, . . . =⇒E[X] = ∞ X k=1 2k−1 · \u00121 2 \u0013k = ∞ X k=1 1 2 = ∞ (b) Define Y as the random variable denoting the money that the player wins in this case. Then Y = ( 2k−1 for k = 1, 2, . . . , 30 230 for k = 31, 32, . . . pY (Y = 2k−1) = 1 2k pY (Y = 230) = ∞ X k=31 1 2k = 1 230 1 −1 2 = 1 229 1 =⇒E[Y ] = 30 X k=1 2k−1 · 1 2k + 230 · 1 229 =⇒E[Y ] = 15 + 2 = 17"}
{"instruction": "Let X be a random variable with mean E[X] = µ. Define the function f(α) as f(α) = E[(X −α)2]. Find the value of α that minimizes f.", "response": "f(α) = E[(X −α)2] = E[X2 + α2 −2Xα] =⇒f(α) = E[X2] + E[α2] + E[−2Xα] (Linearity of Expectation) =⇒f(α) = E[X2] + α2 −2αE[X] To minimize f(α), f ′(α) = 0 =⇒2α −2E[X] = 0 =⇒α = E[X] = µ"}
{"instruction": ": Let X be a binomial random variable with parameters (n, p). What value of p maximizes P{X = k}, k = 0, 1, 2, ..., n?", "response": "The pmf of a binomial random variable X is given by PX(k) = \u0012n k \u0013 pk(1 −p)n−k To find the value of p maximizing this, we differentiate w.r.t p and set the derivative to 0 dPX(k) dp = \u0012n k \u0013 \u0000kpk−1(1 −p)n−k −(n −k)pk(1 −p)n−k−1\u0001 = 0 =⇒k(1 −p) −(n −k)(1 −p) = 0 Solving, we get p = k n"}
{"instruction": "For each of the following random variables, find P(X > 7) and P(3 < X ≤8): (a) X ∼Geometric(0.25) (b) X ∼Binomial(12, 0.4)", "response": "PART (a) Given X ∼Geometric(0.25), we want to find: P(X > 7) and P(3 < X ≤8) The probability mass function for a Geometric distribution is: P(X = k) = (1 −p)k−1p where p = 0.25. 2 Solution for P(X > 7) P(X > 7) = 1 −P(X ≤7) = 1 − 7 X k=1 P(X = k) Since P(X ≤7) = 1 −(1 −p)7, we calculate: P(X > 7) = (1 −0.25)7 = 0.757 ≈0.1335 Solution for P(3 < X ≤8) We have: P(3 < X ≤8) = P(X = 4)+P(X = 5)+P(X = 6)+P(X = 7)+P(X = 8) This is computed as: P(X = k) = (0.75)k−1 × 0.25 Thus: P(3 < X ≤8) = 0.753 × 0.25 + 0.754 × 0.25 + · · · + 0.757 × 0.25 Summing these terms, we get: P(3 < X ≤8) ≈0.246 PART (b) Given X ∼Binomial(12, 0.4), we want to find: P(X > 7) and P(3 < X ≤8) The probability mass function for a Binomial distribution is: P(X = k) = \u0012n k \u0013 pk(1 −p)n−k where n = 12 and p = 0.4. Solution for P(X > 7) P(X > 7) = 1 −P(X ≤7) = 1 − 7 X k=0 P(X = k) Using the binomial formula, we calculate each term and sum to find P(X ≤7), then subtract from 1. 3 Solution for P(3 < X ≤8) P(3 < X ≤8) = P(X = 4)+P(X = 5)+P(X = 6)+P(X = 7)+P(X = 8) Using the binomial formula: P(X = k) = \u001212 k \u0013 (0.4)k(0.6)12−k We calculate these probabilities and sum them to find P(3 < X ≤8)."}
{"instruction": "s. Each question has 5 possible options. You know the correct answer to 7 questions, but for the remaining 8 questions, you guess randomly. Let your total score Z on the quiz be the number of correct answers you get. (a) Find the PMF of Z. (b) What is P(Z > 10)?", "response": "Part (a): Finding the PMF of Z Let’s define the random variable W as the number of correct answers out of the 8 questions you guess randomly. Then your total score will be Z = W + 7. For each of the 8 questions that you guess randomly, the probability of getting the correct answer is 1 5. Since the answers to these 8 questions are independent, W follows a binomial distribution: W ∼Binomial(8, 1 5). Thus, the PMF of W is: pW(w) = (\u00008 w \u0001 \u0000 1 5 \u0001w \u0000 4 5 \u00018−w for w = 0, 1, 2, . . . , 8, 0 otherwise. The range of Z is RZ = {7, 8, 9, . . . , 15}. The PMF of Z can be written as: pZ(7) = P(Z = 7) = P(W +7 = 7) = P(W = 0) = \u00128 0 \u0013 \u00124 5 \u00138 = \u00124 5 \u00138 , pZ(8) = P(Z = 8) = P(W + 7 = 8) = P(W = 1) = \u00128 1 \u0013 \u00121 5 \u0013 \u00124 5 \u00137 , In general, for k ∈RZ = {7, 8, 9, . . . , 15}, pZ(k) = P(Z = k) = P(W+7 = k) = P(W = k−7) = \u0012 8 k −7 \u0013 \u00121 5 \u0013k−7 \u00124 5 \u001315−k . To summarize: 4 pZ(k) = (\u0000 8 k−7 \u0001 \u0000 1 5 \u0001k−7 \u0000 4 5 \u000115−k for k = 7, 8, 9, . . . , 15, 0 otherwise. Part (b): Calculating P(Z > 10) To find P(Z > 10), we need to consider the values k where Z > 10. This corresponds to W = 4, 5, 6, 7, 8: P(Z > 10) = 8 X w=4 \u00128 w \u0013 \u00121 5 \u0013w \u00124 5 \u00138−w , Specifically: pZ(11) = \u00128 4 \u0013 \u00121 5 \u00134 \u00124 5 \u00134 , pZ(12) = \u00128 5 \u0013 \u00121 5 \u00135 \u00124 5 \u00133 , pZ(13) = \u00128 6 \u0013 \u00121 5 \u00136 \u00124 5 \u00132 , pZ(14) = \u00128 7 \u0013 \u00121 5 \u00137 \u00124 5 \u00131 , pZ(15) = \u00128 8 \u0013 \u00121 5 \u00138 \u00124 5 \u00130 . Thus, P(Z > 10) = pZ(11) + pZ(12) + pZ(13) + pZ(14) + pZ(15)."}
{"instruction": "Let X denote a discrete random variable that can take the values -2, -1, M and 2. Given that X has probability distribution function f(X) = (X + 4)/16 , find the variance of X.", "response": "Calculate the value of M using property of summation of probabilies to be 1 and then get the corresponding PMF for X f(x) =          1 8, x = −2 3 16, x = −1 5 16, x = 1 3 8, x = 2 We want to find the variance of X. To do this, we first need to calculate E[X] (the expected value) and E[X2] (the expected value of X2). 5 • Calculate E[X] The expected value E[X] is given by: E[X] = X x x · f(x) Substitute the values: E[X] = (−2) · 1 8 + (−1) · 3 16 + 1 · 5 16 + 2 · 3 8 Convert all terms to a common denominator of 16: E[X] = −2 8 −3 16 + 5 16 + 6 8 E[X] = −4 16 −3 16 + 5 16 + 12 16 E[X] = −4 −3 + 5 + 12 16 E[X] = 10 16 = 5 8 • Calculate E[X2] The expected value E[X2] is given by: E[X2] = X x x2 · f(x) Substitute the values: E[X2] = (−2)2 · 1 8 + (−1)2 · 3 16 + 12 · 5 16 + 22 · 3 8 Calculate each term: E[X2] = 4 · 1 8 + 1 · 3 16 + 1 · 5 16 + 4 · 3 8 E[X2] = 4 8 + 3 16 + 5 16 + 12 8 Convert all terms to a common denominator of 16: 4 8 = 8 16 12 8 = 24 16 E[X2] = 8 16 + 3 16 + 5 16 + 24 16 E[X2] = 8 + 3 + 5 + 24 16 E[X2] = 40 16 = 5 2 6 • Calculate the Variance Var(X) The variance Var(X) is given by: Var(X) = E[X2] −(E[X])2 Substitute the values: (E[X])2 = \u00125 8 \u00132 = 25 64 E[X2] = 5 2 = 160 64 Calculate the variance: Var(X) = 160 64 −25 64 Var(X) = 135 64 Thus, the variance of X is 135 64 . 7"}
{"instruction": "You have two friends, Alice and Bob and they both promised to call you “sometime after 7pm on Saturday”. So you are sitting at home at 7pm on Saturday and you decide to go out with either Alice or Bob, whomever calls you first. Let A be the amount of time before Alice calls you, and B the amount of time before Bob calls you. Assume A and B are independent exponential random variables; the expectation of A is 60 minutes and the expectation of B is 30 minutes. What is the probability that you will go out with Alice?", "response": "The question asks for P(B ≥A). Note that the joint density function of (A, B) is f(x, y) = 1 60 · 1 30 exp \u0010 −x 60 −y 30 \u0011 if x, y > 0 and 0 otherwise. So the answer is P(B ≥A) = Z ∞ 0 Z ∞ x 1 60 · 1 30 exp \u0010 −x 60 −y 30 \u0011 dy dx. Switching the order of integration, P(B ≥A) = Z ∞ 0 Z y 0 1 60 · 1 30 exp \u0010 −x 60 −y 30 \u0011 dx dy. Integrating with respect to x, P(B ≥A) = Z ∞ 0 \u0014 −1 30 exp \u0010 −x 60 −y 30 \u0011\u0015x=y x=0 dy. P(B ≥A) = Z ∞ 0 1 30 h exp \u0010 −y 30 \u0011 −exp \u0010 −y 60 −y 30 \u0011i dy. P(B ≥A) = Z ∞ 0 1 30 h exp \u0010 −y 30 \u0011 −exp \u0010 −y 20 \u0011i dy. Evaluating the integrals, Z ∞ 0 1 30 exp \u0010 −y 30 \u0011 dy = 1, Z ∞ 0 1 30 exp \u0010 −y 20 \u0011 dy = 2 3. Thus, P(B ≥A) = 1 −2 3 = 1 3."}
{"instruction": "X is a random variable distributed uniformly in the interval [0, 1]. Let Y = min(X, 1−X). Calculate the probability density function and expected value of Y . 1", "response": "First, find the cumulative distribution function (CDF) of Y : FY (y) = P(Y ≤y). For Y = min(X, 1 −X) to be less than or equal to y: P(min(X, 1 −X) ≤y) = 1 −P(X ≥y and 1 −X ≥y). The condition X ≥y and 1 −X ≥y implies: P(y ≤X ≤1 −y) = (1 −y) −y = 1 −2y. Thus, the CDF is: FY (y) = 1 −(1 −2y) = 2y. The probability density function (PDF) fY (y) is: fY (y) = d dyFY (y) = 2 for 0 ≤y ≤1 2. Thus, the expected value of Y is: E[Y ] = Z 1 2 0 2y dy = 1 4."}
{"instruction": "Suppose that buses arrive are scheduled to arrive at a bus stop at noon but are always X minutes late, where X is an exponential random variable with probability density function fX(x) = λe−λx. Suppose that you arrive at the bus stop precisely at noon. (a) Compute the probability that you have to wait for more than five minutes for the bus to arrive. (b) Suppose that you have already waiting for 10 minutes. Compute the proba- bility that you have to wait an additional five minutes or more.", "response": "(a) We compute P(X ≥5) = 1−P(X < 5) = 1− Z 5 0 λe−λxdx = 1− \u00001 −e−5λ\u0001 = e−5λ. (b) We want P(X ≥15 | X ≥10). First observe that P(X ≥15, X ≥ 10) = P(X ≥15). From similar computations in (a), we know P(X ≥15) = e−15λ and P(X ≥10) = e−10λ. From the definition of conditional probability, P(X ≥15 | X ≥10) = P(X ≥15, X ≥10) P(X ≥10) = P(X ≥15) P(X ≥10) = e−5λ. Note: This is an illustration of the memorylessness property of the exponential distribution. 2"}
{"instruction": "Let X and Y be two continuous random variables with joint pdf f(x, y) = ( cx2y(1 + y) for 0 ≤x, y ≤3 0 otherwise. (a) Find the value of c. (b) Find the probability P(1 ≤X ≤2, 0 ≤Y ≤1). (c) Determine the joint cumulative distribution function (CDF), F(a, b), of X and Y for a and b between 0 and 3. (d) Find the marginal CDF FX(a) for a between 0 and 3. (e) Find the marginal probability density function (PDF) fX(x) directly from f(x, y) and check that it is the derivative of FX(x). (f) Are X and Y independent?", "response": "(a) Total probability must be 1, so 1 = Z 3 0 Z 3 0 f(x, y)dy dx = Z 3 0 Z 3 0 c(x2y + x2y2)dy dx = c · 243 2 (Here we skipped showing the arithmetic of the integration) Therefore, c = 2 243 (b) P(1 ≤X ≤2, 0 ≤Y ≤1) = Z 2 1 Z 1 0 f(x, y)dy dx = Z 2 1 Z 1 0 c(x2y + x2y2)dy dx = c · 35 18 = 70 4374 ≈0.016 (c) For 0 ≤a ≤3 and 0 ≤b ≤3 we have F(a, b) = Z a 0 Z b 0 f(x, y)dy dx = c(a3b2 6 + a3b3 9 ) (d) Since y = 3 is the maximum value for Y, we have FX(a) = F(a, 3) = c(9a3 6 + 3a3) = 9 2c a3 = a3 27 (e) For 0 ≤x ≤3 we have, by integrating over the entire range for y, fX(x) = Z 3 0 f(x, y)dy = cx2(32 2 + 33 3 ) = c27 2 x2 = 1 9x2. This is consistent with (c) because d dx(x3/27) = x2/9 (f) Since f(x, y) separates into a product as a function of a times a func- tion of y we know X and Y are independent. 3"}
{"instruction": "Let X and W be random variables. Let Y = X + W. Suppose that the joint probability density of X and Y is fX,Y (x, y) = λ2e−λy, 0 < x < y < ∞ (a) Find the density of X. (b) Find the density of Y . (c) Find the joint density of X and W. (d) Find the density of W.", "response": "(a) fX(x) = R ∞ x λ2e−λydy = −λ2 h e−λy −λ i∞ x = λe−λx (b) fY (y) = λ2e−λy R y 0 dx = λ2ye−λy (c) fX,W(x, w) = f(X = x, W = w) = f(X = x, Y = x + w) = λ2e−λ(x+w) = λ2e−λwe−λx (d) fW(w) = R ∞ 0 fX,W(x, w)dx = λ2e−λw R ∞ 0 e−λxdx = λe−λw"}
{"instruction": "Let X be an exponential random variable with parameter λ. Suppose random variable Y = −ln X (a) Find FY (a). (b) Find fY (y).", "response": "(a) P(Y ≤a) = P(−ln X ≤a) = P(X ≥e−a) P(X ≥e−a) = 1 −FX(e−a) = λe−λe−a (b) Let Y = g(X). Let h(Y ) = g−1(Y ) = e−Y . As X increases, Y decreases. So, FY (y) = P(g(X) ≤y) = P(X ≥h(y)) = 1 −FX(h(y)) Using chain rule, fy(Y ) = d dy(1 −FX(h(y)) = e−yfx(e−y) = λe−ye−λe−y 4"}
