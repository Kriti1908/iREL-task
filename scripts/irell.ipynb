{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14199605,"sourceType":"datasetVersion","datasetId":9055634},{"sourceId":14200012,"sourceType":"datasetVersion","datasetId":9055925},{"sourceId":14200115,"sourceType":"datasetVersion","datasetId":9056009}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q \\\n    transformers \\\n    accelerate \\\n    peft \\\n    bitsandbytes \\\n    datasets \\\n    sentence-transformers \\\n    faiss-cpu \\\n    pymupdf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-17T18:39:37.687998Z","iopub.execute_input":"2025-12-17T18:39:37.688776Z","iopub.status.idle":"2025-12-17T18:39:44.914554Z","shell.execute_reply.started":"2025-12-17T18:39:37.688745Z","shell.execute_reply":"2025-12-17T18:39:44.913812Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import torch\nimport faiss\nimport json\nimport numpy as np\nimport fitz\nfrom datasets import load_dataset\nfrom sentence_transformers import SentenceTransformer\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    Trainer\n)\nfrom peft import LoraConfig, get_peft_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T18:39:44.921396Z","iopub.execute_input":"2025-12-17T18:39:44.921699Z","iopub.status.idle":"2025-12-17T18:40:11.415680Z","shell.execute_reply.started":"2025-12-17T18:39:44.921670Z","shell.execute_reply":"2025-12-17T18:40:11.415033Z"}},"outputs":[{"name":"stderr","text":"2025-12-17 18:39:55.941196: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765996796.121744      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765996796.179062      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1765996796.627021      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1765996796.627059      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1765996796.627062      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1765996796.627064      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"MODEL_NAME = \"Qwen/Qwen3-4B\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\"\n)\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME,\n    quantization_config=bnb_config,\n    device_map=\"auto\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T18:40:11.416776Z","iopub.execute_input":"2025-12-17T18:40:11.417560Z","iopub.status.idle":"2025-12-17T18:40:52.711974Z","shell.execute_reply.started":"2025-12-17T18:40:11.417517Z","shell.execute_reply":"2025-12-17T18:40:52.711326Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45d42ddd3281499d9be3958a05344237"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce31dcdeddcb4012988111543130d1a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26cf3715adcd42fc9181cba548523128"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b4e50c5861f4b959af457e7b79861c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/726 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9cc96a4d68b4fa8b00dbe2e9f927e5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5939df9bcb7e43fea7c0efb3bb6dbda5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4dd5d6e57744bac9db749d59d272ca3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"148b3eb624fd4c30ab41ed5dd388136c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d76d0a452a54e02b37a2830b9158c4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/99.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"107cd162d51941c18862de13cd52eb1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6da1faa753f4268813df50a80a7dc01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1368e057c959420e90d34a849c75f751"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=[\"q_proj\", \"v_proj\"],\n    lora_dropout=0.05,\n    task_type=\"CAUSAL_LM\"\n)\n\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T18:40:52.713844Z","iopub.execute_input":"2025-12-17T18:40:52.714602Z","iopub.status.idle":"2025-12-17T18:40:52.833812Z","shell.execute_reply.started":"2025-12-17T18:40:52.714573Z","shell.execute_reply":"2025-12-17T18:40:52.833164Z"}},"outputs":[{"name":"stdout","text":"trainable params: 2,949,120 || all params: 4,025,417,216 || trainable%: 0.0733\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"dataset = load_dataset(\n    \"json\",\n    data_files=\"/kaggle/input/lora-train-json/lora_train.jsonl\"\n)\n\ndef tokenize(example):\n    messages = [\n        {\"role\": \"user\", \"content\": example[\"instruction\"]},\n        {\"role\": \"assistant\", \"content\": example[\"response\"]}\n    ]\n\n    text = tokenizer.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=False\n    )\n\n    out = tokenizer(\n        text,\n        truncation=True,\n        max_length=512\n    )\n    out[\"labels\"] = out[\"input_ids\"].copy()\n    return out\n\ndataset = dataset.map(tokenize, remove_columns=dataset[\"train\"].column_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T18:49:55.550287Z","iopub.execute_input":"2025-12-17T18:49:55.550858Z","iopub.status.idle":"2025-12-17T18:49:56.229835Z","shell.execute_reply.started":"2025-12-17T18:49:55.550827Z","shell.execute_reply":"2025-12-17T18:49:56.229001Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba737baaf8204e2f8699d73b01cf913e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/128 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58d31ed795074a54877c1b9cfab5bddf"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"args = TrainingArguments(\n    output_dir=\"lora_out\",\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=4,\n    num_train_epochs=2,\n    logging_steps=10,\n    save_strategy=\"epoch\",\n    optim=\"paged_adamw_8bit\",\n    fp16=True,\n    report_to=\"none\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=dataset[\"train\"]\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T18:50:04.303431Z","iopub.execute_input":"2025-12-17T18:50:04.303772Z","iopub.status.idle":"2025-12-17T18:53:37.250304Z","shell.execute_reply.started":"2025-12-17T18:50:04.303742Z","shell.execute_reply":"2025-12-17T18:53:37.249735Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [64/64 03:28, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>1.910300</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.639400</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.594500</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.424100</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.486100</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.333800</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=64, training_loss=1.556925855576992, metrics={'train_runtime': 212.4014, 'train_samples_per_second': 1.205, 'train_steps_per_second': 0.301, 'total_flos': 2236379911907328.0, 'train_loss': 1.556925855576992, 'epoch': 2.0})"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"model.save_pretrained(\"qwen3-4b-course\")\ntokenizer.save_pretrained(\"qwen3-4b-course\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T18:58:13.744105Z","iopub.execute_input":"2025-12-17T18:58:13.744459Z","iopub.status.idle":"2025-12-17T18:58:14.316363Z","shell.execute_reply.started":"2025-12-17T18:58:13.744426Z","shell.execute_reply":"2025-12-17T18:58:14.315595Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"('qwen3-4b-course/tokenizer_config.json',\n 'qwen3-4b-course/special_tokens_map.json',\n 'qwen3-4b-course/chat_template.jinja',\n 'qwen3-4b-course/vocab.json',\n 'qwen3-4b-course/merges.txt',\n 'qwen3-4b-course/added_tokens.json',\n 'qwen3-4b-course/tokenizer.json')"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"index = faiss.read_index(\"/kaggle/input/vectorstore/index.faiss\")\ntexts = np.load(\"/kaggle/input/vectorstore/texts.npy\", allow_pickle=True)\n\nembedder = SentenceTransformer(\"intfloat/e5-base-v2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T19:33:40.008428Z","iopub.execute_input":"2025-12-17T19:33:40.009188Z","iopub.status.idle":"2025-12-17T19:33:44.775308Z","shell.execute_reply.started":"2025-12-17T19:33:40.009157Z","shell.execute_reply":"2025-12-17T19:33:44.774554Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e61e4f5c5e59444a8dba03b6ed44f1d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7cf2a75eae84392a7defba786f38581"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f2cef36db174e81a8688560f5eb4743"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58e390e260094bfcaf0d7bd15396cea0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2943714ae90849ec9013d423c93aa6c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b07e6f7d13a41b3a959b7009d831706"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"164af9e768884fc6a548853fbb5e136a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac72bdd350e2464e88ec09029d7c6b7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fb9063adb014a87a395fdc8528e508d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bea3246db2448699dcf7cfe2a3715b4"}},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"def youtube_search(q):\n    return f\"https://www.youtube.com/results?search_query={q.replace(' ', '+')}\"\n\ndef arxiv_search(q):\n    return f\"https://arxiv.org/search/?query={q.replace(' ', '+')}&searchtype=all\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T19:33:53.602099Z","iopub.execute_input":"2025-12-17T19:33:53.602840Z","iopub.status.idle":"2025-12-17T19:33:53.606813Z","shell.execute_reply.started":"2025-12-17T19:33:53.602805Z","shell.execute_reply":"2025-12-17T19:33:53.605952Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def retrieve_context(question, k=4):\n    emb = embedder.encode([question]).astype(\"float32\")\n    _, idx = index.search(emb, k)\n    return \"\\n\\n\".join(texts[i] for i in idx[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T19:34:07.606402Z","iopub.execute_input":"2025-12-17T19:34:07.607102Z","iopub.status.idle":"2025-12-17T19:34:07.610892Z","shell.execute_reply.started":"2025-12-17T19:34:07.607069Z","shell.execute_reply":"2025-12-17T19:34:07.610208Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def generate_answer(question):\n    context = retrieve_context(question)\n\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": \"You are an IIIT course assistant.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": f\"\"\"\nContext:\n{context}\n\nQuestion:\n{question}\n\nAnswer clearly, completely, and in a structured manner.\n\"\"\"\n        }\n    ]\n\n    text = tokenizer.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=True\n    )\n\n    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n\n    output = model.generate(\n        **inputs,\n        max_new_tokens=2048,\n        temperature=0.6,\n        top_p=0.95\n    )\n\n    answer = tokenizer.decode(output[0], skip_special_tokens=True)\n\n    # ‚úÖ ADD THESE\n    yt_links = youtube_search(question)\n    arxiv_links = arxiv_search(question)\n\n    # Safety: ensure lists\n    if isinstance(yt_links, str):\n        yt_links = [yt_links]\n    if isinstance(arxiv_links, str):\n        arxiv_links = [arxiv_links]\n\n    return {\n        \"answer\": answer,\n        \"youtube\": yt_links,\n        \"papers\": arxiv_links\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T19:34:11.271918Z","iopub.execute_input":"2025-12-17T19:34:11.272488Z","iopub.status.idle":"2025-12-17T19:34:11.278304Z","shell.execute_reply.started":"2025-12-17T19:34:11.272457Z","shell.execute_reply":"2025-12-17T19:34:11.277591Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"# Validation","metadata":{}},{"cell_type":"code","source":"# üîç Trial test cell ‚Äî verify RAG + LoRA model works end-to-end\ntest_question = \"What is a random variable? Explain with examples.\"\n\nprint(\"=\" * 70)\nprint(\" IIIT Course Assistant ‚Äì Trial RAG Test\")\nprint(\"=\" * 70)\n\nprint(\"\\nüßë‚Äçüéì Question:\")\nprint(test_question)\n\nprint(\"\\nüîç Thinking...\\n\")\n\nresult = generate_answer(test_question)\n\nprint(\"üìò Answer:\")\nprint(\"-\" * 70)\nprint(result[\"answer\"].strip())\nprint(\"-\" * 70)\n\nif result.get(\"youtube\"):\n    print(\"\\nüì∫ Suggested YouTube Videos:\")\n    for link in result[\"youtube\"]:\n        print(\"  ‚Ä¢\", link)\n\nif result.get(\"papers\"):\n    print(\"\\nüìÑ Relevant Research Papers:\")\n    for paper in result[\"papers\"]:\n        print(\"  ‚Ä¢\", paper)\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"‚úÖ Trial test completed successfully\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T19:34:16.422011Z","iopub.execute_input":"2025-12-17T19:34:16.422324Z","iopub.status.idle":"2025-12-17T19:37:09.935464Z","shell.execute_reply.started":"2025-12-17T19:34:16.422295Z","shell.execute_reply":"2025-12-17T19:37:09.934684Z"}},"outputs":[{"name":"stdout","text":"======================================================================\n IIIT Course Assistant ‚Äì Trial RAG Test\n======================================================================\n\nüßë‚Äçüéì Question:\nWhat is a random variable? Explain with examples.\n\nüîç Thinking...\n\nüìò Answer:\n----------------------------------------------------------------------\nsystem\nYou are an IIIT course assistant.\nuser\n\nContext:\nContinuous random variables\n‚ñ∂A random variable defined on R is discrete, if FX(¬∑) is\npiecewise constant.\n‚ñ∂A random variable defined on R is continuous, if FX(¬∑) is a\ncontinuous function.\n‚ñ∂Examples of Continuous random variables\n1. Pick a number uniformly from [a, b].\n2. Time interval between successive customers entering DMart.\n3. Travel time from office to home.\n4. Level of water in a dam or pending workload on a server.\n8 / 29\n\nExample of function of Random variables\n‚ñ∂Suppose X and Y are continuous independent random\nvariables. Let W = max(X, Y ) and Z = min(X, Y ) Find the\nCDF and pdf of Z.\n‚ñ∂HW: When X and Y are exponential with parameters Œª1 and\nŒª2 then Z is also exponential with parameter Œª1 + Œª2.\n5 / 42\n\nA running example\n‚ñ∂Consider an experiment of tossing a coin and a dice together.\n‚ñ∂Œ©= {0, 1} √ó {1, 2, 3, 4, 5, 6}.\nF = 2Œ©.\nP(œâ) =\n1\n12.\n‚ñ∂Let X and Y denote the random variables depicting outcome\nof a coin and dice respectively.\n‚ñ∂For œâ = (1, 5) we have X(œâ) = 1 and Y (œâ) = 5.\n‚ñ∂We are now interested in the joint PMF pXY (x, y) and joint\nCDF FXY (x, y) of X and Y together.\n10 / 28\n\n\nFrequentist or Classical Inference\n‚ñ∂Classical Inference models the unknown quantity as a constant\nand come up with estimators that are deterministic functions\nof the observed data.\n‚ñ∂Given data, these estimators are deterministic functions of the\ndata, but in reality are also random variables.\n‚ñ∂For example sample mean as an estimator for the mean.\n5 / 25\n\nQuestion:\nWhat is a random variable? Explain with examples.\n\nAnswer clearly, completely, and in a structured manner.\n\nassistant\n<think>\nOkay, the user is asking about what a random variable is, with examples. Let me start by recalling the definitions from the context provided. The context mentions that a random variable is discrete if its CDF is piecewise constant and continuous if the CDF is a continuous function.\n\nFirst, I need to define a random variable. From what I remember, a random variable is a function that assigns a numerical value to each outcome in a sample space. So, in simpler terms, it's a variable whose value is determined by a random process.\n\nThen, I should explain the difference between discrete and continuous random variables. The context gives examples like uniform distribution over [a,b], time between customers, etc. For discrete, examples might be the number of heads in coin tosses, while continuous could be height or temperature.\n\nWait, the user also mentioned the running example with a coin and dice. Maybe I should include that as an example of a random variable. In that case, X could be the coin result (0 or 1) and Y the dice result (1-6). That's a discrete random variable.\n\nAlso, the examples given in the context: uniform from [a,b], time between customers, travel time, water level. These are all continuous. So I should list both types with examples.\n\nBut wait, the user is asking for an explanation, so I need to structure the answer clearly. Start with the definition, then differentiate between discrete and continuous, give examples for each, and maybe mention the CDF and PDF.\n\nI need to make sure I don't confuse the concepts. Also, the user might be a student who is just starting to learn about random variables, so clarity is key. They might need a clear distinction between discrete and continuous, and examples that are easy to understand.\n\nWait, the context also mentions that the CDF is piecewise constant for discrete and continuous for continuous. So in the answer, I should explain that the CDF's form determines the type of random variable.\n\nAlso, the examples from the context: uniform distribution, exponential, etc. But the user might not know what those are, so maybe I should explain them briefly.\n\nLet me outline the answer:\n\n1. Definition of a random variable.\n2. Discrete vs. Continuous.\n3. Examples for each.\n4. CDF and PDF as indicators.\n5. Mention the running example if possible.\n\nWait, the user also mentioned the example of the coin and dice. That's a good example to use. In that case, X and Y are discrete random variables. So I can use that as an example of a discrete random variable.\n\nAlso, the user might be confused between a random variable and a probability distribution. So I need to clarify that a random variable is a function, while the distribution is the probability measure.\n\nBut the question is about the definition and examples. So focus on that.\n\nAnother point: the answer should be structured. So maybe start with the definition, then types, examples, and maybe a note on CDF and PDF.\n\nAlso, the user might have seen the term \"random variable\" in different contexts, so it's important to clarify that it's a function from the sample space to real numbers, and that it can be discrete or continuous.\n\nI should avoid jargon as much as possible. For example, explain that in the coin and dice example, each outcome (like (1,5)) maps to a value via X and Y.\n\nSo, putting it all together: define, differentiate, give examples, and maybe mention the CDF and PDF as part of the explanation.\n</think>\n\n### **What is a Random Variable?**  \nA **random variable** is a function that assigns a numerical value to each outcome in a sample space. It represents a quantity that can take on different values based on the outcome of a random experiment. Random variables can be **discrete** (taking on countable values) or **continuous** (taking on uncountable values in an interval).  \n\n---\n\n### **Key Concepts**  \n1. **Discrete Random Variable**:  \n   - **Definition**: Takes on a countable number of distinct values.  \n   - **CDF (Cumulative Distribution Function)**: Piecewise constant (jumps at specific points).  \n   - **Examples**:  \n     - Number of heads in 3 coin tosses (values: 0, 1, 2, 3).  \n     - Roll of a die (values: 1, 2, 3, 4, 5, 6).  \n\n2. **Continuous Random Variable**:  \n   - **Definition**: Takes on uncountable values within a range (interval).  \n   - **CDF**: Continuous and smooth (no jumps).  \n   - **Examples**:  \n     - Height of a randomly selected person (any real number in a range).  \n     - Time between arrivals at a DMart (any non-negative real number).  \n\n---\n\n### **Examples**  \n1. **Discrete**:  \n   - **Coin and Dice Example**:  \n     - Let $ X $ be the result of a coin toss (0 for heads, 1 for tails).  \n     - Let $ Y $ be the result of a die roll (1‚Äì6).  \n     - $ X $ and $ Y $ are discrete random variables.  \n     - For outcome $ (1, 5) $, $ X = 1 $, $ Y = 5 $.  \n\n2. **Continuous**:  \n   - **Uniform Distribution on [a, b]**:  \n     - A number chosen uniformly at random between $ a $ and $ b $ (e.g., $ a = 0 $, $ b = 1 $).  \n   - **Exponential Distribution**:  \n     - Time between arrivals in a Poisson process (e.g., customer arrivals at a DMart).  \n\n---\n\n### **CDF and PDF**  \n- **Discrete**: CDF is piecewise constant, and the probability mass function (PMF) describes the probability at each value.  \n- **Continuous**: CDF is continuous, and the probability density function (PDF) describes the density of probabilities over intervals.  \n\n---\n\n### **Key Takeaway**  \nA random variable is a mathematical tool that maps outcomes of a random experiment to numerical values, enabling probabilistic analysis. Discrete variables have countable outcomes, while continuous variables have outcomes in an uncountable range.\n----------------------------------------------------------------------\n\nüì∫ Suggested YouTube Videos:\n  ‚Ä¢ https://www.youtube.com/results?search_query=What+is+a+random+variable?+Explain+with+examples.\n\nüìÑ Relevant Research Papers:\n  ‚Ä¢ https://arxiv.org/search/?query=What+is+a+random+variable?+Explain+with+examples.&searchtype=all\n\n======================================================================\n‚úÖ Trial test completed successfully\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"# Test","metadata":{}},{"cell_type":"code","source":"# doc = fitz.open(\"/kaggle/input/endsem/endsem.pdf\")\n# questions = []\n\n# for page in doc:\n#     for line in page.get_text().split(\"\\n\"):\n#         if line.lower().startswith((\"q\", \"question\")):\n#             questions.append(line)\n\n# results = {}\n# for i, q in enumerate(questions):\n#     results[f\"Q{i+1}\"] = generate_answer(q)\n\n# with open(\"endsem_results.json\", \"w\") as f:\n#     json.dump(results, f, indent=2)\nimport json\nimport re\n\nPDF_PATH = \"/kaggle/input/endsem/endsem_solutions.pdf\" \n\ndef extract_questions_from_solutions(pdf_path):\n    doc = fitz.open(pdf_path)\n    full_text = \"\"\n    for page in doc:\n        full_text += page.get_text()\n    \n    # regex to find patterns like \"Q1:\", \"Q2:\", \"(a)\", \"(b)\" etc.\n    # This splits the text based on \"Q\" followed by a number and a colon\n    question_blocks = re.split(r'(Q\\d+[:])', full_text)\n    \n    extracted_questions = []\n    # The first element is usually header text, so we skip it\n    for i in range(1, len(question_blocks), 2):\n        q_marker = question_blocks[i]      # e.g., \"Q1:\"\n        q_content = question_blocks[i+1]    # The text following it\n        \n        # We stop the question text before the answer \"A:\" begins\n        actual_question = q_content.split('A:')[0].strip()\n        extracted_questions.append(f\"{q_marker} {actual_question}\")\n        \n    return extracted_questions\n\n# 1. Extract the questions\nprint(\"Reading questions from PDF...\")\nquestions_to_test = extract_questions_from_solutions(PDF_PATH)\n\n# 2. Run inference on each extracted question\nresults = {}\nprint(f\"Found {len(questions_to_test)} questions. Starting inference...\\n\")\n\nfor i, q_text in enumerate(questions_to_test):\n    print(f\"Testing {q_text[:50]}...\")\n    try:\n        # Using the generate_answer function from your notebook\n        ans_data = generate_answer(q_text)\n        results[f\"Question_{i+1}\"] = {\n            \"input_question\": q_text,\n            \"agent_answer\": ans_data[\"answer\"],\n            \"suggested_resources\": {\n                \"youtube\": ans_data[\"youtube\"],\n                \"papers\": ans_data[\"papers\"]\n            }\n        }\n    except Exception as e:\n        print(f\"Error processing question {i+1}: {e}\")\n\n# 3. Save the agent's performance to a JSON file\noutput_file = \"agent_test_results.json\"\nwith open(output_file, \"w\") as f:\n    json.dump(results, f, indent=4)\n\nprint(f\"\\n‚úÖ Testing complete. Results saved to {output_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T19:47:01.422212Z","iopub.execute_input":"2025-12-17T19:47:01.422519Z","iopub.status.idle":"2025-12-17T20:38:36.576101Z","shell.execute_reply.started":"2025-12-17T19:47:01.422490Z","shell.execute_reply":"2025-12-17T20:38:36.575488Z"}},"outputs":[{"name":"stdout","text":"Reading questions from PDF...\nFound 12 questions. Starting inference...\n\nTesting Q1: Let Z = X1 + X2 + ¬∑ ¬∑ ¬∑ + XN, where Xi are i.i...\nTesting Q2: Let Y = eX, where X ‚àºN(¬µ, œÉ2). Obtain the pdf ...\nTesting Q1: Let D = {x1, x2, . . . , xn} denote i.i.d. sam...\nTesting Q2: Consider a Gaussian random variable X with a k...\nTesting Q3: Consider a sequence {Xn, n = 1, 2, 3, . . . } ...\nTesting Q4: Given a Markov coin with the following transit...\nTesting Q5: Let X and Y be independent random variables wi...\nTesting Q1: Let D = {x1, . . . xn} denote i.i.d. samples f...\nTesting Q2: Bayesian Inference/ Conjugate prior problem: S...\nTesting Q3: (i) For a Markov chain, let Fii denote the pro...\nTesting Q4: Gaussian: Suppose X = AZ + ¬µ, where A is an n ...\nTesting Q5: Shifted Exponential: Let X be a random variabl...\n\n‚úÖ Testing complete. Results saved to agent_test_results.json\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"!zip -r working.zip /kaggle/working","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-17T20:47:54.310426Z","iopub.execute_input":"2025-12-17T20:47:54.311293Z","iopub.status.idle":"2025-12-17T20:47:57.687327Z","shell.execute_reply.started":"2025-12-17T20:47:54.311247Z","shell.execute_reply":"2025-12-17T20:47:57.686351Z"}},"outputs":[{"name":"stdout","text":"updating: kaggle/working/ (stored 0%)\nupdating: kaggle/working/.virtual_documents/ (stored 0%)\nupdating: kaggle/working/.virtual_documents/__notebook_source__.ipynb (deflated 59%)\nupdating: kaggle/working/lora_out/ (stored 0%)\nupdating: kaggle/working/lora_out/checkpoint-64/ (stored 0%)\nupdating: kaggle/working/lora_out/checkpoint-64/optimizer.pt","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":" (deflated 7%)\nupdating: kaggle/working/lora_out/checkpoint-64/adapter_config.json (deflated 56%)\nupdating: kaggle/working/lora_out/checkpoint-64/README.md (deflated 65%)\nupdating: kaggle/working/lora_out/checkpoint-64/rng_state.pth (deflated 26%)\nupdating: kaggle/working/lora_out/checkpoint-64/scheduler.pt (deflated 62%)\nupdating: kaggle/working/lora_out/checkpoint-64/adapter_model.safetensors (deflated 8%)\nupdating: kaggle/working/lora_out/checkpoint-64/training_args.bin (deflated 53%)\nupdating: kaggle/working/lora_out/checkpoint-64/trainer_state.json (deflated 66%)\nupdating: kaggle/working/lora_out/checkpoint-64/scaler.pt (deflated 64%)\nupdating: kaggle/working/lora_out/checkpoint-32/ (stored 0%)\nupdating: kaggle/working/lora_out/checkpoint-32/optimizer.pt (deflated 7%)\nupdating: kaggle/working/lora_out/checkpoint-32/adapter_config.json (deflated 56%)\nupdating: kaggle/working/lora_out/checkpoint-32/README.md (deflated 65%)\nupdating: kaggle/working/lora_out/checkpoint-32/rng_state.pth (deflated 26%)\nupdating: kaggle/working/lora_out/checkpoint-32/scheduler.pt (deflated 61%)\nupdating: kaggle/working/lora_out/checkpoint-32/adapter_model.safetensors (deflated 8%)\nupdating: kaggle/working/lora_out/checkpoint-32/training_args.bin (deflated 53%)\nupdating: kaggle/working/lora_out/checkpoint-32/trainer_state.json (deflated 61%)\nupdating: kaggle/working/lora_out/checkpoint-32/scaler.pt (deflated 64%)\nupdating: kaggle/working/agent_test_results.json (deflated 76%)\nupdating: kaggle/working/qwen3-4b-course/ (stored 0%)\nupdating: kaggle/working/qwen3-4b-course/adapter_config.json (deflated 56%)\nupdating: kaggle/working/qwen3-4b-course/README.md (deflated 65%)\nupdating: kaggle/working/qwen3-4b-course/vocab.json (deflated 61%)\nupdating: kaggle/working/qwen3-4b-course/merges.txt (deflated 57%)\nupdating: kaggle/working/qwen3-4b-course/adapter_model.safetensors (deflated 8%)\nupdating: kaggle/working/qwen3-4b-course/tokenizer.json (deflated 81%)\nupdating: kaggle/working/qwen3-4b-course/special_tokens_map.json (deflated 69%)\nupdating: kaggle/working/qwen3-4b-course/chat_template.jinja (deflated 76%)\nupdating: kaggle/working/qwen3-4b-course/tokenizer_config.json (deflated 90%)\nupdating: kaggle/working/qwen3-4b-course/added_tokens.json (deflated 68%)\n","output_type":"stream"}],"execution_count":33}]}