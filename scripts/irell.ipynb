{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14199605,"sourceType":"datasetVersion","datasetId":9055634},{"sourceId":14200012,"sourceType":"datasetVersion","datasetId":9055925},{"sourceId":14200115,"sourceType":"datasetVersion","datasetId":9056009}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q \\\n    transformers \\\n    accelerate \\\n    peft \\\n    bitsandbytes \\\n    datasets \\\n    sentence-transformers \\\n    faiss-cpu \\\n    pymupdf","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-12-19T13:12:24.570893Z","iopub.execute_input":"2025-12-19T13:12:24.571512Z","iopub.status.idle":"2025-12-19T13:12:33.734031Z","shell.execute_reply.started":"2025-12-19T13:12:24.571483Z","shell.execute_reply":"2025-12-19T13:12:33.733339Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nimport faiss\nimport json\nimport numpy as np\nimport fitz\nfrom datasets import load_dataset\nfrom sentence_transformers import SentenceTransformer\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    Trainer\n)\nfrom peft import LoraConfig, get_peft_model","metadata":{"execution":{"iopub.status.busy":"2025-12-19T13:12:33.735808Z","iopub.execute_input":"2025-12-19T13:12:33.736326Z","iopub.status.idle":"2025-12-19T13:13:05.381173Z","shell.execute_reply.started":"2025-12-19T13:12:33.736296Z","shell.execute_reply":"2025-12-19T13:13:05.380552Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2025-12-19 13:12:50.938382: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766149971.107539      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766149971.156890      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1766149971.586781      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766149971.586820      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766149971.586823      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766149971.586825      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"MODEL_NAME = \"Qwen/Qwen3-4B\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\"\n)\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME,\n    quantization_config=bnb_config,\n    device_map=\"auto\"\n)","metadata":{"execution":{"iopub.status.busy":"2025-12-19T13:13:05.382000Z","iopub.execute_input":"2025-12-19T13:13:05.382594Z","iopub.status.idle":"2025-12-19T13:13:46.653557Z","shell.execute_reply.started":"2025-12-19T13:13:05.382565Z","shell.execute_reply":"2025-12-19T13:13:46.652696Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e327e1d747ba4da09734bd83219b2639"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf7960bc3da34b6eb809dafd29fe76f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3767a0703b274cb58bf9bf6b07b4f289"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cef3a6d3ecb04974a39502feae673101"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/726 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a509c65b3e7a425ba3b8fee50b7450db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db641e579edb4e369cc0ba46241fea97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b0e1db102454413be909073eaaf626b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88854af94894413da7abd106c8095975"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/99.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17304fc7082749f58737bb7d1c77e7fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85c5695f042e4302883811635221ffe2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47d3bcdf70704d948a7e520d88e010f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed431adfc877449095a28f7345a0579f"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=[\"q_proj\", \"v_proj\"],\n    lora_dropout=0.05,\n    task_type=\"CAUSAL_LM\"\n)\n\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2025-12-19T13:13:46.655401Z","iopub.execute_input":"2025-12-19T13:13:46.657854Z","iopub.status.idle":"2025-12-19T13:13:46.801815Z","shell.execute_reply.started":"2025-12-19T13:13:46.657825Z","shell.execute_reply":"2025-12-19T13:13:46.801057Z"},"trusted":true},"outputs":[{"name":"stdout","text":"trainable params: 2,949,120 || all params: 4,025,417,216 || trainable%: 0.0733\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"dataset = load_dataset(\n    \"json\",\n    data_files=\"/kaggle/input/lora-train-json/lora_train.jsonl\"\n)\n\ndef tokenize(example):\n    messages = [\n        {\"role\": \"user\", \"content\": example[\"instruction\"]},\n        {\"role\": \"assistant\", \"content\": example[\"response\"]}\n    ]\n\n    text = tokenizer.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=False\n    )\n\n    out = tokenizer(\n        text,\n        truncation=True,\n        max_length=512\n    )\n    out[\"labels\"] = out[\"input_ids\"].copy()\n    return out\n\ndataset = dataset.map(tokenize, remove_columns=dataset[\"train\"].column_names)","metadata":{"execution":{"iopub.status.busy":"2025-12-19T13:13:46.802780Z","iopub.execute_input":"2025-12-19T13:13:46.803095Z","iopub.status.idle":"2025-12-19T13:13:57.861788Z","shell.execute_reply.started":"2025-12-19T13:13:46.803059Z","shell.execute_reply":"2025-12-19T13:13:57.861001Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dff0d88132804ae78af8a5e07f93c31d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/128 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11953748a5b5452aa97525be1d0eecde"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"args = TrainingArguments(\n    output_dir=\"lora_out\",\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=4,\n    num_train_epochs=2,\n    logging_steps=10,\n    save_strategy=\"epoch\",\n    optim=\"paged_adamw_8bit\",\n    fp16=True,\n    report_to=\"none\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=dataset[\"train\"]\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2025-12-19T13:13:57.862694Z","iopub.execute_input":"2025-12-19T13:13:57.863318Z","iopub.status.idle":"2025-12-19T13:17:00.127578Z","shell.execute_reply.started":"2025-12-19T13:13:57.863292Z","shell.execute_reply":"2025-12-19T13:17:00.126790Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [64/64 02:58, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>1.910700</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.640100</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.594900</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.425400</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.487700</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.335600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=64, training_loss=1.5580613389611244, metrics={'train_runtime': 181.7352, 'train_samples_per_second': 1.409, 'train_steps_per_second': 0.352, 'total_flos': 2236379911907328.0, 'train_loss': 1.5580613389611244, 'epoch': 2.0})"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"model.save_pretrained(\"qwen3-4b-course\")\ntokenizer.save_pretrained(\"qwen3-4b-course\")","metadata":{"execution":{"iopub.status.busy":"2025-12-19T13:17:00.128674Z","iopub.execute_input":"2025-12-19T13:17:00.128931Z","iopub.status.idle":"2025-12-19T13:17:00.463232Z","shell.execute_reply.started":"2025-12-19T13:17:00.128907Z","shell.execute_reply":"2025-12-19T13:17:00.462474Z"},"trusted":true},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"('qwen3-4b-course/tokenizer_config.json',\n 'qwen3-4b-course/special_tokens_map.json',\n 'qwen3-4b-course/chat_template.jinja',\n 'qwen3-4b-course/vocab.json',\n 'qwen3-4b-course/merges.txt',\n 'qwen3-4b-course/added_tokens.json',\n 'qwen3-4b-course/tokenizer.json')"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"index = faiss.read_index(\"/kaggle/input/vectorstore/index.faiss\")\ntexts = np.load(\"/kaggle/input/vectorstore/texts.npy\", allow_pickle=True)\n\nembedder = SentenceTransformer(\"intfloat/e5-base-v2\")","metadata":{"execution":{"iopub.status.busy":"2025-12-19T13:17:00.464207Z","iopub.execute_input":"2025-12-19T13:17:00.464517Z","iopub.status.idle":"2025-12-19T13:17:03.675643Z","shell.execute_reply.started":"2025-12-19T13:17:00.464483Z","shell.execute_reply":"2025-12-19T13:17:03.675102Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2e59e0251f94e1fb059cf555f2455c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af0ac14411cb45b990cd54c4ae08813f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4b77f99bb8e4281b339daefd9975dff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bd798784ced4ac5994795a41de017f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce4b971878f943e4898ed4a70f053fe0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a67388c749294276b4d420b872495337"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa1f29a72e074b97a7487a1f4878e51c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3734e354fe8e4b06afe6086cf809c6f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6910adfdb384d5faf53f6b5ee8459f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16f5f2b89fec4e94a47c812bc871981d"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"!pip install -q \\\n    arxiv \\\n    youtube-search","metadata":{"execution":{"iopub.status.busy":"2025-12-19T13:17:03.676425Z","iopub.execute_input":"2025-12-19T13:17:03.676738Z","iopub.status.idle":"2025-12-19T13:17:11.354344Z","shell.execute_reply.started":"2025-12-19T13:17:03.676713Z","shell.execute_reply":"2025-12-19T13:17:11.353624Z"},"trusted":true},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import sys\nimport arxiv\nimport subprocess\nfrom youtube_search import YoutubeSearch\n\ndef extract_concepts(question):\n    \"\"\"Isolates core technical keywords from the question.\"\"\"\n    # This prompt provides an example to guide the model's output format\n    extraction_prompt = f\"\"\"\nExtract 2-3 core mathematical concepts from the question below.\nExample: \nQuestion: \"Calculate the PDF of Z = X + Y for Gaussian variables.\"\nKeywords: Gaussian distribution, Probability Density Function\n\nQuestion: \"{question}\"\nKeywords:\"\"\"\n    \n    inputs = tokenizer(extraction_prompt, return_tensors=\"pt\").to(model.device)\n    \n    # max_new_tokens=30 keeps the output short to prevent instructions from leaking\n    output = model.generate(\n        **inputs, \n        max_new_tokens=30, \n        temperature=0.1, \n        do_sample=False,\n        pad_token_id=tokenizer.eos_token_id\n    )\n    \n    full_text = tokenizer.decode(output[0], skip_special_tokens=True)\n    \n    # Split by 'Keywords:' and take only the first line to discard extra model chatter\n    if \"Keywords:\" in full_text:\n        concepts = full_text.split(\"Keywords:\")[-1].strip().split('\\n')[0]\n    else:\n        concepts = full_text.split('\\n')[-1].strip()\n        \n    return concepts\n\ndef youtube_search(query, max_results=3):\n    \"\"\"Fetches video links using the youtube-search library.\"\"\"\n    try:\n        # We clean the query to ensure it's just words separated by spaces\n        clean_query = query.replace(\",\", \" \")\n        results = YoutubeSearch(clean_query, max_results=max_results).to_dict()\n        \n        links = []\n        for v in results:\n            links.append({\n                \"title\": v['title'],\n                \"link\": f\"https://www.youtube.com{v['url_suffix']}\"\n            })\n        return links\n    except Exception as e:\n        print(f\"YT Search Error: {e}\")\n        return []\ndef arxiv_search(query, max_results=3):\n    try:\n        client = arxiv.Client()\n        search_term = query.replace(\",\", \" \")\n        search = arxiv.Search(query=search_term, max_results=max_results)\n        return [{\"title\": res.title, \"url\": res.pdf_url} for res in client.results(search)]\n    except:\n        return []\n    ","metadata":{"execution":{"iopub.status.busy":"2025-12-19T13:17:11.357041Z","iopub.execute_input":"2025-12-19T13:17:11.357289Z","iopub.status.idle":"2025-12-19T13:17:11.391570Z","shell.execute_reply.started":"2025-12-19T13:17:11.357260Z","shell.execute_reply":"2025-12-19T13:17:11.390857Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# CREATING EMBEDDINGS FOR PREVIOUS QUESTIONS\n# 1. Load ONLY the questions (instruction field) from the lora_train.jsonl file\npast_questions_list = []\nwith open(\"/kaggle/input/lora-train-json/lora_train.jsonl\", \"r\") as f:\n    for line in f:\n        try:\n            data = json.loads(line.strip())\n            # Extract the content of the 'instruction' field, which is the question\n            # located between the instruction and response keys in the JSON record\n            if \"instruction\" in data:\n                past_questions_list.append(data[\"instruction\"])\n        except json.JSONDecodeError:\n            # Skip lines that are not valid JSON\n            continue\n\n# 2. Create embeddings for the questions using the existing embedder [cite: 18]\nprint(f\"Indexing {len(past_questions_list)} past questions...\")\n# Ensure the embedder (intfloat/e5-base-v2) is already loaded from previous cells [cite: 18]\nquestion_embeddings = embedder.encode(past_questions_list).astype(\"float32\")\n\n# 3. Initialize a separate FAISS index specifically for these questions [cite: 18]\nd = question_embeddings.shape[1]\npast_questions_index = faiss.IndexFlatL2(d)\npast_questions_index.add(question_embeddings)\n\nprint(\"âœ… Past questions index created successfully.\")\n\n# 4. Retrieval function to find similar questions based on the new index\ndef get_similar_past_questions(query, k=3):\n    \"\"\"Retrieves the k most similar questions from the training set.\"\"\"\n    query_vector = embedder.encode([query]).astype(\"float32\")\n    distances, indices = past_questions_index.search(query_vector, k)\n    return [past_questions_list[i] for i in indices[0]]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T13:17:11.392412Z","iopub.execute_input":"2025-12-19T13:17:11.392617Z","iopub.status.idle":"2025-12-19T13:17:12.465437Z","shell.execute_reply.started":"2025-12-19T13:17:11.392595Z","shell.execute_reply":"2025-12-19T13:17:12.464659Z"}},"outputs":[{"name":"stdout","text":"Indexing 128 past questions...\nâœ… Past questions index created successfully.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def retrieve_context(question, k=4):\n    emb = embedder.encode([question]).astype(\"float32\")\n    _, idx = index.search(emb, k)\n    return \"\\n\\n\".join(texts[i] for i in idx[0])","metadata":{"execution":{"iopub.status.busy":"2025-12-19T13:17:12.466482Z","iopub.execute_input":"2025-12-19T13:17:12.467042Z","iopub.status.idle":"2025-12-19T13:17:12.471139Z","shell.execute_reply.started":"2025-12-19T13:17:12.467005Z","shell.execute_reply":"2025-12-19T13:17:12.470358Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def generate_answer(question):\n    # STEP 1: Concept Extraction\n    concepts = extract_concepts(question)\n    search_query = concepts.replace(\",\", \" \")\n    \n    context = retrieve_context(question)\n\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": \"You are an IIIT course assistant.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": f\"\"\"\n                Context:\n                {context}\n                \n                Question:\n                {question}\n                \n                Think briefly, then answer. Answer clearly, completely, briefly and in a structured manner.\n                \"\"\"\n        }\n    ]\n\n    text = tokenizer.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=True\n    )\n\n    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n\n    output = model.generate(\n        **inputs,\n        max_new_tokens=7500,\n        temperature=0.6,\n        top_p=0.95\n    )\n\n    raw_answer = tokenizer.decode(output[0], skip_special_tokens=True)\n    thoughts = raw_answer.split(\"assistant\")[-1].split(\"</think>\")[0].strip()\n    clean_answer = raw_answer.split(\"assistant\")[-1].split(\"</think>\")[-1].strip()\n\n    print(\"ğŸŒ Fetching external resources...\")\n    sys.stdout.flush()\n    \n    yt_links = youtube_search(search_query)\n    arxiv_links = arxiv_search(search_query)\n    similar_qs = get_similar_past_questions(question, k=3)\n    \n    return {\n        \"extracted_concepts\": concepts,\n        \"search_query\": search_query,\n        \"thoughts\": thoughts,\n        \"answer\": clean_answer,\n        \"youtube\": yt_links,\n        \"papers\": arxiv_links,\n        \"similar_questions\": similar_qs\n    }","metadata":{"execution":{"iopub.status.busy":"2025-12-19T13:17:12.471975Z","iopub.execute_input":"2025-12-19T13:17:12.472176Z","iopub.status.idle":"2025-12-19T13:17:12.480401Z","shell.execute_reply.started":"2025-12-19T13:17:12.472153Z","shell.execute_reply":"2025-12-19T13:17:12.479690Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# Validation","metadata":{}},{"cell_type":"code","source":"# ğŸ” Trial test cell â€” verify RAG + LoRA model works end-to-end\ntest_question = \"What is a random variable? Explain with examples.\"\n\nprint(\"=\" * 70)\nprint(\" IIIT Course Assistant â€“ Trial RAG Test\")\nprint(\"=\" * 70)\n\nprint(\"\\nğŸ§‘â€ğŸ“ Question:\")\nprint(test_question)\n\nprint(\"\\nğŸ” Thinking...\\n\")\n\nresult = generate_answer(test_question)\n\nprint(f\"\\nğŸ§  Model Extraction: {result['extracted_concepts']}\")\nprint(f\"ğŸ” Query fed to YT/ArXiv: {result['search_query']}\")\nprint(\"-\" * 70)\n\nprint(\"\\nğŸ“˜ Assistant Thoughts:\")\nthoughts = result[\"thoughts\"].strip()\nprint(thoughts)\n\nprint(\"-\" * 70)\n\nprint(\"\\nğŸ“˜ Assistant Answer:\")\n# Cleaning the answer display to remove the chat history prefix if needed\nfinal_answer = result[\"answer\"].split(\"assistant\")[-1].strip()\nprint(final_answer)\n\nprint(\"-\" * 70)\n\nif result.get(\"youtube\"):\n    print(\"\\nğŸ“º Suggested YouTube Videos:\")\n    for vid in result[\"youtube\"]:\n        print(f\"  â€¢ {vid['title']}: {vid['link']}\")\n\nif result.get(\"papers\"):\n    print(\"\\nğŸ“„ Relevant Research Papers (arXiv):\")\n    for paper in result[\"papers\"]:\n        print(f\"  â€¢ {paper['title']}: {paper['url']}\")\n\nif result.get(\"similar_questions\"):\n    print(\"\\nğŸ“ Similar Past Exam Questions:\")\n    for i, q in enumerate(result[\"similar_questions\"]):\n        # Clean up the string to remove citations if present in the source text\n        clean_q = q.split(\"[\")[0].strip() \n        print(f\"  {i+1}. {clean_q}\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"âœ… Test completed with concept-aware search.\")","metadata":{"execution":{"iopub.status.busy":"2025-12-19T13:17:12.481323Z","iopub.execute_input":"2025-12-19T13:17:12.481950Z","iopub.status.idle":"2025-12-19T13:19:22.952579Z","shell.execute_reply.started":"2025-12-19T13:17:12.481917Z","shell.execute_reply":"2025-12-19T13:19:22.951971Z"},"trusted":true},"outputs":[{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"======================================================================\n IIIT Course Assistant â€“ Trial RAG Test\n======================================================================\n\nğŸ§‘â€ğŸ“ Question:\nWhat is a random variable? Explain with examples.\n\nğŸ” Thinking...\n\nğŸŒ Fetching external resources...\nYT Search Error: HTTPSConnectionPool(host='www.youtube.com', port=443): Read timed out. (read timeout=10)\n\nğŸ§  Model Extraction: Discrete random variable, Continuous\nğŸ” Query fed to YT/ArXiv: Discrete random variable  Continuous\n----------------------------------------------------------------------\n\nğŸ“˜ Assistant Thoughts:\n<think>\nOkay, the user is asking what a random variable is and wants examples. Let me recall the definitions from the context provided.\n\nFirst, the context mentions that a random variable is discrete if its CDF is piecewise constant and continuous if the CDF is a continuous function. Examples given include uniform distribution over [a, b], time intervals, travel time, and water levels. Also, there's a running example with a coin and dice experiment.\n\nI need to define a random variable clearly. A random variable is a function that assigns numerical values to outcomes in a sample space. Examples should include both discrete and continuous cases. The coin and dice example is a good one, where X and Y are discrete. The uniform distribution on [a,b] is continuous. Also, the exponential distribution for time intervals.\n\nWait, the user might be confused between a random variable and a probability distribution. I should clarify that a random variable is a variable whose value is determined by a random process, not the distribution itself. Also, the examples from the context should be highlighted.\n\nI should structure the answer by first defining a random variable, then differentiating discrete and continuous, then give examples. The running example with coin and dice can be used to show discrete. The uniform and exponential examples for continuous. Also, mention that the CDF is a key part of the definition.\n\nMake sure to explain that a random variable is a function from the sample space to real numbers, and that it can be discrete or continuous. Examples should be clear. Also, note that the sample space is the set of all possible outcomes, like the coin and dice in the example.\n----------------------------------------------------------------------\n\nğŸ“˜ Assistant Answer:\n**Random Variable**  \nA **random variable** is a function that maps outcomes from a sample space to real numbers, representing numerical values of random events. It quantifies outcomes of experiments in a probabilistic framework.  \n\n---\n\n### **Types**  \n1. **Discrete**: Takes countable values (e.g., integers).  \n   - Example: Outcome of a coin toss (X = 0 or 1).  \n   - Example: Dice roll (Y = 1â€“6).  \n\n2. **Continuous**: Takes any real value in an interval.  \n   - Example: Uniformly distributed over [a, b] (e.g., height of a person).  \n   - Example: Time between customer arrivals (exponential distribution).  \n\n---\n\n### **Key Properties**  \n- **CDF**: Cumulative distribution function (CDF) defines the probability that the variable is â‰¤ a given value.  \n  - Discrete: CDF is **piecewise constant**.  \n  - Continuous: CDF is **continuous**.  \n\n---\n\n### **Example from Context**  \n- **Coin and Dice Experiment**:  \n  - Sample space: Î© = {0, 1} Ã— {1, 2, 3, 4, 5, 6}.  \n  - Random variables:  \n    - X: Coin outcome (0 for tails, 1 for heads).  \n    - Y: Dice outcome (1â€“6).  \n  - Joint PMF: P(X = x, Y = y) = 1/12 for all (x, y) âˆˆ Î©.  \n\n---\n\n### **Key Takeaway**  \nA random variable is a **numerical representation of outcomes** in a probabilistic experiment, distinguishing between discrete (countable values) and continuous (real-number values).\n----------------------------------------------------------------------\n\nğŸ“„ Relevant Research Papers (arXiv):\n  â€¢ Continuous variable controlled quantum dialogue and secure multiparty quantum computation: https://arxiv.org/pdf/1902.00458v1\n  â€¢ Mixed Hamiltonian Monte Carlo for Mixed Discrete and Continuous Variables: https://arxiv.org/pdf/1909.04852v6\n  â€¢ Entropy and thinning of discrete random variables: https://arxiv.org/pdf/1510.05390v3\n\nğŸ“ Similar Past Exam Questions:\n  1. We are given random variables X1, X2, . . . , Xn with finite variances, and they are not necessarily independent. We need to find the variance of Sn = Pn i=1 Xi and then check how the expression changes when the Xiâ€™s are independent.\n  2. Let A and B be two independent Poisson random variables with parameters a and b respectively. Let C = A + B. Using MGF, show that C is also a Poisson random variable.\n  3. Given samples x1, . . . xn from an exponential random variable X with parameter Î», convert it into samples from another exponential random variable with parameter Âµ. Explain the procedure in detail with justifications\n\n======================================================================\nâœ… Test completed with concept-aware search.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import json\nimport fitz\nimport re\n\nPDF_PATH = \"/kaggle/input/endsem/endsem_solutions.pdf\"\n\ndef extract_questions_from_solutions(pdf_path):\n    doc = fitz.open(pdf_path)\n    full_text = \"\"\n    for page in doc:\n        full_text += page.get_text()\n\n    question_blocks = re.split(r'(Q\\d+[:])', full_text)\n\n    extracted_questions = []\n    for i in range(1, len(question_blocks), 2):\n        q_id = question_blocks[i].replace(\":\", \"\").strip()   # Q1\n        q_content = question_blocks[i+1]\n        question_text = q_content.split('A:')[0].strip()\n        extracted_questions.append((q_id, question_text))\n\n    return extracted_questions\n\n\nprint(\"ğŸ“„ Reading questions from endsem PDF...\")\nquestions = extract_questions_from_solutions(PDF_PATH)\n\nprint(f\"âœ… Found {len(questions)} questions. Starting evaluation...\\n\")\nprint(\"Questions found: \")\nprint(questions)\nprint()\nresults = {}\nid = 1\n\nfor q_id, q_text in questions:\n    q_id = id\n    print(f\"ğŸ§ª Evaluating {q_id}...\")\n    try:\n        ans = generate_answer(q_text)\n\n        results[q_id] = {\n            \"question_id\": q_id,\n            \"input_question\": q_text,\n            \"retrieval\": {\n                \"extracted_concepts\": ans[\"extracted_concepts\"],\n                \"search_query\": ans[\"search_query\"]\n            },\n            \"model_response\": {\n                \"answer\": ans[\"answer\"].split(\"assistant\")[-1].strip(),\n                \"thoughts\": ans[\"thoughts\"].strip()\n            },\n            \"resources\": {\n                \"youtube\": ans[\"youtube\"],\n                \"papers\": ans[\"papers\"],\n                \"similar_past_questions\": ans.get(\"similar_questions\", [])\n            }\n        }\n\n    except Exception as e:\n        results[q_id] = {\n            \"question_id\": q_id,\n            \"input_question\": q_text,\n            \"error\": str(e)\n        }\n    id += 1\n\n# Save final results\noutput_file = \"endsem_results.json\"\nwith open(output_file, \"w\") as f:\n    json.dump(results, f, indent=4)\n\nprint(f\"\\nğŸ¯ Endsem evaluation complete.\")\nprint(f\"ğŸ“ Results saved to {output_file}\")","metadata":{"execution":{"iopub.status.busy":"2025-12-19T13:43:37.263593Z","iopub.execute_input":"2025-12-19T13:43:37.264389Z","iopub.status.idle":"2025-12-19T14:49:54.204733Z","shell.execute_reply.started":"2025-12-19T13:43:37.264356Z","shell.execute_reply":"2025-12-19T14:49:54.203956Z"},"trusted":true},"outputs":[{"name":"stdout","text":"ğŸ“„ Reading questions from endsem PDF...\nâœ… Found 12 questions. Starting evaluation...\n\nQuestions found: \n[('Q1', 'Let Z = X1 + X2 + Â· Â· Â· + XN, where Xi are i.i.d. random variables and N is a\\npositive discrete random variable. Prove that:\\nMZ(t) = MN(log MX(t)).'), ('Q2', 'Let Y = eX, where X âˆ¼N(Âµ, Ïƒ2). Obtain the pdf of Y .'), ('Q1', 'Let D = {x1, x2, . . . , xn} denote i.i.d. samples from a Poisson random variable with\\nunknown parameter Î³.\\n(a) Find the Maximum Likelihood Estimate (MLE) for the unknown parameter\\nÎ³. (5 marks)\\n(b) Determine the Mean Squared Error (MSE) of the estimate. (3 marks)'), ('Q2', 'Consider a Gaussian random variable X with a known mean Âµ but an unknown\\nvariance Ïƒ2. Suppose you observe k iid samples from this random variable, denoted\\nby D = {x1, x2, . . . , xk}.\\n(a) Find the MLE for the unknown variance Ïƒ2.\\n(5 marks)\\n(b) Is the MLE estimate biased? Justify your answer.\\n(3 marks)'), ('Q3', 'Consider a sequence {Xn, n = 1, 2, 3, . . . } such that\\nXn =\\n(\\nn,\\nwith probability\\n1\\nn2\\n0,\\nwith probability 1 âˆ’\\n1\\nn2\\n(a) Show that Xn\\npâˆ’â†’0 (Convergence in probability to 0).\\n(4 marks)\\n(b) Show that Xn\\na.s.\\nâˆ’âˆ’â†’0 (Almost sure convergence to 0).\\n(4 marks)'), ('Q4', 'Given a Markov coin with the following transition probability matrix P and initial\\ndistribution Âµ = [0.1, 0.9], use the following 4 independent Uniform[0, 1] samples\\n{0.3, 0.7, 0.23, 0.97} to obtain/generate 4 successive toss outcomes of the Markov\\ncoin. (Hint: The first toss is to be sampled from the initial distribution.)\\nP =\\n\\x140.9\\n0.1\\n0.4\\n0.6\\n\\x15'), ('Q5', 'Let X and Y be independent random variables with common distribution function\\nF.\\n1. PDF of Z1 = max(X, Y )\\nCDF of Z1:\\nFZ1(z) = P(Z1 â‰¤z)\\n= P(max(X, Y ) â‰¤z)\\n= P(X â‰¤z and Y â‰¤z)\\n= P(X â‰¤z) Â· P(Y â‰¤z)\\n(using independence)\\n= F(z) Â· F(z)\\n= F(z)2\\nPDF of Z1:\\nfZ1(z) = d\\ndzF(z)2 = 2F(z)f(z)\\n2. PDF of Z2 = min(X, Y )\\nCDF of Z2:\\nFZ2(z) = P(Z2 â‰¤z)\\n= P(min(X, Y ) â‰¤z)\\n= 1 âˆ’P(min(X, Y ) > z)\\n= 1 âˆ’P(X > z and Y > z)\\n= 1 âˆ’P(X > z) Â· P(Y > z)\\n(using independence)\\n= 1 âˆ’(1 âˆ’F(z)) Â· (1 âˆ’F(z))\\n= 1 âˆ’(1 âˆ’F(z))2\\nPDF of Z2:\\nfZ2(z) = d\\ndz\\n\\x02\\n1 âˆ’(1 âˆ’F(z))2\\x03\\n= 2(1 âˆ’F(z))f(z)\\nFinal PDFs\\nfZ1(z) = 2F(z)f(z)\\nfZ2(z) = 2(1 âˆ’F(z))f(z)\\n8\\n10 Mark Questions'), ('Q1', 'Let D = {x1, . . . xn} denote i.i.d. samples from a uniform random variable U[a, b]\\nwhere a and b are unknown. Find an MLE estimate for the unknown parameters\\na and b'), ('Q2', 'Bayesian Inference/ Conjugate prior problem: Suppose D = {x1, ..., xn} is a data\\nset consisting of independent samples of a Poisson random variable with unknown\\nparameter Î»âˆ—.\\nNow assume a prior model Î› âˆ¼Gamma(Î±, Î²) on the unknown\\nparameter Î»âˆ—(see hint below for gamma distribution). Obtain an expression for\\nthe posterior distribution on Î»âˆ—. (7mks). What is the MAP estimate for Î»âˆ—? (3mks)\\nHint: Use Prior belief: Î› âˆ¼Gamma(Î±, Î²),\\nfÎ›(Î») =\\nÎ²Î±\\nÎ“(Î±)Î»Î±âˆ’1eâˆ’Î²Î»;\\nÎ» > 0.\\nand Likelihood of observing x given Î› = Î»:\\nfX|Î›(x|Î») = Î»xeâˆ’Î»\\nx!'), ('Q3', '(i) For a Markov chain, let Fii denote the probability of the chain ever returning to\\nstate i having started in state i, and let f n\\nii denote the probability of visiting state\\ni for the first time in exactly n steps, having started in state i. Show that:\\nFii =\\nâˆ\\nX\\nn=1\\nf n\\nii.\\n(ii) For a Markov chain with state space S = {1, 2, 3} and transition matrix:\\nP =\\n\\uf8ee\\n\\uf8f0\\np\\n1 âˆ’p\\n0\\np\\n1 âˆ’2p\\np\\n0\\n0\\n1\\n\\uf8f9\\n\\uf8fb,\\nuse the above equality to find Fii for i = 1, 2, 3. From the values of Fii, deduce\\nwhich states are transient and recurrent.'), ('Q4', 'Gaussian: Suppose X = AZ + Âµ, where A is an n Ã— n matrix and Z is a standard\\nnormal vector of length n. Derive the expression for the mean E[X] and covariance\\nmatrix CX. (5 mks) Also derive the expression for the pdf of X. (5 mks)'), ('Q5', 'Shifted Exponential: Let X be a random variable following a shifted exponential\\ndistribution with rate parameter Î» > 0 and shift parameter Âµ. The probability\\ndensity function (PDF) of X is given by:\\nfX(x) =\\n(\\nÎ»eâˆ’Î»(xâˆ’Âµ),\\nif x â‰¥Âµ,\\n0,\\notherwise.\\n(a) Derive the MGF of X, state its region of convergence (5 mks)\\n(b) Using the MGF, obtain the first and second moments of X.\\nWhat is the\\nvariance of X? (5 mks)')]\n\nğŸ§ª Evaluating 1...\nğŸŒ Fetching external resources...\nğŸ§ª Evaluating 2...\nğŸŒ Fetching external resources...\nğŸ§ª Evaluating 3...\nğŸŒ Fetching external resources...\nğŸ§ª Evaluating 4...\nğŸŒ Fetching external resources...\nğŸ§ª Evaluating 5...\nğŸŒ Fetching external resources...\nğŸ§ª Evaluating 6...\nğŸŒ Fetching external resources...\nğŸ§ª Evaluating 7...\nğŸŒ Fetching external resources...\nğŸ§ª Evaluating 8...\nğŸŒ Fetching external resources...\nğŸ§ª Evaluating 9...\nğŸŒ Fetching external resources...\nğŸ§ª Evaluating 10...\nğŸŒ Fetching external resources...\nğŸ§ª Evaluating 11...\nğŸŒ Fetching external resources...\nğŸ§ª Evaluating 12...\nğŸŒ Fetching external resources...\n\nğŸ¯ Endsem evaluation complete.\nğŸ“ Results saved to endsem_results.json\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"!zip -r working.zip /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2025-12-19T14:55:12.820963Z","iopub.execute_input":"2025-12-19T14:55:12.821551Z","iopub.status.idle":"2025-12-19T14:55:16.051494Z","shell.execute_reply.started":"2025-12-19T14:55:12.821517Z","shell.execute_reply":"2025-12-19T14:55:16.050620Z"},"trusted":true},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/ (stored 0%)\n  adding: kaggle/working/lora_out/ (stored 0%)\n  adding: kaggle/working/lora_out/checkpoint-32/ (stored 0%)\n  adding: kaggle/working/lora_out/checkpoint-32/README.md (deflated 65%)\n  adding: kaggle/working/lora_out/checkpoint-32/trainer_state.json (deflated 61%)\n  adding: kaggle/working/lora_out/checkpoint-32/training_args.bin (deflated 53%)\n  adding: kaggle/working/lora_out/checkpoint-32/adapter_model.safetensors","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":" (deflated 8%)\n  adding: kaggle/working/lora_out/checkpoint-32/rng_state.pth (deflated 26%)\n  adding: kaggle/working/lora_out/checkpoint-32/scheduler.pt (deflated 61%)\n  adding: kaggle/working/lora_out/checkpoint-32/adapter_config.json (deflated 56%)\n  adding: kaggle/working/lora_out/checkpoint-32/scaler.pt (deflated 64%)\n  adding: kaggle/working/lora_out/checkpoint-32/optimizer.pt (deflated 7%)\n  adding: kaggle/working/lora_out/checkpoint-64/ (stored 0%)\n  adding: kaggle/working/lora_out/checkpoint-64/README.md (deflated 65%)\n  adding: kaggle/working/lora_out/checkpoint-64/trainer_state.json (deflated 65%)\n  adding: kaggle/working/lora_out/checkpoint-64/training_args.bin (deflated 53%)\n  adding: kaggle/working/lora_out/checkpoint-64/adapter_model.safetensors (deflated 8%)\n  adding: kaggle/working/lora_out/checkpoint-64/rng_state.pth (deflated 26%)\n  adding: kaggle/working/lora_out/checkpoint-64/scheduler.pt (deflated 62%)\n  adding: kaggle/working/lora_out/checkpoint-64/adapter_config.json (deflated 56%)\n  adding: kaggle/working/lora_out/checkpoint-64/scaler.pt (deflated 64%)\n  adding: kaggle/working/lora_out/checkpoint-64/optimizer.pt (deflated 7%)\n  adding: kaggle/working/endsem_results.json (deflated 79%)\n  adding: kaggle/working/qwen3-4b-course/ (stored 0%)\n  adding: kaggle/working/qwen3-4b-course/README.md (deflated 65%)\n  adding: kaggle/working/qwen3-4b-course/added_tokens.json (deflated 68%)\n  adding: kaggle/working/qwen3-4b-course/adapter_model.safetensors (deflated 8%)\n  adding: kaggle/working/qwen3-4b-course/vocab.json (deflated 61%)\n  adding: kaggle/working/qwen3-4b-course/special_tokens_map.json (deflated 69%)\n  adding: kaggle/working/qwen3-4b-course/chat_template.jinja (deflated 76%)\n  adding: kaggle/working/qwen3-4b-course/tokenizer_config.json (deflated 90%)\n  adding: kaggle/working/qwen3-4b-course/merges.txt (deflated 57%)\n  adding: kaggle/working/qwen3-4b-course/adapter_config.json (deflated 56%)\n  adding: kaggle/working/qwen3-4b-course/tokenizer.json (deflated 81%)\n  adding: kaggle/working/.virtual_documents/ (stored 0%)\n","output_type":"stream"}],"execution_count":18}]}